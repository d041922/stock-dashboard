# dashboard_v34_final.py

import streamlit as st
import finnhub
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import yfinance as yf
import google.generativeai as genai
import gspread
from google.oauth2.service_account import Credentials
import json
import re  # Add this line
from googleapiclient.discovery import build # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
from io import BytesIO
from googleapiclient.http import MediaIoBaseDownload
import tempfile # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
import os       # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
from PyPDF2 import PdfReader


# --- 1. ì´ˆê¸° ì„¤ì • ë° ë¡œê·¸ì¸ ---
st.set_page_config(page_title="GEM: Finance Dashboard", page_icon="ğŸ’", layout="wide")

def login():
    if "authenticated" not in st.session_state: st.session_state["authenticated"] = False
    if not st.session_state["authenticated"]:
        st.title("ğŸ’ GEM: Finance Dashboard")
        st.caption("MASTER, please enter the password to access the command center.")
        password = st.text_input("Enter password:", type="password")
        if st.button("Login"):
            if "password" in st.secrets and password == st.secrets["password"]:
                st.session_state["authenticated"] = True
                st.rerun()
            else:
                st.error("Incorrect password or password not set in secrets.toml ğŸš«")
        st.stop()

login()

# --- 2. API í‚¤ ë° ì¸ì¦ ì„¤ì • ---
try:
    FINNHUB_API_KEY = st.secrets["FINNHUB_API_KEY"]
    finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
    gc = gspread.authorize(creds)
    SPREADSHEET_NAME = "GEM_Finance_Portfolio"
except Exception as e:
    st.error(f"API í‚¤ ë˜ëŠ” ì¸ì¦ ì •ë³´ë¥¼ secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜: {e}")
    st.stop()

# --- 3. ë°ì´í„° í˜¸ì¶œ ë° ì²˜ë¦¬ í•¨ìˆ˜ ---

def load_data_from_gsheet():
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        portfolio_ws = spreadsheet.worksheet("Portfolio")
        portfolio_data = portfolio_ws.get_all_values()
        portfolio_headers = portfolio_data.pop(0)
        portfolio_df = pd.DataFrame(portfolio_data, columns=portfolio_headers)

        watchlist_ws = spreadsheet.worksheet("Watchlist")
        watchlist_df = pd.DataFrame(watchlist_ws.get_all_records())

        cash_ws = spreadsheet.worksheet("Cash")
        cash_df = pd.DataFrame(cash_ws.get_all_records())

        numeric_cols = ['ìˆ˜ëŸ‰', 'í‰ê·  ë‹¨ê°€(USD)', 'í‰ê·  ë‹¨ê°€(KRW)', 'ìˆ˜ë™ í˜„ì¬ê°€(KRW)']
        for col in numeric_cols:
            if col in portfolio_df.columns:
                portfolio_df[col] = portfolio_df[col].replace('', '0').astype(str).str.replace(',', '')
                portfolio_df[col] = pd.to_numeric(portfolio_df[col], errors='coerce').fillna(0)
        
        if 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)' in portfolio_df.columns:
            portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] = portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'].replace('', '0').astype(str).str.replace('%', '')
            portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] = pd.to_numeric(portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'], errors='coerce').fillna(0) / 100
        
        if 'ê¸ˆì•¡(KRW)' in cash_df.columns:
            cash_df['ê¸ˆì•¡(KRW)'] = cash_df['ê¸ˆì•¡(KRW)'].replace('', '0').astype(str).str.replace(',', '')
            cash_df['ê¸ˆì•¡(KRW)'] = pd.to_numeric(cash_df['ê¸ˆì•¡(KRW)'], errors='coerce').fillna(0)

        return portfolio_df, watchlist_df, cash_df
    except gspread.exceptions.WorksheetNotFound as e:
        st.error(f"Google Sheetsì—ì„œ '{e.args[0]}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('Portfolio', 'Watchlist', 'Cash', 'Analysis_Log')")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    except Exception as e:
        st.error(f"Google Sheets ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# [ëˆ„ë½ëœ í•¨ìˆ˜ ì¶”ê°€] AI ë¶„ì„ ì „ìš© í˜„ê¸ˆ ë°ì´í„° ë¡œë”
def load_cash_data_only():
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        cash_ws = spreadsheet.worksheet("Cash")
        cash_df = pd.DataFrame(cash_ws.get_all_records())
        if 'ê¸ˆì•¡(KRW)' in cash_df.columns:
            # ê¸ˆì•¡(KRW) ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³ , ë¹ˆ ë¬¸ìì—´ê³¼ ì‰¼í‘œë¥¼ ì²˜ë¦¬
            cash_df['ê¸ˆì•¡(KRW)'] = cash_df['ê¸ˆì•¡(KRW)'].astype(str).str.replace(',', '').replace('', '0')
            # ìˆ«ì í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë³€í™˜
            cash_df['ê¸ˆì•¡(KRW)'] = pd.to_numeric(cash_df['ê¸ˆì•¡(KRW)'], errors='coerce').fillna(0)
        return cash_df
    except Exception as e:
        st.error(f"Cash ì‹œíŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# [ìµœì¢… ë²„ì „] ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•œ ë‹¨ì¼ ë™ê¸°í™” í•¨ìˆ˜
def synchronize_knowledge_files(folder_name="GEM_Finance_Knowledge", core_folder_name="Core_Principles"):
    """Google Drive í´ë”ì™€ ê·¸ í•˜ìœ„ í´ë”ë¥¼ ëª¨ë‘ íƒìƒ‰í•˜ì—¬ Gemini APIì™€ ë™ê¸°í™”í•˜ê³ ,
    'ìµœìƒìœ„ ì§€ì¹¨'ê³¼ 'ì°¸ê³  ìë£Œ' íŒŒì¼ ëª©ë¡ì„ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        drive_service = build('drive', 'v3', credentials=creds)
        
        # 1. ë©”ì¸ í´ë” ID ì°¾ê¸°
        folder_response = drive_service.files().list(q=f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false", fields='files(id)').execute()
        if not folder_response.get('files'):
            st.warning(f"Google Driveì—ì„œ '{folder_name}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return [], []
        folder_id = folder_response.get('files')[0].get('id')
        
        # 2. [í•µì‹¬ ìˆ˜ì •] ë©”ì¸ í´ë” í•˜ìœ„ì˜ ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°
        all_items_response = drive_service.files().list(q=f"'{folder_id}' in parents and trashed=false", fields='files(id, name, mimeType, modifiedTime, parents)').execute()
        all_items = all_items_response.get('files', [])

        # Core_Principles í´ë” ID ì°¾ê¸° ë° í•´ë‹¹ í´ë” ë‚´ë¶€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        core_folder_id = None
        for item in all_items:
            if item.get('mimeType') == 'application/vnd.google-apps.folder' and item.get('name') == core_folder_name:
                core_folder_id = item.get('id')
                core_files_response = drive_service.files().list(q=f"'{core_folder_id}' in parents and trashed=false", fields='files(id, name, mimeType, modifiedTime, parents)').execute()
                all_items.extend(core_files_response.get('files', []))
                break
        
        # íŒŒì¼ë§Œ í•„í„°ë§í•˜ê³ , Core_Principles íŒŒì¼ ì´ë¦„ ëª©ë¡ ìƒì„±
        drive_files = {f['name']: f for f in all_items if f.get('mimeType') != 'application/vnd.google-apps.folder'}
        core_file_names = {f['name'] for f in all_items if f.get('parents') and core_folder_id in f.get('parents')}

        # 3. Gemini APIì™€ ë™ê¸°í™”
        gemini_files_list = genai.list_files()
        gemini_files = {f.display_name: f for f in gemini_files_list}

        # 3. Drive ê¸°ì¤€ìœ¼ë¡œ ë™ê¸°í™”
        with st.spinner("Knowledge Core ë™ê¸°í™” ì¤‘..."):
            # Driveì— ì—†ëŠ” íŒŒì¼ì€ Geminiì—ì„œ ì‚­ì œ
            for name, gemini_file in gemini_files.items():
                if name not in drive_files:
                    st.write(f"   - Driveì—ì„œ ì‚­ì œëœ íŒŒì¼ '{name}'ì„ AIì—ì„œ ì œê±°í•©ë‹ˆë‹¤.")
                    genai.delete_file(gemini_file.name)
            
            # Driveì— ìƒˆë¡œ ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ì€ Geminiì— ì—…ë¡œë“œ
            for name, drive_file in drive_files.items():
                should_upload = False
                if name in gemini_files:
                    gemini_file_metadata = genai.get_file(gemini_files[name].name)
                    drive_mod_time = pd.to_datetime(drive_file['modifiedTime'])
                    gemini_create_time = pd.to_datetime(gemini_file_metadata.create_time)
                    if drive_mod_time > gemini_create_time:
                        st.write(f"   - ìˆ˜ì •ëœ íŒŒì¼ '{name}'ì„ AIì— ë‹¤ì‹œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
                        genai.delete_file(gemini_files[name].name)
                        should_upload = True
                else:
                    should_upload = True

                if should_upload:
                    st.write(f"   - ìƒˆ íŒŒì¼ '{name}'ì„ AIì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
                    request = drive_service.files().get_media(fileId=drive_file.get('id'))
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{name}") as tmp_file:
                        fh = BytesIO()
                        downloader = MediaIoBaseDownload(fh, request)
                        done = False
                        while not done:
                            status, done = downloader.next_chunk()
                        tmp_file.write(fh.getvalue())
                        tmp_file_path = tmp_file.name
                    
                    genai.upload_file(path=tmp_file_path, display_name=name)
                    os.unlink(tmp_file_path)

        st.success("Knowledge Core ë™ê¸°í™” ì™„ë£Œ!")

       # 4. ìµœì¢… íŒŒì¼ ëª©ë¡ì„ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜
        final_gemini_files = genai.list_files()
        core_principle_files = [f for f in final_gemini_files if f.display_name in core_file_names]
        reference_files = [f for f in final_gemini_files if f.display_name not in core_file_names]
        
        return core_principle_files, reference_files

    except Exception as e:
        st.error(f"ì§€ì‹ íŒŒì¼ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        return [], []


def save_analysis_to_gsheet(log_data):
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        log_ws = spreadsheet.worksheet("Analysis_Log")
        EXPECTED_HEADERS = ["Timestamp", "ì¢…ëª©ì½”ë“œ", "AI_Model", "ë‹¹ì‹œ ì£¼ê°€", "ë¶„ì„ ìš”ì•½", "ì „ì²´ ë¶„ì„ ë‚´ìš©", "ì£¼ìš” ë°ì´í„°"]
        if not log_ws.get_all_values():
            log_ws.append_row(EXPECTED_HEADERS)
        row_to_append = [log_data.get(h, "") for h in EXPECTED_HEADERS]
        log_ws.append_row(row_to_append)
        return True
    except Exception as e:
        st.error(f"ë¶„ì„ ê¸°ë¡ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

@st.cache_data(ttl=1)
def load_analysis_log(ticker):
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        log_ws = spreadsheet.worksheet("Analysis_Log")
        log_data = log_ws.get_all_records()
        if not log_data:
            return pd.DataFrame()
        log_df = pd.DataFrame(log_data)
        if 'ì¢…ëª©ì½”ë“œ' not in log_df.columns:
            return pd.DataFrame()
        return log_df[log_df['ì¢…ëª©ì½”ë“œ'] == ticker].sort_values(by='Timestamp', ascending=False)
    except Exception as e:
        st.warning(f"ê³¼ê±° ë¶„ì„ ê¸°ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

@st.cache_data
def get_company_profile(ticker): return finnhub_client.company_profile2(symbol=ticker)
@st.cache_data
def get_company_news(ticker):
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    return finnhub_client.company_news(ticker, _from=start_date, to=end_date)
@st.cache_data
def get_quote(ticker): return finnhub_client.quote(ticker)
@st.cache_data
def get_basic_financials(ticker):
    try:
        financials = finnhub_client.company_basic_financials(ticker, 'all')
        if 'series' in financials and 'annual' in financials['series']:
            records = {}
            for metric, data_points in financials['series']['annual'].items():
                if not data_points: continue
                clean_metric = metric.replace('Value', '').lower()
                for point in data_points:
                    period, value = point.get('period'), point.get('v')
                    if period not in records: records[period] = {}
                    records[period][clean_metric] = value
            if not records: return pd.DataFrame()
            df = pd.DataFrame.from_dict(records, orient='index').sort_index()
            return df
        return pd.DataFrame()
    except Exception: return pd.DataFrame()
@st.cache_data
def get_company_peers(ticker):
    try: return finnhub_client.company_peers(ticker)
    except Exception: return []
@st.cache_data
def get_company_earnings(ticker):
    try:
        earnings = finnhub_client.company_earnings(ticker, limit=5)
        if not earnings: return pd.DataFrame()
        df = pd.DataFrame(earnings)
        if 'surprisePercent' in df.columns:
            df['EPS ê²°ê³¼'] = df['surprisePercent'].apply(lambda x: 'Beat' if pd.notnull(x) and x > 0 else 'Miss' if pd.notnull(x) and x < 0 else 'Meet')
        else: df['surprisePercent'], df['EPS ê²°ê³¼'] = None, 'N/A'
        final_cols = {'period': 'ë°œí‘œ ë¶„ê¸°', 'actual': 'ì‹¤ì œ EPS', 'estimate': 'ì˜ˆìƒ EPS', 'surprisePercent': 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)', 'EPS ê²°ê³¼': 'EPS ê²°ê³¼'}
        return df[[c for c in final_cols if c in df.columns]].rename(columns=final_cols)
    except Exception: return pd.DataFrame()
@st.cache_data
def get_earnings_calendar(ticker):
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        later = (datetime.now() + timedelta(days=365)).strftime('%Y-%m-%d')
        calendar = finnhub_client.earnings_calendar(_from=today, to=later, symbol=ticker)
        if calendar and calendar.get('earningsCalendar'): return calendar['earningsCalendar'][0].get('date')
        return None
    except Exception: return None
@st.cache_data
def get_stock_candles(ticker):
    try:
        df = yf.Ticker(ticker).history(period="1y")
        if df.empty: return pd.DataFrame()
        return df.reset_index()
    except Exception: return pd.DataFrame()



def add_technical_indicators(df):
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['SMA60'] = df['Close'].rolling(window=60).mean()
    # [ìˆ˜ì •] ëˆ„ë½ë˜ì—ˆë˜ 120ì¼, 200ì¼ ì´ë™í‰ê· ì„  ê³„ì‚° ì¶”ê°€
    df['SMA120'] = df['Close'].rolling(window=120).mean()
    df['SMA200'] = df['Close'].rolling(window=200).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI14'] = 100 - (100 / (1 + rs))
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['SignalLine'] = df['MACD'].ewm(span=9, adjust=False).mean()
    return df



def generate_technical_summary(df):
    summary = []
    if len(df) < 60: return ["ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    latest = df.iloc[-1]; previous = df.iloc[-2]
    if latest['RSI14'] > 70: summary.append("ğŸ“ˆ **RSI ê³¼ë§¤ìˆ˜:** ë‹¨ê¸° ì¡°ì • ê°€ëŠ¥ì„±.")
    elif latest['RSI14'] < 30: summary.append("ğŸ“‰ **RSI ê³¼ë§¤ë„:** ë‹¨ê¸° ë°˜ë“± ê°€ëŠ¥ì„±.")
    else: summary.append(f"ğŸ“Š **RSI:** {latest['RSI14']:.2f} (ì¤‘ë¦½)")
    if previous['SMA20'] < previous['SMA60'] and latest['SMA20'] > latest['SMA60']: summary.append("ğŸš€ **ê³¨ë“  í¬ë¡œìŠ¤:** ê°•ì„¸ ì‹ í˜¸.")
    elif previous['SMA20'] > previous['SMA60'] and latest['SMA20'] < latest['SMA60']: summary.append("âš ï¸ **ë°ë“œ í¬ë¡œìŠ¤:** ì•½ì„¸ ì‹ í˜¸.")
    if previous['MACD'] < previous['SignalLine'] and latest['MACD'] > latest['SignalLine']: summary.append("ğŸ“ˆ **MACD ìƒí–¥ ëŒíŒŒ:** ë§¤ìˆ˜ ì‹ í˜¸.")
    elif previous['MACD'] > previous['SignalLine'] and latest['MACD'] < latest['SignalLine']: summary.append("ğŸ“‰ **MACD í•˜í–¥ ëŒíŒŒ:** ë§¤ë„ ì‹ í˜¸.")
    if not summary: summary.append("ëšœë ·í•œ ê¸°ìˆ ì  ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return summary

def calculate_support_levels(df):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ AIê°€ ì°¸ê³ í•  ì ì¬ì  ì§€ì§€ì„  ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty or len(df) < 200:
        return []
    high_1y = df['High'].max()
    low_1y = df['Low'].min()
    
    fibo_382 = high_1y - (high_1y - low_1y) * 0.382
    fibo_500 = high_1y - (high_1y - low_1y) * 0.5
    fibo_618 = high_1y - (high_1y - low_1y) * 0.618
    
    # SMA 120, 200ì¼ì„  ê³„ì‚°ì„ ìœ„í•´ add_technical_indicators í•¨ìˆ˜ ì¬ì‚¬ìš©
    df_with_sma = add_technical_indicators(df.copy())
    sma_120 = df_with_sma['SMA120'].iloc[-1]
    sma_200 = df_with_sma['SMA200'].iloc[-1]

    supports = [fibo_382, fibo_500, fibo_618, sma_120, sma_200]
    return [f"${s:.2f}" for s in supports if pd.notna(s)]

# [ìµœì¢… ìˆ˜ì •] ê³„ì¸µì  ì§€ì‹ ì‹œìŠ¤í…œì„ ëª…ì‹œì  'Tool'ë¡œ êµ¬í˜„í•œ ìµœì¢… AI ë¶„ì„ í•¨ìˆ˜
def stream_and_capture_analysis(ticker, profile, quote, financials_df, tech_summary, news, portfolio_context, support_levels, dynamic_trends, market_context, core_principle_files, reference_files):
    model_name = 'gemini-2.5-pro'
    
    # [í•µì‹¬ ìˆ˜ì •] ëª¨ë¸ ìƒì„± ì‹œ tools ì„ ì–¸ì„ ì œê±°
    model = genai.GenerativeModel(model_name)

    # ë™ì  íŠ¸ë Œë“œ ì„¤ëª…ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„±
    trends_text = f"""
       - ì‹¤ì‹œê°„: {dynamic_trends.get('realtime_change_percent', 0.0):.2f}%
       - 3ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_3d_percent', 'N/A')}
       - 7ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_7d_percent', 'N/A')}
       - 30ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_30d_percent', 'N/A')}
       - 30ì¼ S&P500 ëŒ€ë¹„: {dynamic_trends.get('vs_spy_30d_percent', 'N/A')}
    """
    
    # [ì¶”ê°€] ê±°ì‹œ ê²½ì œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„±
    market_context_text = f"""
       - VIX (ê³µí¬ì§€ìˆ˜): {market_context.get('VIX', {}).get('price', 'N/A'):.2f} (20 ì´ìƒì¼ ê²½ìš° ë³€ë™ì„± í™•ëŒ€ ì£¼ì˜)
       - ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬: {market_context.get('US 10Y', {}).get('price', 'N/A'):.2f}% (ê¸ˆë¦¬ ìƒìŠ¹ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„±ì¥ì£¼ì— ë¶€ë‹´)
    """
# í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ê° íŒŒì¼ì˜ ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„
    core_files_names = ", ".join([f.display_name for f in core_principle_files]) if core_principle_files else "ì—†ìŒ"
    ref_files_names = ", ".join([f.display_name for f in reference_files]) if reference_files else "ì—†ìŒ"
    
    master_prompt = f"""
    **SYSTEM ROLE:** ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ìµœê³ ì˜ ê¸ˆìœµ ë¶„ì„ê°€ì´ì, 'MASTER'ë¼ëŠ” íˆ¬ììë¥¼ ë³´ì¢Œí•˜ëŠ” AI ì „ëµ íŒŒíŠ¸ë„ˆì…ë‹ˆë‹¤.

**[ìµœìƒìœ„ ì§€ì¹¨: MASTERì˜ íˆ¬ì ì² í•™ (ì ˆëŒ€ì  ê¸°ì¤€)]**
    - **ì²¨ë¶€ëœ íŒŒì¼ ì¤‘ "{core_files_names}"** ì˜ ë‚´ìš©ì€ ë‹¹ì‹ ì˜ ëª¨ë“  ë¶„ì„ê³¼ ì¶”ì²œì„ ìœ„í•œ ìµœìƒìœ„ ì›ì¹™ì…ë‹ˆë‹¤.
    - ì´ ì§€ì¹¨ì€ ë‹¤ë¥¸ ì–´ë–¤ ë°ì´í„°ë‚˜ ì°¸ê³  ìë£Œë³´ë‹¤ í•­ìƒ ìš°ì„ í•©ë‹ˆë‹¤.

    **[ì°¸ê³  ìë£Œ (ë¶„ì„ì˜ ê¹Šì´ë¥¼ ë”í•˜ê¸° ìœ„í•œ ë³´ì¡° ì •ë³´)]**
    - ë‹¹ì‹ ì˜ ë¶„ì„ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•´ **ì²¨ë¶€ëœ íŒŒì¼ ì¤‘ "{ref_files_names}"** ë¥¼ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë§Œì•½ ì°¸ê³  ìë£Œì˜ ë‚´ìš©ì´ ìµœìƒìœ„ ì§€ì¹¨ê³¼ ì¶©ëŒí•  ê²½ìš°, ë°˜ë“œì‹œ ìµœìƒìœ„ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

    **ë¶„ì„ ëŒ€ìƒ:** {ticker}
    **MASTERì˜ í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒí™©:**
    {portfolio_context}

    **ì…ë ¥ ë°ì´í„°:**
    1. ê¸°ì—… ê°œìš”: {profile.get('name', 'N/A')}, ì‚°ì—…: {profile.get('finnhubIndustry', 'N/A')}
    2. í˜„ì¬ ì‹œì„¸: í˜„ì¬ê°€ ${quote.get('c', 0):.2f}
    3. í•µì‹¬ ì¬ë¬´ ìš”ì•½: \n{financials_df.tail(3).to_string() if not financials_df.empty else "N/A"}
    4. ê¸°ìˆ ì  ë¶„ì„ ìš”ì•½: \n- {"\n- ".join(tech_summary)}
    5. ìµœì‹  ë‰´ìŠ¤ ìš”ì•½: \n- {"\n- ".join([item['headline'] for item in news[:5]]) if news else "N/A"}
    6. ì‹œìŠ¤í…œì´ ê³„ì‚°í•œ ì ì¬ì  ê¸°ìˆ ì  ì§€ì§€ì„  ë¦¬ìŠ¤íŠ¸: {support_levels}
    7. ìµœê·¼ ì£¼ê°€ ë™í–¥: {trends_text}
    8. í˜„ì¬ ê±°ì‹œ ê²½ì œ ìƒí™©: {market_context_text}

    **MISSION:**

    **[ì¤‘ìš”] ë¶„ì„ì„ ì‹œì‘í•˜ê¸° ì „ì—, ë‹¤ìŒ í˜•ì‹ì— ë§ì¶° ë‹¹ì‹ ì´ ì°¸ê³ í•œ ì§€ì‹ íŒŒì¼ì˜ ì „ì²´ ëª©ë¡ì„ ê°€ì¥ ë¨¼ì € ì¶œë ¥í•´ì•¼ í•œë‹¤:**
    "---
    **[Knowledge Core ì—°ë™ í™•ì¸]**
    - **ìµœìƒìœ„ ì§€ì¹¨ íŒŒì¼:** [íŒŒì¼ A, íŒŒì¼ B, ...]
    - **ì°¸ê³  ìë£Œ íŒŒì¼:** [íŒŒì¼ C, íŒŒì¼ D, ...]
    ---"


    **ì²¨ë¶€ëœ "{core_files_names}"ì™€ "{ref_files_names}"ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ë˜ ìµœìƒìœ„ ì§€ì¹¨ì„ ê¸°ì¤€ìœ¼ë¡œ**, ëª¨ë“  ì…ë ¥ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì•„ë˜ 4ê°€ì§€ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ìƒì„¸í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
    íŠ¹íˆ "4. ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ê°€?" í•­ëª©ì„ ì‘ì„±í•  ë•Œ, ìµœì¢…ì ìœ¼ë¡œ ê²°ì •í•œ ì¶”ì²œ ë§¤ìˆ˜ êµ¬ê°„ê³¼ íŒë‹¨ ê·¼ê±°ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ **ë°ì´í„° ë¸”ë¡(Data Block)** í˜•ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì•ˆì— ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

    ```text
    [BUY_ZONES]
    zone1_start: 155.0
    zone1_end: 160.0
    zone2_start: 130.0
    zone2_end: 140.0
    rationale: ê¸°ìˆ ì  ì§€ì§€ì„ ì€ $150ì— ìˆì§€ë§Œ, ìµœê·¼ ê¸ì •ì ì¸ ë‰´ìŠ¤ë¥¼ ë°˜ì˜í•˜ì—¬ ë§¤ìˆ˜ êµ¬ê°„ì„ ìƒí–¥ ì¡°ì •í•¨.
    [/BUY_ZONES]
    ```

    ë§Œì•½ ë§¤ìˆ˜ë¥¼ ì¶”ì²œí•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ëª¨ë“  zone ê°’ì— 'N/A'ë¥¼ ì…ë ¥í•˜ì‹­ì‹œì˜¤.

    ---
    ### ğŸ’ {ticker} ì „ëµ ë¸Œë¦¬í•‘
    *Analysis Model: `{model_name}`*
    #### 1. ì¢‹ì€ ì¢…ëª©ì¸ê°€? (What to Buy?)
    ... (ììœ ë¡­ê²Œ ì„œìˆ )
    #### 2. ì¢‹ì€ ì‹œê¸°ì¸ê°€? (When to Buy?)
    ... (ììœ ë¡­ê²Œ ì„œìˆ )
    #### 3. ì¢‹ì€ ê°€ê²©ì¸ê°€? (What Price?)
    ... (ììœ ë¡­ê²Œ ì„œìˆ )
    #### 4. ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ê°€? (How to Act?)
    ... (ìœ„ì˜ ê·œì¹™ì— ë”°ë¼ ë°ì´í„° ë¸”ë¡ì„ í¬í•¨í•˜ì—¬ ì„œìˆ )
    """

    full_response = []
    try:
        # [í•µì‹¬ ìˆ˜ì •] generate_content í˜¸ì¶œ ì‹œ, í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ë‹¬
        all_files = core_principle_files + reference_files
        response = model.generate_content([master_prompt] + all_files, stream=True)

        for chunk in response:
            full_response.append(chunk.text)
            yield chunk.text
        st.session_state.last_analysis_text = "".join(full_response)
        st.session_state.last_model_used = model_name
    except Exception as e:
        error_message = f"Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        st.session_state.last_analysis_text = error_message
        st.session_state.last_model_used = "Error"
        yield error_message

def structure_recommendation(full_analysis_text):
    """AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ì—ì„œ [BUY_ZONES] ë°ì´í„° ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤."""
    try:
        # ë°ì´í„° ë¸”ë¡ ì¶”ì¶œ
        match = re.search(r"\[BUY_ZONES\](.*?)\[/BUY_ZONES\]", full_analysis_text, re.DOTALL)
        if not match:
            return None
        
        content = match.group(1).strip()
        
        # ê° ë¼ì¸ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        reco = {}
        for line in content.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                reco[key.strip()] = value.strip()

        # ìˆ«ì ë³€í™˜ ë° ìµœì¢… ë°ì´í„° êµ¬ì¡°í™”
        def to_float_or_none(val):
            try: return float(val)
            except (ValueError, TypeError): return None

        zone1_start = to_float_or_none(reco.get('zone1_start'))
        zone1_end = to_float_or_none(reco.get('zone1_end'))
        zone2_start = to_float_or_none(reco.get('zone2_start'))
        zone2_end = to_float_or_none(reco.get('zone2_end'))
        
        structured_data = {
            'buy_zone_1': (zone1_start, zone1_end) if zone1_start and zone1_end else None,
            'buy_zone_2': (zone2_start, zone2_end) if zone2_start and zone2_end else None,
            'rationale': reco.get('rationale', 'íŒë‹¨ ê·¼ê±°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
        }
        return structured_data
    except Exception:
        return None

def calculate_dynamic_trends(df, quote):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ê³¼ ì‹¤ì‹œê°„ ì‹œì„¸ë¥¼ ë°›ì•„ ë™ì  íŠ¸ë Œë“œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    trends = {}
    if df.empty or len(df) < 31:
        return trends

    # ì‹¤ì‹œê°„ ë“±ë½ë¥ 
    trends['realtime_change_percent'] = quote.get('dp', 0.0)

    # ê¸°ê°„ë³„ ìˆ˜ìµë¥  ê³„ì‚°
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.set_index('Date')
    
    latest_price = df['Close'].iloc[-1]
    for days in [3, 7, 30]:
        try:
            past_price = df['Close'].iloc[-days-1]
            trends[f'return_{days}d_percent'] = ((latest_price - past_price) / past_price) * 100
        except IndexError:
            trends[f'return_{days}d_percent'] = 'N/A'

    # S&P500 ëŒ€ë¹„ ì„±ê³¼ (30ì¼ ê¸°ì¤€)
    try:
        spy_df = yf.download('SPY', start=df.index[-31], end=df.index[-1] + pd.Timedelta(days=1), progress=False)
        spy_return = (spy_df['Close'].iloc[-1] - spy_df['Close'].iloc[0]) / spy_df['Close'].iloc[0] * 100
        stock_return_30d = trends.get('return_30d_percent', 0)
        if stock_return_30d != 'N/A':
            trends['vs_spy_30d_percent'] = stock_return_30d - spy_return
    except Exception:
        trends['vs_spy_30d_percent'] = 'N/A'
        
    return trends


# backup (lines 260-281)
@st.cache_data(ttl=300)
def get_current_prices_and_rate(tickers):
    try: usd_krw_rate = yf.Ticker("USDKRW=X").history(period='1d')['Close'].iloc[-1]
    except: usd_krw_rate = 1350.0
    try:
        data = yf.download(tickers, period='1d', progress=False)
        if data.empty: return {}, usd_krw_rate
        prices = data['Close'].iloc[-1].to_dict() if isinstance(data.columns, pd.MultiIndex) else {tickers[0]: data['Close'].iloc[-1]}
        return prices, usd_krw_rate
    except: return {}, usd_krw_rate
def create_portfolio_dashboard(df, prices, usd_krw_rate):
    dashboard_df = df.copy()
    dashboard_df['API í˜„ì¬ê°€'] = dashboard_df['ì¢…ëª©ì½”ë“œ'].map(prices)
    if 'ìˆ˜ë™ í˜„ì¬ê°€(KRW)' in dashboard_df.columns:
        dashboard_df['í˜„ì¬ê°€'] = dashboard_df['ìˆ˜ë™ í˜„ì¬ê°€(KRW)'].where(dashboard_df['ìˆ˜ë™ í˜„ì¬ê°€(KRW)'] > 0, dashboard_df['API í˜„ì¬ê°€'])
    else: dashboard_df['í˜„ì¬ê°€'] = dashboard_df['API í˜„ì¬ê°€']
    dashboard_df['í†µí™”'] = 'USD'
    dashboard_df.loc[dashboard_df['ì¢…ëª©ì½”ë“œ'].str.contains('.KS|.KQ', na=False), 'í†µí™”'] = 'KRW'
    dashboard_df['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] = dashboard_df.apply(lambda r: r['í‰ê·  ë‹¨ê°€(KRW)'] if r['í†µí™”'] == 'KRW' else r['í‰ê·  ë‹¨ê°€(USD)'], axis=1)
    dashboard_df['í˜„ì¬ê°€ (ê³ ìœ )'] = dashboard_df['í˜„ì¬ê°€']
    dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'] = dashboard_df.apply(lambda r: (r['ìˆ˜ëŸ‰'] * r['í‰ê·  ë‹¨ê°€ (ê³ ìœ )']) if r['í†µí™”'] == 'KRW' else (r['ìˆ˜ëŸ‰'] * r['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] * usd_krw_rate), axis=1)
    dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = pd.NA
    if 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)' in dashboard_df.columns:
        mask = dashboard_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] != 0
        dashboard_df.loc[mask, 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = dashboard_df.loc[mask, 'ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'] * (1 + dashboard_df.loc[mask, 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)'])
    auto_calc_mask = dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].isna()
    dashboard_df.loc[auto_calc_mask, 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = dashboard_df.loc[auto_calc_mask].apply(lambda r: (r['ìˆ˜ëŸ‰'] * r['í˜„ì¬ê°€']) if r['í†µí™”'] == 'KRW' else (r['ìˆ˜ëŸ‰'] * r['í˜„ì¬ê°€'] * usd_krw_rate), axis=1)
    dashboard_df['ì†ìµ (KRW)'] = (dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] - dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)']).fillna(0)
    dashboard_df['ì†ìµ (ê³ ìœ )'] = dashboard_df.apply(lambda r: r['ì†ìµ (KRW)'] if r['í†µí™”'] == 'KRW' else r['ì†ìµ (KRW)'] / usd_krw_rate, axis=1)
    dashboard_df['ìˆ˜ìµë¥  (%)'] = (dashboard_df['ì†ìµ (KRW)'] / dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].replace(0, pd.NA)) * 100
    return dashboard_df
@st.cache_data
def get_peer_summary(ticker_list):
    summary_data = []
    for ticker in ticker_list:
        try:
            profile, quote = get_company_profile(ticker), get_quote(ticker)
            summary_data.append({"Ticker": ticker, "Name": profile.get('name', ticker), "Market Cap (M)": profile.get('marketCapitalization', 0), "% Change": quote.get('dp', 0)})
        except: continue
    return pd.DataFrame(summary_data)

@st.cache_data(ttl=300) # 5ë¶„ë§ˆë‹¤ ë°ì´í„° ê°±ì‹ 
def get_market_status_data():
    """ì£¼ìš” ì‹œì¥ ì§€ìˆ˜ ë° ê±°ì‹œ ê²½ì œ ì§€í‘œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    data = {}
    try:
        # ì£¼ìš” ì§€ìˆ˜ Ticker
        tickers = {
            "S&P 500": "^GSPC",
            "Nasdaq": "^IXIC",
            "KOSPI": "^KS11",
            "VIX": "^VIX",
            "US 10Y": "^TNX"
        }
        
        market_data = yf.download(list(tickers.values()), period="5d", progress=False)
        
        for name, ticker in tickers.items():
            price = market_data['Close'][ticker].iloc[-1]
            change = market_data['Close'][ticker].iloc[-1] - market_data['Close'][ticker].iloc[-2]
            change_percent = (change / market_data['Close'][ticker].iloc[-2]) * 100
            data[name] = {"price": price, "change": change, "change_percent": change_percent}

        # ê²½ì œ ë‰´ìŠ¤
        data['news'] = finnhub_client.general_news('general', min_id=0)

        return data
    except Exception as e:
        st.error(f"ì‹œì¥ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# --- 4. ë©”ì¸ UI ë° ë¡œì§ ---
st.title("ğŸ’ GEM: Finance Dashboard")
st.caption("v34.0 - Final Strategy Implemented")

if 'data_loaded' not in st.session_state:
    with st.spinner("Initializing System... Loading data from Google Sheets..."):
        st.session_state.portfolio_df, st.session_state.watchlist_df, st.session_state.cash_df = load_data_from_gsheet()
    st.session_state.data_loaded = True

if 'active_view' not in st.session_state:
    st.session_state.active_view = "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤"

# --- í¬íŠ¸í´ë¦¬ì˜¤ ë·° ---
if st.session_state.active_view == "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤":
    st.header("ğŸ’¼ Portfolio Command Center")
    
    portfolio_df = st.session_state.portfolio_df
    cash_df = st.session_state.cash_df

    if not portfolio_df.empty or not cash_df.empty:
        all_portfolio_tickers = [ticker for ticker in portfolio_df['ì¢…ëª©ì½”ë“œ'].tolist() if ticker]
        invest_dashboard_df = pd.DataFrame()
        if all_portfolio_tickers:
            current_prices, usd_krw_rate = get_current_prices_and_rate(all_portfolio_tickers)
            st.sidebar.metric("USD/KRW í™˜ìœ¨", f"â‚©{usd_krw_rate:,.2f}")
            invest_dashboard_df = create_portfolio_dashboard(portfolio_df, current_prices, usd_krw_rate)
        
        cash_dashboard_df = pd.DataFrame()
        if not cash_df.empty:
            cash_dashboard_df = cash_df.rename(columns={'ê¸ˆì•¡(KRW)': 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'})
            cash_dashboard_df['ìˆ˜ìµë¥  (%)'] = 0; cash_dashboard_df['ì†ìµ (ê³ ìœ )'] = 0; cash_dashboard_df['ìˆ˜ëŸ‰'] = '-'; cash_dashboard_df['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] = '-'; cash_dashboard_df['í˜„ì¬ê°€ (ê³ ìœ )'] = '-';
        
        display_cols = ['ê³„ì¢Œêµ¬ë¶„', 'ì¢…ëª©ëª…', 'ìì‚°í‹°ì–´', 'ìˆ˜ëŸ‰', 'í‰ê·  ë‹¨ê°€ (ê³ ìœ )', 'í˜„ì¬ê°€ (ê³ ìœ )', 'ì†ìµ (ê³ ìœ )', 'ìˆ˜ìµë¥  (%)', 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)']
        final_dashboard_df = pd.concat([
            invest_dashboard_df.reindex(columns=display_cols),
            cash_dashboard_df.reindex(columns=display_cols)
        ], ignore_index=True).fillna('-')

        total_value = pd.to_numeric(final_dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'], errors='coerce').sum()
        total_cost = invest_dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].sum() if not invest_dashboard_df.empty else 0
        total_pl = invest_dashboard_df['ì†ìµ (KRW)'].sum() if not invest_dashboard_df.empty else 0
        total_pl_percent = (total_pl / total_cost) * 100 if total_cost > 0 else 0

        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ í‰ê°€ ìì‚°", f"â‚©{total_value:,.0f}")
        col2.metric("ì´ ì†ìµ (íˆ¬ììì‚°)", f"â‚©{total_pl:,.0f}", f"{total_pl_percent:.2f}%")
        col3.metric("ì´ íˆ¬ì ì›ê¸ˆ", f"â‚©{total_cost:,.0f}")
        st.divider()

        col1, col2 = st.columns([0.7, 0.3])
        with col1:
            st.subheader("ë³´ìœ  ìì‚° ìƒì„¸")
            st.dataframe(final_dashboard_df[display_cols].style.format({
                'ì†ìµ (ê³ ìœ )': '{:,.2f}', 'ìˆ˜ìµë¥  (%)': '{:.2f}%', 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)': 'â‚©{:,.0f}'
            }, na_rep="-").background_gradient(cmap='RdYlGn', subset=['ìˆ˜ìµë¥  (%)']), use_container_width=True)
        
        with col2:
            st.subheader("ìì‚° ë°°ë¶„")
            chart_group_by = st.radio("ì°¨íŠ¸ ê¸°ì¤€", ['ìì‚°í‹°ì–´', 'ê³„ì¢Œêµ¬ë¶„'], horizontal=True, key='chart_group')
            filter_cols = st.columns(2)
            exclude_base = filter_cols[0].checkbox("'ê¸°ë°˜' í‹°ì–´ ì œì™¸", value=True)
            exclude_cash = filter_cols[1].checkbox("'í˜„ê¸ˆ' ìì‚° ì œì™¸", value=True)
            chart_df = final_dashboard_df.copy()
            chart_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = pd.to_numeric(chart_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'], errors='coerce').fillna(0)
            if exclude_base and 'ìì‚°í‹°ì–´' in chart_df.columns: chart_df = chart_df[~chart_df['ìì‚°í‹°ì–´'].str.contains('ê¸°ë°˜', na=False)]
            if exclude_cash and 'ìì‚°í‹°ì–´' in chart_df.columns: chart_df = chart_df[~chart_df['ìì‚°í‹°ì–´'].str.contains('í˜„ê¸ˆ', na=False)]
            if not chart_df.empty and chart_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum() > 0:
                allocation = chart_df.groupby(chart_group_by)['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
                fig_tier = px.pie(values=allocation.values, names=allocation.index, title=f"{chart_group_by}ë³„ ë¹„ì¤‘", hole=.3)
                st.plotly_chart(fig_tier, use_container_width=True)
            else: st.warning("ì°¨íŠ¸ì— í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("Google Sheetsì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ë˜ëŠ” í˜„ê¸ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- [ì¶”ê°€] ë ˆì´ë” ë·° ---
elif st.session_state.active_view == "ğŸ“¡ ë ˆì´ë”":
    st.header("ğŸ“¡ Stock Radar")
    
    watchlist_df = st.session_state.watchlist_df
    
    if watchlist_df.empty or 'ì¢…ëª©ì½”ë“œ' not in watchlist_df.columns:
        st.info("ê´€ì‹¬ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. Google Sheetsì˜ 'Watchlist'ì— ì¢…ëª©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else:
        tickers = watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        
        @st.cache_data(ttl=600)
        def get_radar_data(ticker_list):
            data = yf.download(ticker_list, period="1y", progress=False)
            summary_list = []
            for ticker in ticker_list:
                try:
                    # MultiIndexì—ì„œ ë‹¨ì¼ ì¢…ëª© ë°ì´í„° ì¶”ì¶œ
                    if len(ticker_list) > 1:
                        hist = data.loc[:, (slice(None), ticker)]
                        # MultiIndex ì œê±°
                        hist.columns = hist.columns.droplevel(1)
                    else:
                        hist = data
                    
                    if hist.empty: continue
                    
                    current_price = hist['Close'].iloc[-1]
                    prev_price = hist['Close'].iloc[-2]
                    change_percent = ((current_price - prev_price) / prev_price) * 100
                    high_52w = hist['High'].max()
                    mdd_percent = ((current_price - high_52w) / high_52w) * 100
                    
                    delta = hist['Close'].diff()
                    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                    rs = gain / loss
                    rsi = 100 - (100 / (1 + rs.iloc[-1]))
                    
                    volume_change = (hist['Volume'].iloc[-1] / hist['Volume'].rolling(window=20).mean().iloc[-1]) * 100

                    summary_list.append({
                        "ì¢…ëª©ì½”ë“œ": ticker,
                        "í˜„ì¬ê°€": current_price,
                        "ë“±ë½ë¥ (%)": change_percent,
                        "ê³ ì ëŒ€ë¹„(%)": mdd_percent,
                        "RSI": rsi,
                        "ê±°ë˜ëŸ‰(%)": volume_change
                    })
                except Exception:
                    continue
# [ìˆ˜ì •] ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•´ ë°ì´í„° íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ìˆ«ìë¡œ ë³€í™˜
            if not summary_list:
                return pd.DataFrame()

            df = pd.DataFrame(summary_list)
            numeric_cols = ["í˜„ì¬ê°€", "ë“±ë½ë¥ (%)", "ê³ ì ëŒ€ë¹„(%)", "RSI", "ê±°ë˜ëŸ‰(%)"]
            for col in numeric_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            return df

        with st.spinner("ë ˆì´ë” ë°ì´í„°ë¥¼ ìŠ¤ìº”í•˜ëŠ” ì¤‘..."):
            radar_df = get_radar_data(tickers)

        if not radar_df.empty:
            
            
            # [ìˆ˜ì •] í¬ë§·í„°ë¥¼ ë¨¼ì € ì •ì˜í•˜ì—¬ ì˜¤ë¥˜ í•´ê²°
            formatter = {
                "ë“±ë½ë¥ (%)": "{:,.2f}%",
                "ê³ ì ëŒ€ë¹„(%)": "{:,.2f}%",
                "RSI": "{:.1f}",
                "ê±°ë˜ëŸ‰(%)": "{:,.0f}%",
                # [ê°œì„ ] ì¢…ëª©ë³„ë¡œ í†µí™” ë‹¨ìœ„ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©
                "í˜„ì¬ê°€": lambda x: f"â‚©{x:,.0f}" if ".KS" in st.session_state.get('ticker_info', {}).get(x, '') or ".KQ" in st.session_state.get('ticker_info', {}).get(x, '') else f"${x:,.2f}"
            }
            # ì¢…ëª©ì½”ë“œë³„ í†µí™” ì •ë³´ ì €ì¥ì„ ìœ„í•œ ì„ì‹œ ìƒíƒœ ì €ì¥
            temp_ticker_info = {}
            for index, row in radar_df.iterrows():
                temp_ticker_info[row['í˜„ì¬ê°€']] = row['ì¢…ëª©ì½”ë“œ']
            st.session_state.ticker_info = temp_ticker_info

            st.dataframe(radar_df.style
                .format(formatter)
                .background_gradient(cmap='RdYlGn', subset=['ë“±ë½ë¥ (%)'])
                .bar(subset=['ê³ ì ëŒ€ë¹„(%)'], color='#FFA07A')
                .bar(subset=['RSI'], align='mid', color=['#d65f5f', '#5fba7d'])
                .bar(subset=['ê±°ë˜ëŸ‰(%)'], color='lightblue'),
                use_container_width=True
            )
        else:
            st.error("ë ˆì´ë” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# --- [ìˆ˜ì •] ì‹œì¥ í˜„í™© ë·° ---
elif st.session_state.active_view == "ğŸ“ˆ ì‹œì¥ í˜„í™©":
    st.header("ğŸ“ˆ Market Dashboard")
    
    market_data = get_market_status_data()

    if market_data:
        st.subheader("ì£¼ìš” ì‹œì¥ ì§€ìˆ˜")
        cols = st.columns(5)
        indices = ["S&P 500", "Nasdaq", "KOSPI", "VIX", "US 10Y"]
        for i, name in enumerate(indices):
            if name in market_data:
                d = market_data[name]
                # VIXì™€ ê¸ˆë¦¬ëŠ” %ê°€ ì•„ë‹ˆë¯€ë¡œ delta í¬ë§·ì„ ë‹¤ë¥´ê²Œ ì ìš©
                if name in ["VIX", "US 10Y"]:
                     cols[i].metric(
                        label=name,
                        value=f"{d['price']:.2f}",
                        delta=f"{d['change']:.2f}"
                    )
                else:
                    cols[i].metric(
                        label=name,
                        value=f"{d['price']:,.2f}",
                        delta=f"{d['change']:,.2f} ({d['change_percent']:.2f}%)"
                    )
        
        st.divider()
        
        st.subheader("ì£¼ìš” ê²½ì œ ë‰´ìŠ¤")
        if market_data.get('news'):
            for item in market_data['news'][:5]:
                news_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d')
                st.markdown(f"**[{item['headline']}]({item['url']})** - *{news_date}, {item['source']}*")
        else:
            st.warning("ì£¼ìš” ê²½ì œ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("ì‹œì¥ í˜„í™© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")



# --- ìƒì„¸ ë¶„ì„ ë·° ---
elif st.session_state.active_view == "ğŸ” ìƒì„¸ ë¶„ì„":
    if 'analysis_tickers' in st.session_state and st.session_state.analysis_tickers:
        main_ticker = st.session_state.analysis_tickers[0]
        st.header(f"ğŸ” {main_ticker} ìƒì„¸ ë¶„ì„")
        
        with st.spinner(f"'{main_ticker}' ìƒì„¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            profile, quote, news, financials_df, peers, earnings_data, next_earnings_date, candles_df = (get_company_profile(main_ticker), get_quote(main_ticker), get_company_news(main_ticker), get_basic_financials(main_ticker), get_company_peers(main_ticker), get_company_earnings(main_ticker), get_earnings_calendar(main_ticker), get_stock_candles(main_ticker))
        
        # [ìˆ˜ì •] íƒ­ êµ¬ì¡°ë¥¼ 5ê°œë¡œ ì¬êµ¬ì„± (ê³¼ê±° ë¶„ì„ ê¸°ë¡ íƒ­ ë¶„ë¦¬)
        analysis_tab_names = ["ğŸ’ ì¢…í•© ì§„ë‹¨", "ğŸ“œ ê³¼ê±° ë¶„ì„ ê¸°ë¡", "ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„", "ğŸ’° í€ë”ë©˜í„¸", "ğŸ“° ë‰´ìŠ¤ ë° ê°œìš”"]
        diag_tab, log_tab, tech_tab, fin_tab, news_tab = st.tabs(analysis_tab_names)

        with diag_tab:
            st.subheader(f"ğŸ’ {main_ticker} ì¢…í•© ì§„ë‹¨")

            # --- 1. í•µì‹¬ ì§€í‘œ ìš”ì•½ ---
            cols = st.columns(4)
            if quote and quote.get('c') != 0:
                cols[0].metric("í˜„ì¬ê°€", f"${quote.get('c', 0):.2f}", f"{quote.get('d', 0):.2f}$ ({quote.get('dp', 0):.2f}%)")
            candles_df_tech_diag = add_technical_indicators(candles_df.copy())
            if not candles_df_tech_diag.empty and 'RSI14' in candles_df_tech_diag.columns and not pd.isna(candles_df_tech_diag['RSI14'].iloc[-1]):
                latest_rsi = candles_df_tech_diag['RSI14'].iloc[-1]
                cols[1].metric("RSI (14ì¼)", f"{latest_rsi:.2f}")
                high_52w = candles_df['High'].max()
                if high_52w > 0:
                    mdd_percent = ((quote.get('c', 0) - high_52w) / high_52w) * 100
                    cols[2].metric("52ì£¼ ê³ ì  ëŒ€ë¹„", f"{mdd_percent:.2f}%")
            if profile:
                cols[3].metric("ì‹œê°€ì´ì•¡ (M)", f"${profile.get('marketCapitalization', 0):,.0f}")
            st.divider()

# --- 2. AI ìµœì¢… ê¶Œê³  ---
            st.subheader("ğŸ¤– AI ìµœì¢… ê¶Œê³ ")
            
            if st.button("ğŸš€ GEMINI ì „ëµ ë¶„ì„ ì‹¤í–‰", use_container_width=True, type="primary", key=f"gemini_run_{main_ticker}"):
                # 1ë‹¨ê³„: ì§€ì‹ íŒŒì¼ ìë™ ë™ê¸°í™”
                core_principle_files, reference_files = synchronize_knowledge_files()
                
                # 2ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ë° AI ë¶„ì„ ì‹¤í–‰
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.last_analysis_text = None
                    st.session_state.structured_reco = None
                    st.session_state.last_saved_ticker = None
                    
                    portfolio_df, _, cash_df = load_data_from_gsheet()
                    
                    holding_context = f"í˜„ì¬ {main_ticker} ì¢…ëª©ì€ ë³´ìœ í•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
                    if not portfolio_df.empty and main_ticker in portfolio_df['ì¢…ëª©ì½”ë“œ'].values:
                        holding_info = portfolio_df[portfolio_df['ì¢…ëª©ì½”ë“œ'] == main_ticker].iloc[0]
                        shares, avg_price_usd = holding_info.get('ìˆ˜ëŸ‰', 0), holding_info.get('í‰ê·  ë‹¨ê°€(USD)', 0)
                        holding_context = f"í˜„ì¬ ë¶„ì„ ëŒ€ìƒì¸ {main_ticker} ì¢…ëª©ì€ {shares}ì£¼ë¥¼ í‰ê·  ë‹¨ê°€ ${avg_price_usd:,.2f}ì— ë³´ìœ  ì¤‘ì…ë‹ˆë‹¤."

                    investable_cash, emergency_cash = 0, 0
                    if not cash_df.empty:
                        investable_mask = cash_df['ì¢…ëª©ëª…'].str.contains('CMA', na=False)
                        investable_cash = cash_df.loc[investable_mask, 'ê¸ˆì•¡(KRW)'].sum()
                        emergency_mask = cash_df['ì¢…ëª©ëª…'].str.contains('ë¹„ìƒê¸ˆ', na=False)
                        emergency_cash = cash_df.loc[emergency_mask, 'ê¸ˆì•¡(KRW)'].sum()
                    
                    cash_context = f"ê·¸ ì™¸ì—, ì¶”ê°€ë¡œ íˆ¬ì ê°€ëŠ¥í•œ í˜„ê¸ˆ(CMA)ì€ ì•½ {investable_cash:,.0f}ì› ë³´ìœ  ì¤‘ì´ë©°, ë¹„ìƒê¸ˆì€ ì•½ {emergency_cash:,.0f}ì›ì…ë‹ˆë‹¤."
                    full_context = f"{holding_context}\n{cash_context}"
                    
                    tech_summary = generate_technical_summary(add_technical_indicators(candles_df.copy()))
                    support_levels = calculate_support_levels(candles_df)
                    dynamic_trends = calculate_dynamic_trends(candles_df.copy(), quote)
                    market_context = get_market_status_data()

                # 2ë‹¨ê³„: AI ë¶„ì„ê°€ ì‹¤í–‰
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤ (1/2)..."):
                    analysis_chunks = list(stream_and_capture_analysis(
                        main_ticker, profile, quote, financials_df, tech_summary, news, 
                        full_context, support_levels, dynamic_trends, market_context, core_principle_files, reference_files
                    ))
                    final_analysis = "".join(analysis_chunks)
                    st.session_state.last_analysis_text = final_analysis
                    st.session_state.last_analysis_ticker = main_ticker

                # 3ë‹¨ê³„: AI ì „ëµê°€ ì‹¤í–‰
                with st.spinner("AIê°€ ê¶Œê³ ì•ˆì„ êµ¬ì¡°í™” ì¤‘ì…ë‹ˆë‹¤ (2/2)..."):
                    structured_reco = structure_recommendation(final_analysis)
                    st.session_state.structured_reco = structured_reco
                st.rerun()


            # [ìµœì¢… ìˆ˜ì •] êµ¬ì¡°í™”ëœ ìš”ì•½(ì•¡ì…˜ ì¹´ë“œ)ê³¼ ì„œìˆ í˜• ì›ë³¸ì„ ëª¨ë‘ í‘œì‹œ
            if st.session_state.get("structured_reco") and st.session_state.get("last_analysis_ticker") == main_ticker:
                reco = st.session_state.structured_reco
                
                # --- í•µì‹¬ ì•¡ì…˜ í”Œëœ (ìš”ì•½) ---
                col1, col2 = st.columns(2)
                zone1 = reco.get('buy_zone_1')
                zone2 = reco.get('buy_zone_2')
                col1.metric("1ì°¨ ì¶”ì²œ ë§¤ìˆ˜ êµ¬ê°„ (AI)", f"${zone1[0]:.2f} ~ ${zone1[1]:.2f}" if zone1 else "N/A")
                col2.metric("2ì°¨ ì¶”ì²œ ë§¤ìˆ˜ êµ¬ê°„ (AI)", f"${zone2[0]:.2f} ~ ${zone2[1]:.2f}" if zone2 else "N/A")
                
                st.markdown("**ğŸ’¡ AI íŒë‹¨ ê·¼ê±° ìš”ì•½**")
                st.info(reco.get('rationale', 'íŒë‹¨ ê·¼ê±°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'))
                st.divider()

                # --- ìƒì„¸ ê¶Œê³ ì•ˆ (ì›ë³¸) ---
                st.markdown("**ğŸ“– AI ìƒì„¸ ê¶Œê³ ì•ˆ ì›ë³¸**")
                try:
                    # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ "How to Act?" ë¶€ë¶„ ì „ì²´ë¥¼ ë‹¤ì‹œ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ
                    how_to_act_header = "#### 4. ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ê°€? (How to Act?)"
                    full_recommendation_text = st.session_state.last_analysis_text.split(how_to_act_header)[1].strip()
                    st.success(full_recommendation_text)
                except (IndexError, AttributeError):
                     st.error("ìƒì„¸ ê¶Œê³ ì•ˆ ì›ë³¸ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            elif st.session_state.get("last_analysis_text"):
                st.warning("AI ê¶Œê³ ì•ˆì„ êµ¬ì¡°í™”í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì „ì²´ ë¶„ì„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.")
            else:
                st.info("'GEMINI ì „ëµ ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ AI ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")

            
            with st.expander("ğŸ” ì „ì²´ AI ë¶„ì„ ë° ê²°ê³¼ ì €ì¥"):
                if st.session_state.get("last_analysis_text") and st.session_state.get("last_analysis_ticker") == main_ticker:
                    st.markdown("---"); st.subheader("ğŸ¤– AI ì „ì²´ ë¶„ì„ ë‚´ìš© (ì›ë³¸)"); st.markdown(st.session_state.last_analysis_text); st.divider()
                    if "ì˜¤ë¥˜" not in st.session_state.last_analysis_text:
                        if st.session_state.get("last_saved_ticker") == main_ticker:
                            st.success("âœ… ì´ ë¶„ì„ ê²°ê³¼ëŠ” 'ê³¼ê±° ë¶„ì„ ê¸°ë¡'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            if st.button("ğŸ’¾ í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì €ì¥", key=f"gemini_save_{main_ticker}"):
                                with st.spinner("ë¶„ì„ ê²°ê³¼ë¥¼ Google Sheetsì— ì €ì¥í•˜ëŠ” ì¤‘..."):
                                    analysis_text = st.session_state.get("last_analysis_text", "")
                                    try: summary_text = analysis_text.split("#### 4. ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ê°€? (How to Act?)")[1].strip().replace("*", "").replace("#", "")[:200] + "..."
                                    except (IndexError, AttributeError): summary_text = analysis_text.strip().replace("*","").replace("#","")[:200] + "..."
                                    log_entry = { "Timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), "ì¢…ëª©ì½”ë“œ": main_ticker, "AI_Model": st.session_state.get("last_model_used", "N/A"), "ë‹¹ì‹œ ì£¼ê°€": quote.get('c', 0), "ë¶„ì„ ìš”ì•½": summary_text, "ì „ì²´ ë¶„ì„ ë‚´ìš©": analysis_text, "ì£¼ìš” ë°ì´í„°": json.dumps({}, ensure_ascii=False) }
                                    if save_analysis_to_gsheet(log_entry):
                                        st.session_state.last_saved_ticker = main_ticker; st.cache_data.clear(); st.rerun()
                                    else: st.error("ë¶„ì„ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        with log_tab:
            st.subheader("ğŸ“œ ê³¼ê±° ë¶„ì„ ê¸°ë¡")
            analysis_logs = load_analysis_log(main_ticker)
            if not analysis_logs.empty:
                for index, row in analysis_logs.iterrows():
                    with st.expander(f"**{row['Timestamp']}** | ë‹¹ì‹œ ì£¼ê°€: ${float(row.get('ë‹¹ì‹œ ì£¼ê°€', 0)):.2f} | ëª¨ë¸: {row.get('AI_Model', 'N/A')}"):
                        st.markdown(f"**ìš”ì•½:** {row.get('ë¶„ì„ ìš”ì•½', 'N/A')}")
                        st.markdown("---")
                        st.markdown(row.get('ì „ì²´ ë¶„ì„ ë‚´ìš©', 'ì €ì¥ëœ ì „ì²´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'))
            else:
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ê³¼ê±° ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")


        with tech_tab:
            st.subheader("ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„")
            if not candles_df.empty and len(candles_df) > 60:
                candles_df_tech = add_technical_indicators(candles_df.copy())
                st.subheader("ê¸°ìˆ ì  ë¶„ì„ ìš”ì•½"); 
                tech_summary = generate_technical_summary(candles_df_tech)
                for point in tech_summary: st.markdown(f"- {point}")
                st.divider(); st.subheader("AI ì¶”ì²œ ë§¤ìˆ˜ êµ¬ê°„ ì‹œê°í™”")
                fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05, subplot_titles=('Candlestick & AI Buy Zones', 'MACD', 'RSI'), row_heights=[0.6, 0.2, 0.2])
                fig.add_trace(go.Candlestick(x=candles_df_tech['Date'], open=candles_df_tech['Open'], high=candles_df_tech['High'], low=candles_df_tech['Low'], close=candles_df_tech['Close'], name='Price'), row=1, col=1)
                
                if st.session_state.get("structured_reco") and st.session_state.get("last_analysis_ticker") == main_ticker:
                    reco = st.session_state.structured_reco
                    zone1 = reco.get('buy_zone_1'); zone2 = reco.get('buy_zone_2')
                    if zone1: fig.add_hrect(y0=zone1[0], y1=zone1[1], line_width=0, fillcolor="green", opacity=0.2, annotation_text="1st Buy Zone (AI)", annotation_position="bottom right", row=1, col=1)
                    if zone2: fig.add_hrect(y0=zone2[0], y1=zone2[1], line_width=0, fillcolor="red", opacity=0.2, annotation_text="2nd Buy Zone (AI)", annotation_position="bottom right", row=1, col=1)
                else: st.warning("ì¢…í•© ì§„ë‹¨ íƒ­ì—ì„œ AI ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SMA20'], name='SMA 20', line=dict(color='orange', width=1)), row=1, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SMA60'], name='SMA 60', line=dict(color='purple', width=1)), row=1, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['MACD'], name='MACD', line=dict(color='blue', width=1)), row=2, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SignalLine'], name='Signal Line', line=dict(color='red', width=1)), row=2, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['RSI14'], name='RSI 14', line=dict(color='royalblue', width=1)), row=3, col=1)
                fig.add_hline(y=70, line_dash="dash", line_color="red", row=3, col=1)
                fig.add_hline(y=30, line_dash="dash", line_color="green", row=3, col=1)
                fig.update_layout(height=800, xaxis_rangeslider_visible=False)
                st.plotly_chart(fig, use_container_width=True)
            else: st.info(f"'{main_ticker}'ì— ëŒ€í•œ ì°¨íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë§¤ìˆ˜ êµ¬ê°„ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        with fin_tab:
            st.subheader("ğŸ’° í€ë”ë©˜í„¸ ë¶„ì„")
            st.subheader("í•µì‹¬ ì¬ë¬´ ì§€í‘œ (ì—°ê°„)")
            if not financials_df.empty: st.dataframe(financials_df.style.format("{:,.2f}", na_rep="-"))
            else: st.warning(f"'{main_ticker}'ì— ëŒ€í•œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.subheader("ë¶„ê¸°ë³„ ì‹¤ì  ë°œí‘œ ë‚´ì—­")
            if not earnings_data.empty:
                format_dict = {'ì‹¤ì œ EPS': '{:.2f}', 'ì˜ˆìƒ EPS': '{:.2f}', 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)': '{:.2f}%'}
                st.dataframe(earnings_data.style.format(format_dict, na_rep="-"))
                if 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)' in earnings_data.columns:
                    fig_earn = px.bar(earnings_data, x='ë°œí‘œ ë¶„ê¸°', y='EPS ì„œí”„ë¼ì´ì¦ˆ (%)', color='EPS ê²°ê³¼', color_discrete_map={'Beat': 'green', 'Miss': 'red', 'Meet': 'blue'})
                    st.plotly_chart(fig_earn, use_container_width=True)
            else: st.warning(f"'{main_ticker}'ì— ëŒ€í•œ ì‹¤ì  ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.subheader("ê²½ìŸì‚¬ ë¹„êµ")
            if peers:
                peer_df = get_peer_summary([p for p in peers if p != main_ticker][:5])
                if not peer_df.empty: st.dataframe(peer_df.set_index('Ticker').style.format({"Market Cap (M)": "{:,.0f}", "% Change": "{:.2f}%"}, na_rep="-").background_gradient(cmap='RdYlGn', subset=['% Change']))
                else: st.info("ê²½ìŸì‚¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else: st.info("ê²½ìŸì‚¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        with news_tab:
            st.subheader("ğŸ“° ë‰´ìŠ¤ ë° ê¸°ì—… ê°œìš”")
            if profile:
                st.subheader(f"ê¸°ì—… í”„ë¡œí•„: {profile.get('name', main_ticker)}")
                col1, col2 = st.columns([1, 4]); col1.image(profile.get('logo'), width=100)
                with col2: st.text(f"Industry: {profile.get('finnhubIndustry')}"); st.link_button("Visit Website", profile.get('weburl'))
                if next_earnings_date: st.info(f"**ë‹¤ìŒ ì‹¤ì  ë°œí‘œ ì˜ˆì •ì¼:** {next_earnings_date}")
            else: st.warning("ê¸°ì—… í”„ë¡œí•„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.divider()
            st.subheader("ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤")
            if news:
                for item in news[:10]:
                    news_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d %H:%M')
                    st.markdown(f"**[{item['headline']}]({item['url']})**\n- *Source: {item['source']} | {news_date}*")
            else: st.info("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  Tickerë¥¼ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒì„¸ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        
with st.sidebar:
    st.header("Controls")
    view_options = ["ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤", "ğŸ“¡ ë ˆì´ë”", "ğŸ“ˆ ì‹œì¥ í˜„í™©", "ğŸ” ìƒì„¸ ë¶„ì„"]
    
    # st.radioì˜ í˜„ì¬ ì„ íƒê°’ì„ selected_view ë³€ìˆ˜ì— ì €ì¥
    selected_view = st.radio(
        "Select View", 
        view_options, 
        index=view_options.index(st.session_state.active_view), 
        horizontal=True,
        key="view_selector"
    )
    
    if selected_view != st.session_state.active_view:
        st.session_state.active_view = selected_view
        st.rerun()

    st.divider()
    
    default_tickers = ""
    if not st.session_state.watchlist_df.empty and 'ì¢…ëª©ì½”ë“œ' in st.session_state.watchlist_df.columns:
        default_tickers = ", ".join(st.session_state.watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist())
    
    tickers_input = st.text_area("Ticker(s) for Analysis", value=default_tickers, help="ë¶„ì„í•  ì¢…ëª©ì˜ Tickerë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”.")
    
    if st.button("ğŸ” ë¶„ì„ ì‹¤í–‰", use_container_width=True, type="primary"):
        st.session_state.analysis_tickers = [ticker.strip().upper() for ticker in tickers_input.replace(',', '\n').split('\n') if ticker.strip()]
        st.session_state.active_view = "ğŸ” ìƒì„¸ ë¶„ì„"
        st.session_state.last_analysis_text = None
        st.session_state.last_saved_ticker = None
        st.rerun()

    st.divider()
    st.info("í¬íŠ¸í´ë¦¬ì˜¤, í˜„ê¸ˆ, ê´€ì‹¬ì¢…ëª©ì€ Google Sheetsì—ì„œ ì§ì ‘ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
    if st.button("ğŸ”„ Reload Data & Clear Cache", use_container_width=True):
        st.session_state.clear()
        st.cache_data.clear()
        st.rerun()
