# dashboard_v34_final.py

import streamlit as st
import finnhub
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import yfinance as yf
import google.generativeai as genai
import gspread
from google.oauth2.service_account import Credentials
import json
import re  # Add this line
from googleapiclient.discovery import build # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
from io import BytesIO
from googleapiclient.http import MediaIoBaseDownload
import tempfile # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
import os       # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
from PyPDF2 import PdfReader


# --- 1. ì´ˆê¸° ì„¤ì • ë° ë¡œê·¸ì¸ ---
st.set_page_config(page_title="GEM: Finance Dashboard", page_icon="ğŸ’", layout="wide")

def login():
    if "authenticated" not in st.session_state: st.session_state["authenticated"] = False
    if not st.session_state["authenticated"]:
        st.title("ğŸ’ GEM: Finance Dashboard")
        st.caption("MASTER, please enter the password to access the command center.")
        password = st.text_input("Enter password:", type="password")
        if st.button("Login"):
            if "password" in st.secrets and password == st.secrets["password"]:
                st.session_state["authenticated"] = True
                st.rerun()
            else:
                st.error("Incorrect password or password not set in secrets.toml ğŸš«")
        st.stop()

login()

# --- 2. API í‚¤ ë° ì¸ì¦ ì„¤ì • ---
try:
    FINNHUB_API_KEY = st.secrets["FINNHUB_API_KEY"]
    finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
    gc = gspread.authorize(creds)
    SPREADSHEET_NAME = "GEM_Finance_Portfolio"

    # [ì‹ ê·œ] GEM-Core AI ëª¨ë¸ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
    @st.cache_resource
    def get_gem_core_ai():
        print("Initializing GEM-Core AI Model...") # AIê°€ ì²˜ìŒ ë¡œë“œë  ë•Œë§Œ ì´ ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤.
        model_name = 'gemini-2.5-pro' # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
        return genai.GenerativeModel(model_name)


except Exception as e:
    st.error(f"API í‚¤ ë˜ëŠ” ì¸ì¦ ì •ë³´ë¥¼ secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜: {e}")
    st.stop()

# [ìµœì¢… ë‹¨ìˆœí™” ë²„ì „] run_status_screener í•¨ìˆ˜ë¥¼ ì•„ë˜ ì½”ë“œë¡œ êµì²´
def run_status_screener(ticker_list):
    """
    (ìµœì¢… ë‹¨ìˆœí™” ë²„ì „) ì „ì²´ ì¢…ëª©ì— ëŒ€í•´ 'ë§¤ìˆ˜', 'ì£¼ì˜/ë§¤ë„', 'ì¤‘ë¦½'ì˜ 3ê°€ì§€ ìƒíƒœë¡œë§Œ íŒì •í•©ë‹ˆë‹¤.
    """
    if not ticker_list: return pd.DataFrame()

    data = yf.download(ticker_list, period="1y", progress=False, auto_adjust=True)
    if data.empty: return pd.DataFrame()

    final_results = []
    progress_bar = st.progress(0, text="ì „ì²´ ì¢…ëª© ìƒíƒœ ë¶„ì„ ì‹œì‘...")

    for i, ticker in enumerate(ticker_list):
        progress_bar.progress((i + 1) / len(ticker_list), text=f"ë¶„ì„ ì¤‘... {ticker}")
        try:
            stock_df = data.loc[:, (slice(None), ticker)]
            stock_df.columns = stock_df.columns.droplevel(1)
            
            if stock_df.empty or len(stock_df) < 61: continue

            # ì§€í‘œ ê³„ì‚° (SMA, 52ì£¼ ê³ ì , RSI)
            sma20 = stock_df['Close'].rolling(window=20).mean()
            sma60 = stock_df['Close'].rolling(window=60).mean()
            high_52w = stock_df['High'].rolling(window=252, min_periods=1).max().iloc[-1]
            mdd_percent = (stock_df['Close'].iloc[-1] / high_52w - 1) * 100 if high_52w > 0 else 0
            
            delta = stock_df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).ewm(com=13, adjust=False).mean()
            loss = (-delta.where(delta < 0, 0)).ewm(com=13, adjust=False).mean()
            rsi = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))
            latest_rsi = rsi.iloc[-1]

            # --- âœ¨ ìƒíƒœ íŒì • ë¡œì§ ë‹¨ìˆœí™” ---
            status = "ì¤‘ë¦½/ê´€ë§ âšªï¸"
            # ë§¤ìˆ˜ ì‹ í˜¸
            if (sma20.iloc[-2] < sma60.iloc[-2] and sma20.iloc[-1] > sma60.iloc[-1]) or (latest_rsi <= 30):
                status = "ë§¤ìˆ˜ ì‹ í˜¸ ğŸŸ¢"
            # ì£¼ì˜/ë§¤ë„ ì‹ í˜¸
            elif (sma20.iloc[-2] > sma60.iloc[-2] and sma20.iloc[-1] < sma60.iloc[-1]) or (latest_rsi >= 70):
                status = "ì£¼ì˜/ë§¤ë„ ì‹ í˜¸ ğŸ”´"

            final_results.append({
                "ì¢…ëª©ì½”ë“œ": ticker,
                "ìƒíƒœ": status,
                "í˜„ì¬ê°€": stock_df['Close'].iloc[-1],
                "ë“±ë½ë¥ (%)": (stock_df['Close'].iloc[-1] / stock_df['Close'].iloc[-2] - 1) * 100,
                "ê³ ì ëŒ€ë¹„(%)": mdd_percent,
                "RSI": latest_rsi
            })
        except Exception:
            continue
    
    progress_bar.empty()
    return pd.DataFrame(final_results)



# --- 3. ë°ì´í„° í˜¸ì¶œ ë° ì²˜ë¦¬ í•¨ìˆ˜ ---

def load_data_from_gsheet():
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        portfolio_ws = spreadsheet.worksheet("Portfolio")
        portfolio_data = portfolio_ws.get_all_values()
        portfolio_headers = portfolio_data.pop(0)
        portfolio_df = pd.DataFrame(portfolio_data, columns=portfolio_headers)

        watchlist_ws = spreadsheet.worksheet("Watchlist")
        watchlist_df = pd.DataFrame(watchlist_ws.get_all_records())

        cash_ws = spreadsheet.worksheet("Cash")
        cash_df = pd.DataFrame(cash_ws.get_all_records())

        numeric_cols = ['ìˆ˜ëŸ‰', 'í‰ê·  ë‹¨ê°€(USD)', 'í‰ê·  ë‹¨ê°€(KRW)', 'ìˆ˜ë™ í˜„ì¬ê°€(KRW)']
        for col in numeric_cols:
            if col in portfolio_df.columns:
                portfolio_df[col] = portfolio_df[col].replace('', '0').astype(str).str.replace(',', '')
                portfolio_df[col] = pd.to_numeric(portfolio_df[col], errors='coerce').fillna(0)
        
        if 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)' in portfolio_df.columns:
            portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] = portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'].replace('', '0').astype(str).str.replace('%', '')
            portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] = pd.to_numeric(portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'], errors='coerce').fillna(0) / 100
        
        if 'ê¸ˆì•¡(KRW)' in cash_df.columns:
            cash_df['ê¸ˆì•¡(KRW)'] = cash_df['ê¸ˆì•¡(KRW)'].replace('', '0').astype(str).str.replace(',', '')
            cash_df['ê¸ˆì•¡(KRW)'] = pd.to_numeric(cash_df['ê¸ˆì•¡(KRW)'], errors='coerce').fillna(0)

        return portfolio_df, watchlist_df, cash_df
    except gspread.exceptions.WorksheetNotFound as e:
        st.error(f"Google Sheetsì—ì„œ '{e.args[0]}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('Portfolio', 'Watchlist', 'Cash', 'Analysis_Log')")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    except Exception as e:
        st.error(f"Google Sheets ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# [ëˆ„ë½ëœ í•¨ìˆ˜ ì¶”ê°€] AI ë¶„ì„ ì „ìš© í˜„ê¸ˆ ë°ì´í„° ë¡œë”
def load_cash_data_only():
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        cash_ws = spreadsheet.worksheet("Cash")
        cash_df = pd.DataFrame(cash_ws.get_all_records())
        if 'ê¸ˆì•¡(KRW)' in cash_df.columns:
            # ê¸ˆì•¡(KRW) ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³ , ë¹ˆ ë¬¸ìì—´ê³¼ ì‰¼í‘œë¥¼ ì²˜ë¦¬
            cash_df['ê¸ˆì•¡(KRW)'] = cash_df['ê¸ˆì•¡(KRW)'].astype(str).str.replace(',', '').replace('', '0')
            # ìˆ«ì í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë³€í™˜
            cash_df['ê¸ˆì•¡(KRW)'] = pd.to_numeric(cash_df['ê¸ˆì•¡(KRW)'], errors='coerce').fillna(0)
        return cash_df
    except Exception as e:
        st.error(f"Cash ì‹œíŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# [ìµœì¢… ë²„ì „] ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•œ ë‹¨ì¼ ë™ê¸°í™” í•¨ìˆ˜
def synchronize_knowledge_files(folder_name="GEM_Finance_Knowledge", core_folder_name="Core_Principles"):
    """Google Drive í´ë”ì™€ ê·¸ í•˜ìœ„ í´ë”ë¥¼ ëª¨ë‘ íƒìƒ‰í•˜ì—¬ Gemini APIì™€ ë™ê¸°í™”í•˜ê³ ,
    'ìµœìƒìœ„ ì§€ì¹¨'ê³¼ 'ì°¸ê³  ìë£Œ' íŒŒì¼ ëª©ë¡ì„ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        drive_service = build('drive', 'v3', credentials=creds)
        
        # 1. ë©”ì¸ í´ë” ID ì°¾ê¸°
        folder_response = drive_service.files().list(q=f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false", fields='files(id)').execute()
        if not folder_response.get('files'):
            st.warning(f"Google Driveì—ì„œ '{folder_name}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return [], []
        folder_id = folder_response.get('files')[0].get('id')
        
        # 2. [í•µì‹¬ ìˆ˜ì •] ë©”ì¸ í´ë” í•˜ìœ„ì˜ ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°
        all_items_response = drive_service.files().list(q=f"'{folder_id}' in parents and trashed=false", fields='files(id, name, mimeType, modifiedTime, parents)').execute()
        all_items = all_items_response.get('files', [])

        # Core_Principles í´ë” ID ì°¾ê¸° ë° í•´ë‹¹ í´ë” ë‚´ë¶€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        core_folder_id = None
        for item in all_items:
            if item.get('mimeType') == 'application/vnd.google-apps.folder' and item.get('name') == core_folder_name:
                core_folder_id = item.get('id')
                core_files_response = drive_service.files().list(q=f"'{core_folder_id}' in parents and trashed=false", fields='files(id, name, mimeType, modifiedTime, parents)').execute()
                all_items.extend(core_files_response.get('files', []))
                break
        
        # íŒŒì¼ë§Œ í•„í„°ë§í•˜ê³ , Core_Principles íŒŒì¼ ì´ë¦„ ëª©ë¡ ìƒì„±
        drive_files = {f['name']: f for f in all_items if f.get('mimeType') != 'application/vnd.google-apps.folder'}
        core_file_names = {f['name'] for f in all_items if f.get('parents') and core_folder_id in f.get('parents')}

        # 3. Gemini APIì™€ ë™ê¸°í™”
        gemini_files_list = genai.list_files()
        gemini_files = {f.display_name: f for f in gemini_files_list}

        # 3. Drive ê¸°ì¤€ìœ¼ë¡œ ë™ê¸°í™”
        with st.spinner("Knowledge Core ë™ê¸°í™” ì¤‘..."):
            # Driveì— ì—†ëŠ” íŒŒì¼ì€ Geminiì—ì„œ ì‚­ì œ
            for name, gemini_file in gemini_files.items():
                if name not in drive_files:
                    st.write(f"   - Driveì—ì„œ ì‚­ì œëœ íŒŒì¼ '{name}'ì„ AIì—ì„œ ì œê±°í•©ë‹ˆë‹¤.")
                    genai.delete_file(gemini_file.name)
            
            # Driveì— ìƒˆë¡œ ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ì€ Geminiì— ì—…ë¡œë“œ
            for name, drive_file in drive_files.items():
                should_upload = False
                if name in gemini_files:
                    gemini_file_metadata = genai.get_file(gemini_files[name].name)
                    drive_mod_time = pd.to_datetime(drive_file['modifiedTime'])
                    gemini_create_time = pd.to_datetime(gemini_file_metadata.create_time)
                    if drive_mod_time > gemini_create_time:
                        st.write(f"   - ìˆ˜ì •ëœ íŒŒì¼ '{name}'ì„ AIì— ë‹¤ì‹œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
                        genai.delete_file(gemini_files[name].name)
                        should_upload = True
                else:
                    should_upload = True

                if should_upload:
                    st.write(f"   - ìƒˆ íŒŒì¼ '{name}'ì„ AIì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
                    request = drive_service.files().get_media(fileId=drive_file.get('id'))
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{name}") as tmp_file:
                        fh = BytesIO()
                        downloader = MediaIoBaseDownload(fh, request)
                        done = False
                        while not done:
                            status, done = downloader.next_chunk()
                        tmp_file.write(fh.getvalue())
                        tmp_file_path = tmp_file.name
                    
                    genai.upload_file(path=tmp_file_path, display_name=name)
                    os.unlink(tmp_file_path)

        st.success("Knowledge Core ë™ê¸°í™” ì™„ë£Œ!")

       # 4. ìµœì¢… íŒŒì¼ ëª©ë¡ì„ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜
        final_gemini_files = genai.list_files()
        core_principle_files = [f for f in final_gemini_files if f.display_name in core_file_names]
        #reference_files = [f for f in final_gemini_files if f.display_name not in core_file_names]
        
        return core_principle_files#, reference_files

    except Exception as e:
        st.error(f"ì§€ì‹ íŒŒì¼ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        return [], []


def save_analysis_to_gsheet(log_data):
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        log_ws = spreadsheet.worksheet("Analysis_Log")
        EXPECTED_HEADERS = ["Timestamp", "ì¢…ëª©ì½”ë“œ", "AI_Model", "ë‹¹ì‹œ ì£¼ê°€", "ë¶„ì„ ìš”ì•½", "ì „ì²´ ë¶„ì„ ë‚´ìš©", "ì£¼ìš” ë°ì´í„°"]
        if not log_ws.get_all_values():
            log_ws.append_row(EXPECTED_HEADERS)
        row_to_append = [log_data.get(h, "") for h in EXPECTED_HEADERS]
        log_ws.append_row(row_to_append)
        return True
    except Exception as e:
        st.error(f"ë¶„ì„ ê¸°ë¡ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

@st.cache_data(ttl=1)
def load_analysis_log(ticker):
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        log_ws = spreadsheet.worksheet("Analysis_Log")
        log_data = log_ws.get_all_records()
        if not log_data:
            return pd.DataFrame()
        log_df = pd.DataFrame(log_data)
        if 'ì¢…ëª©ì½”ë“œ' not in log_df.columns:
            return pd.DataFrame()
        return log_df[log_df['ì¢…ëª©ì½”ë“œ'] == ticker].sort_values(by='Timestamp', ascending=False)
    except Exception as e:
        st.warning(f"ê³¼ê±° ë¶„ì„ ê¸°ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

@st.cache_data
def get_company_profile(ticker): return finnhub_client.company_profile2(symbol=ticker)

@st.cache_data
def get_company_news(ticker):
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    return finnhub_client.company_news(ticker, _from=start_date, to=end_date)

@st.cache_data
def get_quote(ticker): return finnhub_client.quote(ticker)

# [ì‹ ê·œ] ì¤‘ì•™ ë°ì´í„° í—ˆë¸Œë¥¼ ê²½ìœ í•˜ì—¬ ì‹œì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_quote_from_hub(ticker):
    """
    ì¤‘ì•™ ë°ì´í„° í—ˆë¸Œ(st.session_state.data_hub)ë¥¼ í™•ì¸í•˜ê³ ,
    ë°ì´í„°ê°€ ì—†ê±°ë‚˜ 5ë¶„ì´ ì§€ë‚¬ìœ¼ë©´ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê°±ì‹ í•©ë‹ˆë‹¤.
    """
    now = datetime.now()
    hub_key = f"quote_{ticker}"
    
    # í—ˆë¸Œì— ë°ì´í„°ê°€ ìˆê³ , 5ë¶„ ì´ë‚´ì˜ ìµœì‹  ì •ë³´ì¸ì§€ í™•ì¸
    if hub_key in st.session_state.data_hub:
        data, timestamp = st.session_state.data_hub[hub_key]
        if (now - timestamp) < timedelta(minutes=5):
            return data # ìµœì‹  ì •ë³´ê°€ ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜

    # í—ˆë¸Œì— ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ì •ë³´ì´ë©´, ì‹¤ì œ API í˜¸ì¶œ (ê¸°ì¡´ í•¨ìˆ˜ ì¬í™œìš©)
    # st.write(f"CACHE MISS: Calling API for {ticker} quote...") # í…ŒìŠ¤íŠ¸ìš© ë¡œê·¸
    new_data = get_quote(ticker)
    
    # í—ˆë¸Œì— ìµœì‹  ì •ë³´ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
    if new_data:
        st.session_state.data_hub[hub_key] = (new_data, now)
        
    return new_data


@st.cache_data
def get_basic_financials(ticker):
    try:
        financials = finnhub_client.company_basic_financials(ticker, 'all')
        if 'series' in financials and 'annual' in financials['series']:
            records = {}
            for metric, data_points in financials['series']['annual'].items():
                if not data_points: continue
                clean_metric = metric.replace('Value', '').lower()
                for point in data_points:
                    period, value = point.get('period'), point.get('v')
                    if period not in records: records[period] = {}
                    records[period][clean_metric] = value
            if not records: return pd.DataFrame()
            df = pd.DataFrame.from_dict(records, orient='index').sort_index()
            return df
        return pd.DataFrame()
    except Exception: return pd.DataFrame()
@st.cache_data
def get_company_peers(ticker):
    try: return finnhub_client.company_peers(ticker)
    except Exception: return []
@st.cache_data
def get_company_earnings(ticker):
    try:
        earnings = finnhub_client.company_earnings(ticker, limit=5)
        if not earnings: return pd.DataFrame()
        df = pd.DataFrame(earnings)
        if 'surprisePercent' in df.columns:
            df['EPS ê²°ê³¼'] = df['surprisePercent'].apply(lambda x: 'Beat' if pd.notnull(x) and x > 0 else 'Miss' if pd.notnull(x) and x < 0 else 'Meet')
        else: df['surprisePercent'], df['EPS ê²°ê³¼'] = None, 'N/A'
        final_cols = {'period': 'ë°œí‘œ ë¶„ê¸°', 'actual': 'ì‹¤ì œ EPS', 'estimate': 'ì˜ˆìƒ EPS', 'surprisePercent': 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)', 'EPS ê²°ê³¼': 'EPS ê²°ê³¼'}
        return df[[c for c in final_cols if c in df.columns]].rename(columns=final_cols)
    except Exception: return pd.DataFrame()
@st.cache_data
def get_earnings_calendar(ticker):
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        later = (datetime.now() + timedelta(days=365)).strftime('%Y-%m-%d')
        calendar = finnhub_client.earnings_calendar(_from=today, to=later, symbol=ticker)
        if calendar and calendar.get('earningsCalendar'): return calendar['earningsCalendar'][0].get('date')
        return None
    except Exception: return None
@st.cache_data
def get_stock_candles(ticker):
    try:
        df = yf.Ticker(ticker).history(period="1y")
        if df.empty: return pd.DataFrame()
        return df.reset_index()
    except Exception: return pd.DataFrame()

@st.cache_data(ttl=3600) # 1ì‹œê°„ë§ˆë‹¤ Google Sheetsì—ì„œ í‹°ì»¤ ëª©ë¡ ê°±ì‹ 
def get_all_ticker_lists():
    """'Tickers' ì‹œíŠ¸ì—ì„œ ëª¨ë“  ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ì™€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        tickers_ws = gc.open(SPREADSHEET_NAME).worksheet("Tickers")
        all_values = tickers_ws.get_all_values()
        if not all_values:
            return {}
        
        headers = all_values[0]
        ticker_lists = {header: [] for header in headers}
        
        for col_idx, header in enumerate(headers):
            for row_idx in range(1, len(all_values)):
                if col_idx < len(all_values[row_idx]) and all_values[row_idx][col_idx]:
                    ticker_lists[header].append(all_values[row_idx][col_idx])
        return ticker_lists
    except Exception as e:
        st.error(f"Google Sheets 'Tickers' ì‹œíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return {}




def add_technical_indicators(df):
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['SMA60'] = df['Close'].rolling(window=60).mean()
    # [ìˆ˜ì •] ëˆ„ë½ë˜ì—ˆë˜ 120ì¼, 200ì¼ ì´ë™í‰ê· ì„  ê³„ì‚° ì¶”ê°€
    df['SMA120'] = df['Close'].rolling(window=120).mean()
    df['SMA200'] = df['Close'].rolling(window=200).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI14'] = 100 - (100 / (1 + rs))
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['SignalLine'] = df['MACD'].ewm(span=9, adjust=False).mean()
    return df



def generate_technical_summary(df):
    summary = []
    if len(df) < 60: return ["ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    latest = df.iloc[-1]; previous = df.iloc[-2]
    if latest['RSI14'] > 70: summary.append("ğŸ“ˆ **RSI ê³¼ë§¤ìˆ˜:** ë‹¨ê¸° ì¡°ì • ê°€ëŠ¥ì„±.")
    elif latest['RSI14'] < 30: summary.append("ğŸ“‰ **RSI ê³¼ë§¤ë„:** ë‹¨ê¸° ë°˜ë“± ê°€ëŠ¥ì„±.")
    else: summary.append(f"ğŸ“Š **RSI:** {latest['RSI14']:.2f} (ì¤‘ë¦½)")
    if previous['SMA20'] < previous['SMA60'] and latest['SMA20'] > latest['SMA60']: summary.append("ğŸš€ **ê³¨ë“  í¬ë¡œìŠ¤:** ê°•ì„¸ ì‹ í˜¸.")
    elif previous['SMA20'] > previous['SMA60'] and latest['SMA20'] < latest['SMA60']: summary.append("âš ï¸ **ë°ë“œ í¬ë¡œìŠ¤:** ì•½ì„¸ ì‹ í˜¸.")
    if previous['MACD'] < previous['SignalLine'] and latest['MACD'] > latest['SignalLine']: summary.append("ğŸ“ˆ **MACD ìƒí–¥ ëŒíŒŒ:** ë§¤ìˆ˜ ì‹ í˜¸.")
    elif previous['MACD'] > previous['SignalLine'] and latest['MACD'] < latest['SignalLine']: summary.append("ğŸ“‰ **MACD í•˜í–¥ ëŒíŒŒ:** ë§¤ë„ ì‹ í˜¸.")
    if not summary: summary.append("ëšœë ·í•œ ê¸°ìˆ ì  ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return summary

def calculate_support_levels(df):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ AIê°€ ì°¸ê³ í•  ì ì¬ì  ì§€ì§€ì„  ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty or len(df) < 200:
        return []
    high_1y = df['High'].max()
    low_1y = df['Low'].min()
    
    fibo_382 = high_1y - (high_1y - low_1y) * 0.382
    fibo_500 = high_1y - (high_1y - low_1y) * 0.5
    fibo_618 = high_1y - (high_1y - low_1y) * 0.618
    
    # SMA 120, 200ì¼ì„  ê³„ì‚°ì„ ìœ„í•´ add_technical_indicators í•¨ìˆ˜ ì¬ì‚¬ìš©
    df_with_sma = add_technical_indicators(df.copy())
    sma_120 = df_with_sma['SMA120'].iloc[-1]
    sma_200 = df_with_sma['SMA200'].iloc[-1]

    supports = [fibo_382, fibo_500, fibo_618, sma_120, sma_200]
    return [f"${s:.2f}" for s in supports if pd.notna(s)]

# [ìµœì¢… ìˆ˜ì •] ê³„ì¸µì  ì§€ì‹ ì‹œìŠ¤í…œì„ ëª…ì‹œì  'Tool'ë¡œ êµ¬í˜„í•œ ìµœì¢… AI ë¶„ì„ í•¨ìˆ˜
def stream_and_capture_analysis(ticker, profile, quote, financials_df, tech_summary, news, portfolio_context, support_levels, dynamic_trends, market_context, core_principle_files):
    model = get_gem_core_ai()
    model_name = model.model_name
    
    # [í•µì‹¬ ìˆ˜ì •] ëª¨ë¸ ìƒì„± ì‹œ tools ì„ ì–¸ì„ ì œê±°
    model = genai.GenerativeModel(model_name)

    # ë™ì  íŠ¸ë Œë“œ ì„¤ëª…ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„±
    trends_text = f"""
       - ì‹¤ì‹œê°„: {dynamic_trends.get('realtime_change_percent', 0.0):.2f}%
       - 3ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_3d_percent', 'N/A')}
       - 7ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_7d_percent', 'N/A')}
       - 30ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_30d_percent', 'N/A')}
       - 30ì¼ S&P500 ëŒ€ë¹„: {dynamic_trends.get('vs_spy_30d_percent', 'N/A')}
    """
    
    # [ì¶”ê°€] ê±°ì‹œ ê²½ì œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„±
    market_context_text = f"""
       - VIX (ê³µí¬ì§€ìˆ˜): {market_context.get('VIX', {}).get('price', 'N/A'):.2f} (20 ì´ìƒì¼ ê²½ìš° ë³€ë™ì„± í™•ëŒ€ ì£¼ì˜)
       - ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬: {market_context.get('US 10Y', {}).get('price', 'N/A'):.2f}% (ê¸ˆë¦¬ ìƒìŠ¹ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„±ì¥ì£¼ì— ë¶€ë‹´)
    """
# í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ê° íŒŒì¼ì˜ ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„
    core_files_names = ", ".join([f.display_name for f in core_principle_files]) if core_principle_files else "ì—†ìŒ"
    #ref_files_names = ", ".join([f.display_name for f in reference_files]) if reference_files else "ì—†ìŒ"
    
    master_prompt = f"""
    **SYSTEM ROLE:** ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ìµœê³ ì˜ ê¸ˆìœµ ë¶„ì„ê°€ì´ì, 'MASTER'ë¼ëŠ” íˆ¬ììë¥¼ ë³´ì¢Œí•˜ëŠ” AI ì „ëµ íŒŒíŠ¸ë„ˆ, 'GEM: Finance'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ë¶„ì„ì€ í•­ìƒ MASTERì˜ íˆ¬ì ì² í•™ì´ ë‹´ê¸´ ìµœìƒìœ„ ì§€ì¹¨ì„ ìµœìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤.

    **INPUT DATA:**
    - ë¶„ì„ ëŒ€ìƒ: {ticker}
    - MASTER í¬íŠ¸í´ë¦¬ì˜¤ ìƒí™©: {portfolio_context}
    - ê¸°ì—… ê°œìš”: {profile.get('name', 'N/A')}, ì‚°ì—…: {profile.get('finnhubIndustry', 'N/A')}
    - í˜„ì¬ ì‹œì„¸: ${quote.get('c', 0):.2f}
    - í•µì‹¬ ì¬ë¬´ ìš”ì•½: \n{financials_df.tail(3).to_string() if not financials_df.empty else "N/A"}
    - ê¸°ìˆ ì  ë¶„ì„ ìš”ì•½ (ì‹œìŠ¤í…œ): \n- {"\n- ".join(tech_summary)}
    - ìµœì‹  ë‰´ìŠ¤ ìš”ì•½ (ì‹œìŠ¤í…œ): \n- {"\n- ".join([item['headline'] for item in news[:5]]) if news else "N/A"}
    - ì ì¬ì  ì§€ì§€ì„  (ì‹œìŠ¤í…œ): {support_levels}
    - ìµœê·¼ ì£¼ê°€ ë™í–¥: {trends_text}
    - í˜„ì¬ ê±°ì‹œ ê²½ì œ ìƒí™©: {market_context_text}
    - ì²¨ë¶€ëœ ìµœìƒìœ„ ì§€ì¹¨ íŒŒì¼: {core_files_names}
    

    **MISSION:**
    ëª¨ë“  INPUT DATAì™€ ì²¨ë¶€ëœ ì§€ì¹¨ íŒŒì¼ì„ ì¢…í•©í•˜ì—¬, ì•„ë˜ 4ê°€ì§€ í•µì‹¬ ì§ˆë¬¸ì— ëŒ€í•œ 'ìƒì„¸í•œ ì„œìˆ í˜•' ë‹µë³€ì´ í¬í•¨ëœ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
    ë‹µë³€ì„ ìƒì„±í•  ë•Œ, ê° ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš© ì•ˆì— ì•„ë˜ì— ëª…ì‹œëœ **7ê°œì˜ ë°ì´í„° ë¸”ë¡**ì„ ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    ---
    ### ğŸ’ {ticker} ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
    *Analysis Model: `{model_name}`*

    #### 1. ì¢‹ì€ ì¢…ëª©ì¸ê°€? (í€ë”ë©˜í„¸ ë° ë‰´ìŠ¤ ë¶„ì„)
    *ì´ê³³ì— ììœ ë¡­ê²Œ ì„œìˆ í˜•ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...*
    [FUNDAMENTAL_ANALYSIS_BRIEFING]
    (ì„œìˆ  ë‚´ìš© ìš”ì•½) ì œê³µëœ ì¬ë¬´ì œí‘œì˜ ì„±ì¥ì„±, ìˆ˜ìµì„±, ì•ˆì •ì„± ë™í–¥ì„ ë¶„ì„í•˜ê³ , íˆ¬ììê°€ ìœ ì˜í•´ì•¼ í•  ê¸ì •ì /ë¶€ì •ì  í¬ì¸íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    [/FUNDAMENTAL_ANALYSIS_BRIEFING]
    *ì´ì–´ì„œ ê³„ì† ììœ ë¡­ê²Œ ì„œìˆ í•©ë‹ˆë‹¤...*
    [NEWS_ANALYSIS_BRIEFING]
    (ì„œìˆ  ë‚´ìš© ìš”ì•½) ì œê³µëœ ìµœì‹  ë‰´ìŠ¤ í—¤ë“œë¼ì¸ë“¤ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ê³ , ì „ì²´ì ì¸ ë‰´ìŠ¤ íë¦„ì´ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ì„ ê¸ì •ì , ë¶€ì •ì , ì¤‘ë¦½ì ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    [/NEWS_ANALYSIS_BRIEFING]
    *ê²°ë¡ ì ìœ¼ë¡œ ì´ ì¢…ëª©ì€ í€ë”ë©˜í„¸ê³¼ ë‰´ìŠ¤ ê´€ì ì—ì„œ...*

    #### 2. ì¢‹ì€ ì‹œê¸°ì¸ê°€? (ê¸°ìˆ ì  ë¶„ì„)
    *ì´ê³³ì— ììœ ë¡­ê²Œ ì„œìˆ í˜•ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...*
    [TECHNICAL_ANALYSIS_BRIEFING]
    (ì„œìˆ  ë‚´ìš© ìš”ì•½) í˜„ì¬ ì£¼ê°€ ì°¨íŠ¸ì˜ ì£¼ìš” ì´í‰ì„ (SMA), RSI, MACD ì§€í‘œì™€ ìµœê·¼ ìº”ë“¤ íŒ¨í„´ì„ ì¢…í•©ì ìœ¼ë¡œ í•´ì„í•˜ì—¬, í˜„ì¬ ê¸°ìˆ ì  ìƒíƒœê°€ ê°•ì„¸ì¸ì§€, ì•½ì„¸ì¸ì§€, í˜¹ì€ íš¡ë³´ ìƒíƒœì¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    [/TECHNICAL_ANALYSIS_BRIEFING]
    *ë”°ë¼ì„œ í˜„ì¬ ê¸°ìˆ ì  ê´€ì ì—ì„œëŠ”...*

    #### 3. ì¢‹ì€ ê°€ê²©ì¸ê°€? (ë§¤ìˆ˜ ë° ë§¤ë„ ì „ëµ)
    *ì´ê³³ì— ììœ ë¡­ê²Œ ì„œìˆ í˜•ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...*
    [BUY_ZONES]
    zone1_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone1_end: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_end: [ìˆ«ì ë˜ëŠ” N/A]
    rationale: í•´ë‹¹ ë§¤ìˆ˜ êµ¬ê°„ì„ ì„¤ì •í•œ ê¸°ìˆ ì , í€ë”ë©˜í„¸ì  ê·¼ê±°ë¥¼ ê°„ëµíˆ ì„œìˆ í•©ë‹ˆë‹¤.
    [/BUY_ZONES]
    *ë˜í•œ, ìˆ˜ìµ ì‹¤í˜„ ê´€ì ì—ì„œëŠ”...*
    [SELL_ZONES]
    zone1_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone1_end: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_end: [ìˆ«ì ë˜ëŠ” N/A]
    rationale: í•´ë‹¹ ë§¤ë„/ìˆ˜ìµì‹¤í˜„ êµ¬ê°„ì„ ì„¤ì •í•œ ê¸°ìˆ ì , í€ë”ë©˜í„¸ì  ê·¼ê±°ë¥¼ ê°„ëµíˆ ì„œìˆ í•©ë‹ˆë‹¤.
    [/SELL_ZONES]

    #### 4. ìµœì¢…ì ìœ¼ë¡œ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ê°€? (ìµœì¢… ê¶Œê³ )
    *MASTERì˜ íˆ¬ì ì² í•™ê³¼ ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í–ˆì„ ë•Œ, ìµœì¢…ì ì¸ í–‰ë™ ê¶Œê³ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...*
    [RECOMMENDATION]
    action: [ë§¤ìˆ˜ ì¶”ì²œ, ì ê·¹ ë§¤ìˆ˜, ê´€ë§, ë¹„ì¤‘ ì¶•ì†Œ, ë§¤ë„ ê³ ë ¤] ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
    rationale: ìœ„ íˆ¬ì í–‰ë™ì„ ê²°ì •í•œ í•µì‹¬ì ì¸ ì´ìœ ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    [/RECOMMENDATION]
    """

    full_response = []
    try:
        # [í•µì‹¬ ìˆ˜ì •] generate_content í˜¸ì¶œ ì‹œ, í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ë‹¬
        all_files = core_principle_files#+ reference_files
        
        response = model.generate_content([master_prompt] + all_files, stream=True)

        for chunk in response:
            full_response.append(chunk.text)
            yield chunk.text

        # [ìˆ˜ì •] ëŒ€í™” ê¸°ë¡ì— í˜„ì¬ ë¬¸ë‹µ ì¶”ê°€
        final_text = "".join(full_response)
        st.session_state.last_analysis_text = final_text
        st.session_state.last_model_used = model_name
        


    except Exception as e:
        error_message = f"Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        st.session_state.last_analysis_text = error_message
        st.session_state.last_model_used = "Error"
        yield error_message

# [âœ¨ NEW] 1. 'ì§„í™”ëœ ë³´ê³ ì„œ' ìƒì„±ì„ ìœ„í•œ AI ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
def stream_evolved_report(previous_analysis_text, change_summary, ticker):
    """
    ê¸°ì¡´ ë¶„ì„ê³¼ ë³€ê²½ì ì„ ë°”íƒ•ìœ¼ë¡œ 'ì§„í™”ëœ ì „ì²´ ë³´ê³ ì„œ'ë¥¼ ìƒì„±í•˜ëŠ” AI í•¨ìˆ˜.
    """
    if "ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in change_summary:
        yield previous_analysis_text # ë³€ê²½ ì—†ìœ¼ë©´ ì´ì „ ë³´ê³ ì„œ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return

    model = get_gem_core_ai()
    
    prompt = f"""
**MISSION:** ì•„ë˜ [ê¸°ì¡´ ë¶„ì„ ë³´ê³ ì„œ]ë¥¼ [ìµœì‹  ë°ì´í„° ë³€ê²½ì  ìš”ì•½]ì„ ë°˜ì˜í•˜ì—¬, ë…¼ë¦¬ì  íë¦„ê³¼ êµ¬ì¡°ë¥¼ ì™„ë²½í•˜ê²Œ ìœ ì§€í•œ 'ì™„ê²°ëœ ìµœì‹  ë²„ì „ì˜ ì „ì²´ ë³´ê³ ì„œ'ë¡œ ì—…ë°ì´íŠ¸ í•˜ì‹­ì‹œì˜¤. ìµœì¢… ê²°ê³¼ë¬¼ì€ ë³´ê³ ì„œ ì „ë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

**[ê¸°ì¡´ ë¶„ì„ ë³´ê³ ì„œ]**
---
{previous_analysis_text}
---

**[ìµœì‹  ë°ì´í„° ë³€ê²½ì  ìš”ì•½]**
---
{change_summary}
---
"""
    response = model.generate_content(prompt, stream=True)
    for chunk in response:
        yield chunk.text

# [âœ¨ NEW] 2. 'ë³€ê²½ ìš”ì•½ ë¸Œë¦¬í•‘(Changelog)' ìƒì„±ì„ ìœ„í•œ AI í•¨ìˆ˜
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
def generate_changelog(previous_analysis_text, new_analysis_text, change_summary):
    """
    ì´ì „/ì‹ ê·œ ë³´ê³ ì„œì™€ ë³€ê²½ì ì„ ë¹„êµí•˜ì—¬ 'AI ë³€ê²½ì  ë¸Œë¦¬í•‘'ì„ ìƒì„±í•˜ëŠ” AI í•¨ìˆ˜.
    """
    if "ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in change_summary:
        return "âœ… ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ê¸°ì¡´ ë¶„ì„ì´ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤."
    
    model = get_gem_core_ai()
    
    prompt = f"""
**MISSION:** ë‹¹ì‹ ì€ ë¶„ì„íŒ€ì¥ì…ë‹ˆë‹¤. ì•„ë˜ ì„¸ ê°€ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì–´ë–¤ 'ë°ì´í„° ë³€ê²½ì ' ë•Œë¬¸ì— ì´ì „ ë³´ê³ ì„œê°€ ìƒˆë¡œìš´ ë³´ê³ ì„œë¡œ ì–´ë–»ê²Œ ë°”ë€Œì—ˆëŠ”ì§€ í•µì‹¬ì ì¸ ì´ìœ ë¥¼ 'ë³€ê²½ ìš”ì•½ ë¸Œë¦¬í•‘' í˜•ì‹ìœ¼ë¡œ ë³´ê³ í•˜ì‹­ì‹œì˜¤.

**[1. ë°ì´í„° ë³€ê²½ì ]**
{change_summary}

**[2. ì´ì „ ë³´ê³ ì„œ]**
{previous_analysis_text}

**[3. ìƒˆë¡œìš´ ë³´ê³ ì„œ]**
{new_analysis_text}

**ë³´ê³  í˜•ì‹:**
ğŸ’¡ **AI ë³€ê²½ì  ë¸Œë¦¬í•‘ (Changelog)**
* **[ì‚¬ìœ ]** (ë°ì´í„° ë³€ê²½ì  ìš”ì•½)
    * **[ê²°ê³¼]** (ë³´ê³ ì„œì˜ ì–´ë–¤ ë¶€ë¶„ì´ ì–´ë–»ê²Œ ìˆ˜ì •ë˜ì—ˆëŠ”ì§€ ì„¤ëª…)
"""
    
    response = model.generate_content(prompt)
    return response.text


def structure_recommendation(full_analysis_text):
    """
    AIê°€ ìƒì„±í•œ 'ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ' í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ë°ì´í„° ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    if not full_analysis_text:
        return {}

    def extract_block(block_name, text):
        """ì§€ì •ëœ ì´ë¦„ì˜ ë°ì´í„° ë¸”ë¡ ë‚´ìš©ì„ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        pattern = re.compile(f'\\[{block_name}\\](.*?)\\[/{block_name}\\]', re.DOTALL)
        match = pattern.search(text)
        if match:
            return match.group(1).strip()
        return None

    def parse_zones(zone_content):
        """BUY_ZONES ë˜ëŠ” SELL_ZONESì˜ ë‚´ìš©ì„ íŒŒì‹±í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        if not zone_content:
            return None

        reco = {}
        for line in zone_content.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                reco[key.strip()] = value.strip()

        def to_float_or_none(val):
            try: return float(val)
            except (ValueError, TypeError): return None

        zone1_start = to_float_or_none(reco.get('zone1_start'))
        zone1_end = to_float_or_none(reco.get('zone1_end'))
        zone2_start = to_float_or_none(reco.get('zone2_start'))
        zone2_end = to_float_or_none(reco.get('zone2_end'))

        return {
            'zone1': (zone1_start, zone1_end) if zone1_start and zone1_end else None,
            'zone2': (zone2_start, zone2_end) if zone2_start and zone2_end else None,
            'rationale': reco.get('rationale', 'N/A')
        }

    def parse_recommendation(reco_content):
        """RECOMMENDATION ë¸”ë¡ì„ íŒŒì‹±í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        if not reco_content:
            return None

        reco = {}
        for line in reco_content.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                reco[key.strip()] = value.strip()
        return {
            'action': reco.get('action', 'N/A'),
            'rationale': reco.get('rationale', 'N/A')
        }

    # ê° ë¸”ë¡ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
    recommendation_content = parse_recommendation(extract_block('RECOMMENDATION', full_analysis_text))
    fundamental_content = extract_block('FUNDAMENTAL_ANALYSIS_BRIEFING', full_analysis_text)
    news_content = extract_block('NEWS_ANALYSIS_BRIEFING', full_analysis_text)
    technical_content = extract_block('TECHNICAL_ANALYSIS_BRIEFING', full_analysis_text)
    buy_zones_content = parse_zones(extract_block('BUY_ZONES', full_analysis_text))
    sell_zones_content = parse_zones(extract_block('SELL_ZONES', full_analysis_text))

    # ìµœì¢… êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ì¢…í•©
    structured_data = {
        'recommendation': recommendation_content,
        'fundamental_briefing': fundamental_content,
        'news_briefing': news_content,
        'technical_briefing': technical_content,
        'buy_zones': buy_zones_content,
        'sell_zones': sell_zones_content
    }

    return structured_data

def calculate_dynamic_trends(df, quote):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ê³¼ ì‹¤ì‹œê°„ ì‹œì„¸ë¥¼ ë°›ì•„ ë™ì  íŠ¸ë Œë“œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    trends = {}
    if df.empty or len(df) < 31:
        return trends

    # ì‹¤ì‹œê°„ ë“±ë½ë¥ 
    trends['realtime_change_percent'] = quote.get('dp', 0.0)

    # ê¸°ê°„ë³„ ìˆ˜ìµë¥  ê³„ì‚°
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.set_index('Date')
    
    latest_price = df['Close'].iloc[-1]
    for days in [3, 7, 30]:
        try:
            past_price = df['Close'].iloc[-days-1]
            trends[f'return_{days}d_percent'] = ((latest_price - past_price) / past_price) * 100
        except IndexError:
            trends[f'return_{days}d_percent'] = 'N/A'

    # S&P500 ëŒ€ë¹„ ì„±ê³¼ (30ì¼ ê¸°ì¤€)
    try:
        spy_df = yf.download('SPY', start=df.index[-31], end=df.index[-1] + pd.Timedelta(days=1), progress=False)
        spy_return = (spy_df['Close'].iloc[-1] - spy_df['Close'].iloc[0]) / spy_df['Close'].iloc[0] * 100
        stock_return_30d = trends.get('return_30d_percent', 0)
        if stock_return_30d != 'N/A':
            trends['vs_spy_30d_percent'] = stock_return_30d - spy_return
    except Exception:
        trends['vs_spy_30d_percent'] = 'N/A'
        
    return trends


# backup (lines 260-281)
@st.cache_data(ttl=300)
def get_current_prices_and_rate(tickers):
    try: usd_krw_rate = yf.Ticker("USDKRW=X").history(period='1d')['Close'].iloc[-1]
    except: usd_krw_rate = 1350.0
    try:
        data = yf.download(tickers, period='1d', progress=False)
        if data.empty: return {}, usd_krw_rate
        prices = data['Close'].iloc[-1].to_dict() if isinstance(data.columns, pd.MultiIndex) else {tickers[0]: data['Close'].iloc[-1]}
        return prices, usd_krw_rate
    except: return {}, usd_krw_rate
def create_portfolio_dashboard(df, prices, usd_krw_rate):
    dashboard_df = df.copy()
    dashboard_df['API í˜„ì¬ê°€'] = dashboard_df['ì¢…ëª©ì½”ë“œ'].map(prices)
    if 'ìˆ˜ë™ í˜„ì¬ê°€(KRW)' in dashboard_df.columns:
        dashboard_df['í˜„ì¬ê°€'] = dashboard_df['ìˆ˜ë™ í˜„ì¬ê°€(KRW)'].where(dashboard_df['ìˆ˜ë™ í˜„ì¬ê°€(KRW)'] > 0, dashboard_df['API í˜„ì¬ê°€'])
    else: dashboard_df['í˜„ì¬ê°€'] = dashboard_df['API í˜„ì¬ê°€']
    dashboard_df['í†µí™”'] = 'USD'
    dashboard_df.loc[dashboard_df['ì¢…ëª©ì½”ë“œ'].str.contains('.KS|.KQ', na=False), 'í†µí™”'] = 'KRW'
    dashboard_df['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] = dashboard_df.apply(lambda r: r['í‰ê·  ë‹¨ê°€(KRW)'] if r['í†µí™”'] == 'KRW' else r['í‰ê·  ë‹¨ê°€(USD)'], axis=1)
    dashboard_df['í˜„ì¬ê°€ (ê³ ìœ )'] = dashboard_df['í˜„ì¬ê°€']
    dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'] = dashboard_df.apply(lambda r: (r['ìˆ˜ëŸ‰'] * r['í‰ê·  ë‹¨ê°€ (ê³ ìœ )']) if r['í†µí™”'] == 'KRW' else (r['ìˆ˜ëŸ‰'] * r['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] * usd_krw_rate), axis=1)
    dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = pd.NA
    if 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)' in dashboard_df.columns:
        mask = dashboard_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] != 0
        dashboard_df.loc[mask, 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = dashboard_df.loc[mask, 'ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'] * (1 + dashboard_df.loc[mask, 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)'])
    auto_calc_mask = dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].isna()
    dashboard_df.loc[auto_calc_mask, 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = dashboard_df.loc[auto_calc_mask].apply(lambda r: (r['ìˆ˜ëŸ‰'] * r['í˜„ì¬ê°€']) if r['í†µí™”'] == 'KRW' else (r['ìˆ˜ëŸ‰'] * r['í˜„ì¬ê°€'] * usd_krw_rate), axis=1)
    dashboard_df['ì†ìµ (KRW)'] = (dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] - dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)']).fillna(0)
    dashboard_df['ì†ìµ (ê³ ìœ )'] = dashboard_df.apply(lambda r: r['ì†ìµ (KRW)'] if r['í†µí™”'] == 'KRW' else r['ì†ìµ (KRW)'] / usd_krw_rate, axis=1)
    dashboard_df['ìˆ˜ìµë¥  (%)'] = (dashboard_df['ì†ìµ (KRW)'] / dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].replace(0, pd.NA)) * 100
    return dashboard_df

@st.cache_data
def get_peer_summary(ticker_list):
    summary_data = []
    for ticker in ticker_list:
        try:
            # [ìˆ˜ì •] get_quoteë¥¼ get_quote_from_hubë¡œ ë³€ê²½
            profile, quote = get_profile_from_hub(ticker), get_quote_from_hub(ticker) # <-- ì—¬ê¸°ë¥¼ ìˆ˜ì •
            summary_data.append({"Ticker": ticker, "Name": profile.get('name', ticker), "Market Cap (M)": profile.get('marketCapitalization', 0), "% Change": quote.get('dp', 0)})
        except: continue
    return pd.DataFrame(summary_data)


# --- [MOD v35.5 Start] í•¨ìˆ˜ê°€ 'ì „ì²´ ì´ë ¥ ë°ì´í„°'ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • ---
@st.cache_data(ttl=300)
def get_market_status_data():
    """(ì¶”ì„¸ ë¶„ì„ìš©) ì£¼ìš” ì§€í‘œ, ë‰´ìŠ¤, ê·¸ë¦¬ê³  '5ì¼ ì „ì²´ ì´ë ¥ ë°ì´í„°'ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤."""
    data = {}
    tickers = {
        "S&P 500": "^GSPC", "Nasdaq": "^IXIC", "KOSPI": "^KS11",
        "VIX": "^VIX", "US 10Y": "^TNX", "Dollar": "DX-Y.NYB", "Crude Oil": "CL=F", "Gold": "GC=F"
    }
    
    hist_data = pd.DataFrame() # ê¸°ë³¸ ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”
    try:
        hist_data = yf.download(list(tickers.values()), period="5d", progress=False)
        if not hist_data.empty:
            for name, ticker_symbol in tickers.items():
                try:
                    ticker_series = hist_data['Close'][ticker_symbol].dropna()
                    if len(ticker_series) >= 2:
                        price = ticker_series.iloc[-1]
                        change = price - ticker_series.iloc[-2]
                        change_percent = (change / ticker_series.iloc[-2]) * 100 if ticker_series.iloc[-2] != 0 else 0
                        data[name] = {"price": price, "change": change, "change_percent": change_percent}
                    elif len(ticker_series) == 1:
                        data[name] = {"price": ticker_series.iloc[-1], "change": "N/A", "change_percent": "N/A"}
                    else:
                        data[name] = {"price": "N/A", "change": "N/A", "change_percent": "N/A"}
                except (KeyError, IndexError):
                    data[name] = {"price": "N/A", "change": "N/A", "change_percent": "N/A"}
    except Exception:
        for name in tickers.keys():
            data[name] = {"price": "N/A", "change": "N/A", "change_percent": "N/A"}

    try:
        data['news'] = finnhub_client.general_news('general', min_id=0)[:5]
    except Exception:
        data['news'] = []

    return data, hist_data # ìš”ì•½ ë°ì´í„°ì™€ ì „ì²´ ì´ë ¥ ë°ì´í„°ë¥¼ í•¨ê»˜ ë°˜í™˜
# --- [MOD v35.5 End] ---


# --- [MOD v35.7 Start] AI ë¸Œë¦¬í•‘ì— 'ì„¹í„° ë¶„ì„' ì¶”ê°€ ë° 'ìš”ì•½' ê¸°ëŠ¥ ê°•í™” ---
def generate_market_health_briefing(market_data, full_hist_data, sector_perf_df):
    """
    ì‹œì¥/ì¶”ì„¸/ì„¹í„°/ë‰´ìŠ¤ë¥¼ ì¢…í•© ë¶„ì„í•˜ê³ , 'í•œ ë¬¸ì¥ ìš”ì•½'ì„ í¬í•¨í•œ ìµœì¢… ë¸Œë¦¬í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    model = get_gem_core_ai()
    
    tickers = {
        "S&P 500": "^GSPC", "Nasdaq": "^IXIC", "KOSPI": "^KS11",
        "VIX": "^VIX", "US 10Y": "^TNX", "Dollar": "DX-Y.NYB", "Crude Oil": "CL=F", "Gold": "GC=F"
    }

    # ì§€í‘œ ë° ì¶”ì„¸ ìš”ì•½
    data_summary = []
    for name, values in market_data.items():
        if name == 'news': continue
        price = values.get('price', 'N/A')
        change_percent = values.get('change_percent', 'N/A')
        trend = "íš¡ë³´"
        try:
            ticker_symbol = tickers.get(name)
            if ticker_symbol and not full_hist_data.empty:
                series = full_hist_data['Close'][ticker_symbol].dropna()
                if len(series) >= 5:
                    if series.iloc[-1] > series.iloc[0] * 1.01: trend = "ìƒìŠ¹ ì¶”ì„¸"
                    elif series.iloc[-1] < series.iloc[0] * 0.99: trend = "í•˜ë½ ì¶”ì„¸"
        except (KeyError, IndexError, TypeError):
            trend = "íŒë‹¨ ë¶ˆê°€"
        if isinstance(price, (int, float)) and isinstance(change_percent, (int, float)):
            data_summary.append(f"- {name}: {price:.2f} ({change_percent:+.2f}%) | 5ì¼ ì¶”ì„¸: {trend}")
    data_summary_text = "\n".join(data_summary)
    
    # ë‰´ìŠ¤ ë° ì„¹í„° ë°ì´í„° ìš”ì•½
    news_headlines = [f"- {news['headline']}" for news in market_data.get('news', [])]
    news_summary_text = "\n".join(news_headlines) if news_headlines else "ìµœì‹  ì£¼ìš” ë‰´ìŠ¤ ì—†ìŒ"
    sector_summary_text = sector_perf_df.to_string(index=False) if not sector_perf_df.empty else "ì„¹í„° ë°ì´í„° ì—†ìŒ"

    prompt = f"""
    **SYSTEM ROLE:** ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ìˆ˜ì„ ì‹œì¥ ì „ëµê°€ 'GEM: Finance'ë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ ì—°ê²°í•˜ì—¬ í”¼ìƒì ì¸ í˜„ìƒ ë„ˆë¨¸ì˜ ì§„ì‹¤ì„ íŒŒì•…í•˜ê³ , ë°”ìœ ì˜ì‚¬ê²°ì •ìë¥¼ ìœ„í•´ í•µì‹¬ì„ ìš”ì•½í•˜ëŠ” ê²ƒì´ë‹¤.

    **INPUT DATA:**
    1. ìµœì‹  ì‹œì¥ ì§€í‘œ ë° 5ì¼ ì¶”ì„¸:
    {data_summary_text}
    2. ìµœì‹  ê²½ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸:
    {news_summary_text}
    3. ìµœê·¼ 5ì¼ê°„ ì„¹í„°ë³„ ìê¸ˆ íë¦„(ìˆ˜ìµë¥ ):
    {sector_summary_text}

    **MISSION:**
    1.  **í†µí•© ë¶„ì„:** ìœ„ 3ê°€ì§€ ë°ì´í„°ë¥¼ ëª¨ë‘ ì—°ê²°í•˜ì—¬ ì‹œì¥ì˜ ì¢…í•©ì ì¸ ìƒíƒœë¥¼ ë¶„ì„í•˜ë¼. íŠ¹íˆ, ê±°ì‹œ ì§€í‘œì™€ ì„¹í„°ë³„ ìê¸ˆ íë¦„ ì‚¬ì´ì˜ 'ì¼ì¹˜ì ' ë˜ëŠ” 'ë¶ˆì¼ì¹˜ì 'ì„ ì°¾ì•„ë‚´ì•¼ í•œë‹¤.
    2.  **ìµœì¢… ë¸Œë¦¬í•‘ ìƒì„±:** ì•„ë˜ ì§€ì •ëœ í˜•ì‹ì— ë§ì¶°, ë‹¹ì‹ ì˜ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ë‹´ì€ ìµœì¢… ë¸Œë¦¬í•‘ì„ ìƒì„±í•˜ë¼.
    3.  **âœ¨ [ì¤‘ìš”] í•œ ë¬¸ì¥ ìš”ì•½:** ì „ì²´ ë¶„ì„ì˜ í•µì‹¬ ê²°ë¡ ì„ ë§¨ ì²« ì¤„ì— `[ìš”ì•½]` íƒœê·¸ë¥¼ ë¶™ì—¬ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•˜ë¼.

    **OUTPUT FORMAT:**
    [ìš”ì•½] (ëª¨ë“  ë¶„ì„ì„ ì••ì¶•í•œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ê²°ë¡  í•œ ë¬¸ì¥)

    ğŸ’¡ **AI ì‹œì¥ ì¢…í•© ì§„ë‹¨**
    * **ê°•ì„¸ ìš”ì¸ (Bullish Factors):** (ê¸ì •ì  ì§€í‘œ, ì¶”ì„¸, ë‰´ìŠ¤, ì„¹í„° íë¦„ ìš”ì•½)
    * **ì•½ì„¸ ìš”ì¸ (Bearish Factors):** (ë¶€ì •ì  ì§€í‘œ, ì¶”ì„¸, ë‰´ìŠ¤, ì„¹í„° íë¦„ ìš”ì•½)
    * **í•µì‹¬ ì¸ì‚¬ì´íŠ¸:** (ì§€í‘œì™€ ì„¹í„° íë¦„ ë“±ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ë°œê²¬í•œ ê°€ì¥ ì¤‘ìš”í•œ 'ì¼ì¹˜ì ' ë˜ëŠ” 'ëª¨ìˆœì 'ì— ëŒ€í•œ í•´ì„)
    * **ì¢…í•© ì½”ë©˜íŠ¸:** (í˜„ì¬ ì‹œì¥ êµ­ë©´ì— ëŒ€í•œ ìµœì¢…ì ì¸ ë…¼í‰)
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"[ìš”ì•½] AI ë¸Œë¦¬í•‘ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {e}"
# --- [MOD v35.7 End] ---


# --- [MOD v35.6 Start] ì„¹í„° ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ---
@st.cache_data(ttl=1800) # 30ë¶„ë§ˆë‹¤ ë°ì´í„° ê°±ì‹ 
def get_sector_performance():
    """11ê°œ ì£¼ìš” ì„¹í„° ETFì˜ ìµœê·¼ 5ì¼ê°„ì˜ ì„±ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    sector_tickers = {
        'Technology': 'XLK', 'Health Care': 'XLV', 'Financials': 'XLF',
        'Consumer Discretionary': 'XLY', 'Communication Services': 'XLC', 'Industrials': 'XLI',
        'Consumer Staples': 'XLP', 'Energy': 'XLE', 'Utilities': 'XLU',
        'Real Estate': 'XLRE', 'Materials': 'XLB'
    }
    try:
        data = yf.download(list(sector_tickers.values()), period="5d", progress=False)
        if data.empty:
            return pd.DataFrame()
        
        performance = {}
        for sector, ticker in sector_tickers.items():
            series = data['Close'][ticker].dropna()
            if len(series) >= 2:
                # 5ì¼ê°„ì˜ ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
                perf = (series.iloc[-1] / series.iloc[0] - 1) * 100
                performance[sector] = perf
        
        if not performance:
            return pd.DataFrame()

        perf_df = pd.DataFrame(list(performance.items()), columns=['Sector', 'Performance_5D'])
        return perf_df

    except Exception:
        return pd.DataFrame()
# --- [MOD v35.6 End] ---



# [ì‹ ê·œ] ë‹¤ë¥¸ ëª¨ë“  ë°ì´í„° í•¨ìˆ˜ì— ëŒ€í•œ í—ˆë¸Œ ê²½ìœ  í•¨ìˆ˜ë“¤

def create_hub_function(original_function, key_prefix, minutes_to_live=60):
    """
    ë°˜ë³µì ì¸ í—ˆë¸Œ í•¨ìˆ˜ ìƒì„±ì„ ìœ„í•œ íŒ©í† ë¦¬ í•¨ìˆ˜.
    """
    def hub_function(ticker):
        now = datetime.now()
        hub_key = f"{key_prefix}_{ticker}"
        
        if hub_key in st.session_state.data_hub:
            data, timestamp = st.session_state.data_hub[hub_key]
            if (now - timestamp) < timedelta(minutes=minutes_to_live):
                return data

        new_data = original_function(ticker)
        
        if new_data is not None: # ë°ì´í„°ê°€ Noneì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ì €ì¥
            st.session_state.data_hub[hub_key] = (new_data, now)
            
        return new_data
    return hub_function

# ê° ì›ë³¸ í•¨ìˆ˜ì— ëŒ€í•´ í—ˆë¸Œ ê²½ìœ  í•¨ìˆ˜ ìƒì„±
get_profile_from_hub = create_hub_function(get_company_profile, "profile")
get_news_from_hub = create_hub_function(get_company_news, "news")
get_financials_from_hub = create_hub_function(get_basic_financials, "financials")
get_peers_from_hub = create_hub_function(get_company_peers, "peers")
get_earnings_from_hub = create_hub_function(get_company_earnings, "earnings")
get_calendar_from_hub = create_hub_function(get_earnings_calendar, "calendar")
get_candles_from_hub = create_hub_function(get_stock_candles, "candles")


@st.cache_data
def get_analyst_ratings(ticker):
    """Finnhub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì• ë„ë¦¬ìŠ¤íŠ¸ í‰ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        ratings = finnhub_client.recommendation_trends(ticker)
        if ratings:
            # ê°€ì¥ ìµœì‹  ì›”ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©
            latest_rating = ratings[0]
            return {
                "period": latest_rating['period'],
                "strongBuy": latest_rating['strongBuy'],
                "buy": latest_rating['buy'],
                "hold": latest_rating['hold'],
                "sell": latest_rating['sell'],
                "strongSell": latest_rating['strongSell']
            }
    except Exception:
        return None
    return None

@st.cache_data
def get_insider_transactions(ticker):
    """Finnhub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ 90ì¼ê°„ì˜ ë‚´ë¶€ì ê±°ë˜ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        transactions = finnhub_client.stock_insider_transactions(ticker, _from=start_date.strftime('%Y-%m-%d'), to=end_date.strftime('%Y-%m-%d'))
        
        if transactions and 'data' in transactions and transactions['data']:
            df = pd.DataFrame(transactions['data'])
            # 'mspr'ëŠ” ì´ ê±°ë˜ ê¸ˆì•¡ì„ ì˜ë¯¸
            total_buy_value = df[df['change'] > 0]['mspr'].sum()
            total_sell_value = abs(df[df['change'] < 0]['mspr'].sum())
            net_value = total_buy_value - total_sell_value
            return {
                "totalBuyValue": total_buy_value,
                "totalSellValue": total_sell_value,
                "netValue": net_value
            }
    except Exception:
        return None
    return None

# ìƒˆë¡œìš´ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ì„ ì¤‘ì•™ í—ˆë¸Œì— ë“±ë¡
get_ratings_from_hub = create_hub_function(get_analyst_ratings, "ratings", minutes_to_live=1440) # í•˜ë£¨ì— í•œë²ˆ ê°±ì‹ 
get_insider_trans_from_hub = create_hub_function(get_insider_transactions, "insider", minutes_to_live=1440) # í•˜ë£¨ì— í•œë²ˆ ê°±ì‹ 


# [ì‹ ê·œ] 'ì¼ìƒ ê±´ê°•ê²€ì§„'ì„ ìˆ˜í–‰í•˜ëŠ” í†µí•© ë°ì´í„° ì²˜ë¦¬ê¸°
def get_health_check_data(ticker_list):
    """
    ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ 'ì¼ìƒ ê±´ê°•ê²€ì§„'ì„ ìˆ˜í–‰í•˜ê³ ,
    ê²°ê³¼ë¥¼ ë°ì´í„° í—ˆë¸Œì— ìºì‹œí•œ ë’¤ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    summary_list = []
    
    # yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì¢…ëª©ì˜ 1ë…„ì¹˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜´
    try:
        hist_data = yf.download(ticker_list, period="1y", progress=False)
        if hist_data.empty:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ì£¼ê°€ ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

    for ticker in ticker_list:
        hub_key = f"health_check_{ticker}"
        
        # 1. ìºì‹œ í™•ì¸ (1ì‹œê°„ì§œë¦¬ ìºì‹œ)
        now = datetime.now()
        if hub_key in st.session_state.data_hub:
            data, timestamp = st.session_state.data_hub[hub_key]
            if (now - timestamp) < timedelta(hours=1):
                summary_list.append(data)
                continue # ìºì‹œëœ ë°ì´í„° ì‚¬ìš©

        # 2. ë°ì´í„° ê³„ì‚° (ìºì‹œê°€ ì—†ì„ ê²½ìš°)
        try:
            # MultiIndexì—ì„œ ë‹¨ì¼ ì¢…ëª© ë°ì´í„° ì¶”ì¶œ
            if len(ticker_list) > 1:
                hist = hist_data.loc[:, (slice(None), ticker)]
                hist.columns = hist.columns.droplevel(1)
            else:
                hist = hist_data
            
            if hist.empty or len(hist) < 20: continue

            # í•µì‹¬ ì§€í‘œ ê³„ì‚°
            current_price = hist['Close'].iloc[-1]
            prev_price = hist['Close'].iloc[-2]
            change_percent = ((current_price - prev_price) / prev_price) * 100 if prev_price != 0 else 0
            high_52w = hist['High'].max()
            mdd_percent = ((current_price - high_52w) / high_52w) * 100 if high_52w != 0 else 0
            
            delta = hist['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs.iloc[-1]))
            
            volume_avg_20d = hist['Volume'].rolling(window=20).mean().iloc[-1]
            volume_change = (hist['Volume'].iloc[-1] / volume_avg_20d) * 100 if volume_avg_20d != 0 else 0

            ticker_summary = {
                "ì¢…ëª©ì½”ë“œ": ticker, "í˜„ì¬ê°€": current_price, "ë“±ë½ë¥ (%)": change_percent,
                "ê³ ì ëŒ€ë¹„(%)": mdd_percent, "RSI": rsi, "ê±°ë˜ëŸ‰(%)": volume_change
            }

            # 3. ê³„ì‚° ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            st.session_state.data_hub[hub_key] = (ticker_summary, now)
            summary_list.append(ticker_summary)

        except Exception:
            continue
            
    if not summary_list:
        return pd.DataFrame()
    
    df = pd.DataFrame(summary_list)
    # ë°ì´í„° íƒ€ì…ì„ ìˆ«ìë¡œ ëª…ì‹œì  ë³€í™˜
    numeric_cols = ["í˜„ì¬ê°€", "ë“±ë½ë¥ (%)", "ê³ ì ëŒ€ë¹„(%)", "RSI", "ê±°ë˜ëŸ‰(%)"]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        
    return df

# [âœ¨ NEW & REVISED] 'ì¢…í•© íŒ©í„° ì‹œíŠ¸'ë¥¼ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ í•µì‹¬ í•¨ìˆ˜
def create_factor_sheet(ticker, latest_log, candles_df, news, ratings, insider_trans):
    """
    ëª¨ë“  ë³€ê²½ì  íŒ©í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  AIì—ê²Œ ì „ë‹¬í•  'ì¢…í•© íŒ©í„° ì‹œíŠ¸' í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if latest_log is None:
        return "ê³¼ê±° ë¶„ì„ ê¸°ë¡ì´ ì—†ì–´ ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."

    sheet = [f"**[ì¢…í•© íŒ©í„° ì‹œíŠ¸: {ticker}]**"]
    
    # 1. ê³¼ê±° ë°ì´í„° ë¡œë“œ
    try:
        past_data = json.loads(latest_log.get('ì£¼ìš” ë°ì´í„°', '{}'))
        past_quote = past_data.get('quote', {})
        past_price = past_quote.get('c', 0)
    except Exception:
        past_price = 0

    # 2. ì‹œì¥ ë°ì´í„° íŒ©í„°
    if not candles_df.empty:
        current_price = candles_df['Close'].iloc[-1]
        market_factors = []
        if past_price > 0:
            price_change_cum = ((current_price - past_price) / past_price) * 100
            market_factors.append(f"- ëˆ„ì  ë³€ë™ë¥ : {price_change_cum:+.2f}% (vs. ë§ˆì§€ë§‰ ë¶„ì„)")
        
        price_change_recent = ((current_price - candles_df['Close'].iloc[-2]) / candles_df['Close'].iloc[-2]) * 100
        market_factors.append(f"- ìµœê·¼ ë³€ë™ë¥ : {price_change_recent:+.2f}% (vs. ì „ì¼)")

        if len(candles_df) > 20:
            avg_volume_20d = candles_df['Volume'].rolling(window=20).mean().iloc[-2] # ì „ì¼ê¹Œì§€ì˜ í‰ê· 
            current_volume = candles_df['Volume'].iloc[-1]
            if avg_volume_20d > 0:
                volume_change_percent = (current_volume / avg_volume_20d) * 100
                market_factors.append(f"- ê±°ë˜ëŸ‰: 20ì¼ í‰ê·  ëŒ€ë¹„ {volume_change_percent:.0f}% ìˆ˜ì¤€")
        
        if market_factors:
            sheet.append("\n**I. ì‹œì¥ ë°ì´í„°**\n" + "\n".join(market_factors))

    # 3. ê¸°ìˆ ì  ìƒíƒœ íŒ©í„° (candles_dfëŠ” ì´ë¯¸ ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ ìƒíƒœë¡œ ì „ë‹¬ë°›ì•„ì•¼ í•¨)
    if not candles_df.empty and 'SMA20' in candles_df.columns:
        tech_factors = []
        latest = candles_df.iloc[-1]
        previous = candles_df.iloc[-2]
        # RSI ìƒíƒœ ë³€í™”
        if previous['RSI14'] < 70 and latest['RSI14'] >= 70: tech_factors.append("- RSI ê³¼ë§¤ìˆ˜ êµ¬ê°„(70) ì§„ì…")
        elif previous['RSI14'] > 30 and latest['RSI14'] <= 30: tech_factors.append("- RSI ê³¼ë§¤ë„ êµ¬ê°„(30) ì§„ì…")
        # MACD ì‹ í˜¸
        if previous['MACD'] < previous['SignalLine'] and latest['MACD'] > latest['SignalLine']: tech_factors.append("- MACD ê³¨ë“  í¬ë¡œìŠ¤ ë°œìƒ")
        elif previous['MACD'] > previous['SignalLine'] and latest['MACD'] < latest['SignalLine']: tech_factors.append("- MACD ë°ë“œ í¬ë¡œìŠ¤ ë°œìƒ")
        
        if tech_factors:
            sheet.append("\n**II. ê¸°ìˆ ì  ìƒíƒœ**\n" + "\n".join(tech_factors))

    # 4. ê¸°ì—… ë° ì™¸ë¶€ í™˜ê²½ íŒ©í„°
    env_factors = []
    if news:
        past_news_headlines = past_data.get('news_headlines', [])
        current_news_headlines = [item['headline'] for item in news[:5]]
        new_headlines = [h for h in current_news_headlines if h not in past_news_headlines]
        if new_headlines:
            env_factors.append(f"- {len(new_headlines)}ê°œì˜ ì‹ ê·œ ì£¼ìš” ë‰´ìŠ¤ ë°œìƒ")

    if ratings:
        buy_ratings = ratings.get('strongBuy', 0) + ratings.get('buy', 0)
        total_ratings = buy_ratings + ratings.get('hold', 0) + ratings.get('sell', 0) + ratings.get('strongSell', 0)
        if total_ratings > 0:
            buy_ratio = (buy_ratings / total_ratings) * 100
            env_factors.append(f"- ìµœì‹  ì• ë„ë¦¬ìŠ¤íŠ¸ 'ë§¤ìˆ˜' ì˜ê²¬: {buy_ratio:.0f}% ({total_ratings}ëª… ì°¸ì—¬)")

    if insider_trans and insider_trans.get('netValue') != 0:
        if insider_trans['netValue'] > 0:
            env_factors.append(f"- ìµœê·¼ 90ì¼ê°„ ë‚´ë¶€ì ìˆœë§¤ìˆ˜: ì•½ ${insider_trans['netValue']:,.0f}")
        else:
            env_factors.append(f"- ìµœê·¼ 90ì¼ê°„ ë‚´ë¶€ì ìˆœë§¤ë„: ì•½ ${abs(insider_trans['netValue']):,.0f}")

    if env_factors:
        sheet.append("\n**III. ê¸°ì—… ë° ì™¸ë¶€ í™˜ê²½**\n" + "\n".join(env_factors))

    if len(sheet) == 1: # ì•„ë¬´ íŒ©í„°ë„ ì¶”ê°€ë˜ì§€ ì•Šì•˜ë‹¤ë©´
        return "ë§ˆì§€ë§‰ ë¶„ì„ ì´í›„ ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
    return "\n".join(sheet)


# --- 4. ë©”ì¸ UI ë° ë¡œì§ ---
st.title("ğŸ’ GEM: Finance Dashboard")
st.caption("v34.0 - Final Strategy Implemented")

# [ìˆ˜ì •] ëª¨ë“  ì„¸ì…˜ ìƒíƒœë¥¼ ì—¬ê¸°ì„œ í•œ ë²ˆì— ì´ˆê¸°í™”
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.active_view = "ğŸ”­ ì‹œì¥ ê±´ê°• ìƒíƒœ"
    st.session_state.data_hub = {}
    # ... ê¸°íƒ€ ì´ˆê¸°í™” í•„ìš”í•œ session_state ...

if not st.session_state.data_loaded:
    with st.spinner("Initializing System... Loading data from Google Sheets..."):
        st.session_state.portfolio_df, st.session_state.watchlist_df, st.session_state.cash_df = load_data_from_gsheet()
    st.session_state.data_loaded = True
    st.rerun() # ë°ì´í„°ë¥¼ ë¡œë“œí•œ í›„, ê¸°ë³¸ ë·°ë¥¼ ì œëŒ€ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´ í•œ ë²ˆ ë” ì¬ì‹¤í–‰

# --- í¬íŠ¸í´ë¦¬ì˜¤ ë·° ---
elif st.session_state.active_view == "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤":
    st.header("ğŸ’¼ Portfolio Command Center")
    
    portfolio_df = st.session_state.portfolio_df
    cash_df = st.session_state.cash_df

    if not portfolio_df.empty or not cash_df.empty:
        # [ìˆ˜ì •] ETF/êµ­ë‚´ì£¼ì‹ê³¼ ê°œë³„íˆ¬ì ì¢…ëª© ë¶„ë¦¬
        investment_df = portfolio_df[~portfolio_df['ì¢…ëª©ì½”ë“œ'].str.contains('.KS|.KQ', na=True, regex=True)]
        
        # [ìˆ˜ì •] ê°œë³„íˆ¬ì ì¢…ëª©ì— ëŒ€í•´ì„œë§Œ 'ì¼ìƒ ê±´ê°•ê²€ì§„' ìˆ˜í–‰
        health_check_df = pd.DataFrame()
        all_investment_tickers = investment_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        if all_investment_tickers:
            with st.spinner("ë³´ìœ  ìì‚° ìƒíƒœ ë¶„ì„ ì¤‘... (ì¼ìƒ ê±´ê°•ê²€ì§„ ìˆ˜í–‰)"):
                health_check_df = get_health_check_data(all_investment_tickers)

        # ê¸°ì¡´ í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€ì‹œë³´ë“œ ìƒì„± (ëª¨ë“  ì¢…ëª© ëŒ€ìƒ)
        all_tickers_for_price = portfolio_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        if all_tickers_for_price:
            current_prices, usd_krw_rate = get_current_prices_and_rate(all_tickers_for_price)
            st.sidebar.metric("USD/KRW í™˜ìœ¨", f"â‚©{usd_krw_rate:,.2f}")
            invest_dashboard_df = create_portfolio_dashboard(portfolio_df, current_prices, usd_krw_rate)
        else:
            invest_dashboard_df = pd.DataFrame()

        # [ìˆ˜ì •] ê±´ê°•ê²€ì§„ ê²°ê³¼ì™€ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ 'ì¢…ëª©ì½”ë“œ' ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
        if not health_check_df.empty and not invest_dashboard_df.empty:
            invest_dashboard_df = pd.merge(invest_dashboard_df, health_check_df, on='ì¢…ëª©ì½”ë“œ', how='left')

        # í˜„ê¸ˆ ìì‚° ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        cash_dashboard_df = pd.DataFrame()
        if not cash_df.empty:
            cash_dashboard_df = cash_df.rename(columns={'ê¸ˆì•¡(KRW)': 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'})
            cash_dashboard_df['ìˆ˜ìµë¥  (%)'] = 0
            cash_dashboard_df['ì†ìµ (ê³ ìœ )'] = 0
            cash_dashboard_df['ìˆ˜ëŸ‰'] = '-'
            cash_dashboard_df['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] = '-'
            cash_dashboard_df['í˜„ì¬ê°€ (ê³ ìœ )'] = '-'
        
        # [ìˆ˜ì •] í‘œì‹œí•  ì»¬ëŸ¼ì— ê±´ê°•ê²€ì§„ ê²°ê³¼ ì¶”ê°€
        display_cols = ['ê³„ì¢Œêµ¬ë¶„', 'ì¢…ëª©ëª…', 'ìì‚°í‹°ì–´', 'ìˆ˜ëŸ‰', 'í‰ê·  ë‹¨ê°€ (ê³ ìœ )', 'í˜„ì¬ê°€ (ê³ ìœ )', 
                        'ì†ìµ (ê³ ìœ )', 'ìˆ˜ìµë¥  (%)', 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)', 
                        'ê³ ì ëŒ€ë¹„(%)', 'RSI', 'ê±°ë˜ëŸ‰(%)']
        
        # ìµœì¢… ë°ì´í„°í”„ë ˆì„ ì¡°ë¦½
        final_dashboard_df = pd.concat([
            invest_dashboard_df,
            cash_dashboard_df
        ], ignore_index=True)

        # ìˆ«ì ì»¬ëŸ¼ íƒ€ì… ì •ë¦¬ (ê±´ê°•ê²€ì§„ ì»¬ëŸ¼ ì¶”ê°€)
        numeric_cols_final = ['ì†ìµ (ê³ ìœ )', 'ìˆ˜ìµë¥  (%)', 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)', 'ê³ ì ëŒ€ë¹„(%)', 'RSI', 'ê±°ë˜ëŸ‰(%)']
        for col in numeric_cols_final:
            if col in final_dashboard_df.columns:
                final_dashboard_df[col] = pd.to_numeric(final_dashboard_df[col], errors='coerce')

        # ì´ ìì‚° ìš”ì•½ ë©”íŠ¸ë¦­ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        total_value = final_dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
        total_cost = invest_dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].sum() if not invest_dashboard_df.empty else 0
        total_pl = invest_dashboard_df['ì†ìµ (KRW)'].sum() if not invest_dashboard_df.empty else 0
        total_pl_percent = (total_pl / total_cost) * 100 if total_cost > 0 else 0

        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ í‰ê°€ ìì‚°", f"â‚©{total_value:,.0f}")
        col2.metric("ì´ ì†ìµ (íˆ¬ììì‚°)", f"â‚©{total_pl:,.0f}", f"{total_pl_percent:.2f}%")
        col3.metric("ì´ íˆ¬ì ì›ê¸ˆ", f"â‚©{total_cost:,.0f}")
        st.divider()

        col1, col2 = st.columns([0.7, 0.3])
        with col1:
            st.subheader("ë³´ìœ  ìì‚° ìƒì„¸")
            
            # [ìˆ˜ì •] ë°ì´í„°í”„ë ˆì„ ìŠ¤íƒ€ì¼ë§ì— ê±´ê°•ê²€ì§„ ê²°ê³¼ í¬ë§· ì¶”ê°€
            formatter = {
                'ì†ìµ (ê³ ìœ )': '{:,.2f}', 
                'ìˆ˜ìµë¥  (%)': '{:.2f}%', 
                'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)': 'â‚©{:,.0f}',
                "ê³ ì ëŒ€ë¹„(%)": "{:,.2f}%", 
                "RSI": "{:.1f}", 
                "ê±°ë˜ëŸ‰(%)": "{:,.0f}%"
            }
            
            df_to_display = final_dashboard_df.reindex(columns=display_cols)

            st.dataframe(df_to_display.style
                .format(formatter, na_rep="-")
                .background_gradient(cmap='RdYlGn', subset=['ìˆ˜ìµë¥  (%)'])
                .bar(subset=['ê³ ì ëŒ€ë¹„(%)'], color='#FFA07A')
                .bar(subset=['RSI'], align='mid', color=['#d65f5f', '#5fba7d'])
                .bar(subset=['ê±°ë˜ëŸ‰(%)'], color='lightblue'), 
                use_container_width=True
            )
        
        with col2:
            st.subheader("ìì‚° ë°°ë¶„")
            chart_group_by = st.radio("ì°¨íŠ¸ ê¸°ì¤€", ['ìì‚°í‹°ì–´', 'ê³„ì¢Œêµ¬ë¶„'], horizontal=True, key='chart_group')
            filter_cols = st.columns(2)
            exclude_base = filter_cols[0].checkbox("'ê¸°ë°˜' í‹°ì–´ ì œì™¸", value=True)
            exclude_cash = filter_cols[1].checkbox("'í˜„ê¸ˆ' ìì‚° ì œì™¸", value=True)
            chart_df = final_dashboard_df.copy()
            
            if exclude_base and 'ìì‚°í‹°ì–´' in chart_df.columns:
                chart_df = chart_df[~chart_df['ìì‚°í‹°ì–´'].str.contains('ê¸°ë°˜', na=False)]
            if exclude_cash and 'ìì‚°í‹°ì–´' in chart_df.columns:
                chart_df = chart_df[~chart_df['ìì‚°í‹°ì–´'].str.contains('í˜„ê¸ˆ', na=False)]
            
            if not chart_df.empty and chart_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum() > 0:
                allocation = chart_df.groupby(chart_group_by)['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
                fig_tier = px.pie(values=allocation.values, names=allocation.index, title=f"{chart_group_by}ë³„ ë¹„ì¤‘", hole=.3)
                st.plotly_chart(fig_tier, use_container_width=True)
            else:
                st.warning("ì°¨íŠ¸ì— í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("Google Sheetsì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ë˜ëŠ” í˜„ê¸ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- [ì¶”ê°€] ë ˆì´ë” ë·° ---
elif st.session_state.active_view == "ğŸ“¡ ë ˆì´ë”":
    st.header("ğŸ“¡ Stock Radar")

    watchlist_df = st.session_state.watchlist_df

    if watchlist_df.empty or 'ì¢…ëª©ì½”ë“œ' not in watchlist_df.columns:
        st.info("ê´€ì‹¬ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. Google Sheetsì˜ 'Watchlist'ì— ì¢…ëª©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else:
        tickers = watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()

        # [ìˆ˜ì •] ìŠ¤í”¼ë„ˆ ë©”ì‹œì§€ë¥¼ í˜„ì¬ ì‘ì—…ì— ë§ê²Œ ë³€ê²½
        with st.spinner("ë ˆì´ë” ë°ì´í„°ë¥¼ ìŠ¤ìº”í•˜ëŠ” ì¤‘... (ì¼ìƒ ê±´ê°•ê²€ì§„ ìˆ˜í–‰)"):
            # [ìˆ˜ì •] ìƒˆë¡œìš´ 'í†µí•© ê±´ê°•ê²€ì§„ ëª¨ë“ˆ'ì„ í˜¸ì¶œí•˜ë„ë¡ ë³€ê²½
            radar_df = get_health_check_data(tickers)

        if not radar_df.empty:
            # [ë³€ê²½ ì—†ìŒ] ì´í•˜ ë°ì´í„°í”„ë ˆì„ ìŠ¤íƒ€ì¼ë§ ë° í‘œì‹œ ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•©ë‹ˆë‹¤.
            formatter = {
                "ë“±ë½ë¥ (%)": "{:,.2f}%",
                "ê³ ì ëŒ€ë¹„(%)": "{:,.2f}%",
                "RSI": "{:.1f}",
                "ê±°ë˜ëŸ‰(%)": "{:,.0f}%",
                "í˜„ì¬ê°€": lambda x: f"${x:,.2f}" # ê°„ë‹¨í•˜ê²Œ ë‹¬ëŸ¬ë¡œ í†µì¼ (ì¶”í›„ ê³ ë„í™” ê°€ëŠ¥)
            }

            st.dataframe(radar_df.style
                .format(formatter)
                .background_gradient(cmap='RdYlGn', subset=['ë“±ë½ë¥ (%)'])
                .bar(subset=['ê³ ì ëŒ€ë¹„(%)'], color='#FFA07A')
                .bar(subset=['RSI'], align='mid', color=['#d65f5f', '#5fba7d'])
                .bar(subset=['ê±°ë˜ëŸ‰(%)'], color='lightblue'),
                use_container_width=True
            )
        else:
            st.error("ë ˆì´ë” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

elif st.session_state.active_view == "ğŸ”­ ì‹œì¥ ê±´ê°• ìƒíƒœ":
    st.header("ğŸ”­ Market Health Dashboard")

    # --- [MOD v35.1 Start] AI ì‘ë‹µ ì²˜ë¦¬ ë¡œì§ ê°•í™” ---
    with st.spinner("AIê°€ ì‹œì¥ ê±´ê°• ìƒíƒœ ë° ìê¸ˆ íë¦„ì„ ì¢…í•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        market_data, hist_data = get_market_status_data()
        sector_perf_df = get_sector_performance() # ì„¹í„° ë°ì´í„° í˜¸ì¶œ
        
        hub_key = "market_briefing_v2" # í”„ë¡¬í”„íŠ¸ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ ìºì‹œ í‚¤ ë³€ê²½
        now = datetime.now()
        
        if hub_key in st.session_state.data_hub and (now - st.session_state.data_hub[hub_key][1]) < timedelta(minutes=5):
            briefing_text = st.session_state.data_hub[hub_key][0]
        else:
            # AI ë¸Œë¦¬í•‘ í•¨ìˆ˜ì— sector_perf_dfë„ í•¨ê»˜ ì „ë‹¬
            briefing_text = generate_market_health_briefing(market_data, hist_data, sector_perf_df)
            st.session_state.data_hub[hub_key] = (briefing_text, now)

    # --- [MOD v35.7 Start] ìš”ì•½ê³¼ ì „ë¬¸ ë¶„ë¦¬ í‘œì‹œ ---
    summary = ""
    full_report = ""
    if briefing_text:
        # ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        parts = briefing_text.split('\n', 1)
        # ì²« ì¤„ì´ [ìš”ì•½] íƒœê·¸ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
        if parts[0].startswith("[ìš”ì•½]"):
            summary = parts[0].replace("[ìš”ì•½]", "").strip()
            full_report = parts[1].strip() if len(parts) > 1 else ""
        else:
            # [ìš”ì•½] íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°, ì „ì²´ë¥¼ ì „ë¬¸ìœ¼ë¡œ ê°„ì£¼
            summary = "ìš”ì•½ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            full_report = briefing_text

    # ìš”ì•½ë³¸ì„ ë¨¼ì € í‘œì‹œ
    st.subheader("ğŸ’¡ AI ì¢…í•© ì§„ë‹¨ ìš”ì•½")
    st.info(summary)
    
    # ì „ë¬¸ì€ Expander ì•ˆì— í‘œì‹œ
    with st.expander("ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ë³´ê¸°"):
        if full_report:
            st.markdown(full_report)
        else:
            st.warning("ìƒì„¸ ë¦¬í¬íŠ¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
    # --- [MOD v35.7 End] ---

    if market_data:
        st.divider()
        st.subheader("ì£¼ìš” ì‹œì¥ ì§€ìˆ˜")
        
        cols = st.columns(8)
        indices = ["S&P 500", "Nasdaq", "KOSPI", "VIX", "US 10Y", "Dollar", "Crude Oil", "Gold"]
        
        for i, name in enumerate(indices):
            if name in market_data and market_data[name]["price"] != "N/A":
                d = market_data[name]
                if name in ["VIX", "US 10Y", "Dollar", "Crude Oil", "Gold"]:
                    cols[i].metric(label=name, value=f"{d['price']:.2f}", delta=f"{d['change']:.2f}")
                else:
                    cols[i].metric(label=name, value=f"{d['price']:,.2f}", delta=f"{d['change']:,.2f} ({d['change_percent']:.2f}%)")

        st.divider()

        # --- [MOD v35.6 Start] ì„¹í„° íˆíŠ¸ë§µ í‘œì‹œ ---
        st.divider()
        st.subheader("ì£¼ìš” ì„¹í„° ìê¸ˆ íë¦„ (5ì¼ ëˆ„ì )")
        
        sector_perf_df = get_sector_performance()
        
        if not sector_perf_df.empty:
            # [ìˆ˜ì •] Treemapì˜ 'values'ê°€ í•­ìƒ ì–‘ìˆ˜ì´ë„ë¡ ì ˆëŒ€ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            # ì´ë ‡ê²Œ í•˜ë©´ íƒ€ì¼ì˜ 'í¬ê¸°'ëŠ” ë³€í™”ì˜ í¬ê¸°ë¥¼, 'ìƒ‰ìƒ'ì€ ìƒìŠ¹/í•˜ë½ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
            fig = px.treemap(sector_perf_df, 
                            path=[px.Constant("S&P 500 Sectors"), 'Sector'], 
                            values=sector_perf_df['Performance_5D'].abs(), # <-- í•µì‹¬ ìˆ˜ì •
                            color='Performance_5D',
                            color_continuous_scale=['#d65f5f', 'lightgray', '#5fba7d'], # Red-Gray-Green
                            color_continuous_midpoint=0,
                            custom_data=['Performance_5D']) # íˆ´íŒ ë° í…ìŠ¤íŠ¸ í‘œì‹œìš© ì›ë³¸ ë°ì´í„°

            # íƒ€ì¼ ìœ„ì— ì„¹í„° ì´ë¦„ê³¼ ì‹¤ì œ ìˆ˜ìµë¥ (%)ì„ ì •í™•íˆ í‘œì‹œ
            fig.update_traces(texttemplate='%{label}<br>%{customdata[0]:.2f}%')
            
            fig.update_layout(margin=dict(t=25, l=0, r=0, b=0)) # ìƒë‹¨ ì—¬ë°± ì¶”ê°€
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("ì„¹í„° ì„±ê³¼ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        # --- [MOD v35.6 End] ---

        st.subheader("ì£¼ìš” ê²½ì œ ë‰´ìŠ¤")
        if market_data.get('news'):
            for item in market_data['news']:
                news_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d')
                st.markdown(f"**[{item['headline']}]({item['url']})** - *{news_date}, {item['source']}*")
        else:
            st.warning("ì£¼ìš” ê²½ì œ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("ì‹œì¥ í˜„í™© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


elif st.session_state.active_view == "ğŸ“¡ íƒìƒ‰":
    st.header("ğŸ“¡ Discovery Engine: Status Tracker")
    st.info("ì„ íƒí•œ ì‹œì¥ì˜ ì „ì²´ ì¢…ëª©ì— ëŒ€í•œ ê¸°ìˆ ì  ìƒíƒœë¥¼ ë¶„ì„í•˜ê³ , í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìƒíƒœ íƒœê·¸ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.")

    # --- ìƒíƒœ(Status) íŒì • ê¸°ì¤€ ì„¤ëª… ---
    with st.expander("â„¹ï¸ ìƒíƒœ(Status) íŒì • ê¸°ì¤€"):
        st.markdown("""
        - **ë§¤ìˆ˜ ì‹ í˜¸ ğŸŸ¢**: ê³¨ë“ í¬ë¡œìŠ¤ê°€ ë°œìƒí–ˆê±°ë‚˜, RSIê°€ 30 ì´í•˜ ê³¼ë§¤ë„ êµ¬ê°„ì— ì§„ì…í•œ ì¢…ëª©.
        - **ì£¼ì˜/ë§¤ë„ ì‹ í˜¸ ğŸ”´**: ë°ë“œí¬ë¡œìŠ¤ê°€ ë°œìƒí–ˆê±°ë‚˜, RSIê°€ 70 ì´ìƒ ê³¼ë§¤ìˆ˜ êµ¬ê°„ì— ì§„ì…í•œ ì¢…ëª©.
        - **ì¤‘ë¦½/ê´€ë§ âšªï¸**: ìœ„ ì‹ í˜¸ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ë‚˜ë¨¸ì§€ ëª¨ë“  ì¢…ëª©.
        """)

    ticker_lists = get_all_ticker_lists()
    
    if not ticker_lists:
        st.warning("'Tickers' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. Google Sheetsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        selected_list_name = st.selectbox("íƒìƒ‰ ëŒ€ìƒ ì‹œì¥ ì„ íƒ:", list(ticker_lists.keys()))
        
        if st.button(f"ğŸš€ {selected_list_name} ì „ì²´ ì¢…ëª© ìƒíƒœ ë¶„ì„", use_container_width=True, type="primary"):
            tickers_to_scan = ticker_lists.get(selected_list_name, [])
            st.session_state.screener_results = run_status_screener(tickers_to_scan)
            st.rerun()

    if "screener_results" in st.session_state:
        st.divider()
        results_df = st.session_state.screener_results
        
        st.subheader(f"ğŸ“Š ìƒíƒœ ë¶„ì„ ê²°ê³¼: {len(results_df)}ê°œ ì¢…ëª©")

        if not results_df.empty:
            # ë“±ë½ë¥ (%) ê°’ì— ë”°ë¼ í°íŠ¸ ìƒ‰ìƒì„ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
            def style_change_percent(val):
                color = 'red' if val < 0 else 'green' if val > 0 else '#525252' # íšŒìƒ‰
                return f'color: {color}'

            st.dataframe(
                results_df.style
                    .applymap(style_change_percent, subset=['ë“±ë½ë¥ (%)'])
                    .format({
                        "í˜„ì¬ê°€": "${:,.2f}",
                        "ë“±ë½ë¥ (%)": "{:+.2f}%",
                        "ê³ ì ëŒ€ë¹„(%)": "{:.2f}%",
                        "RSI": "{:.1f}",
                    }),
                hide_index=True,
                use_container_width=True,
                height=800
            )
        else:
            st.error("ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‹°ì»¤ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")



# --- ìƒì„¸ ë¶„ì„ ë·° ---
elif st.session_state.active_view == "ğŸ” ìƒì„¸ ë¶„ì„":
    if 'analysis_tickers' in st.session_state and st.session_state.analysis_tickers:
        main_ticker = st.session_state.analysis_tickers[0]
        st.header(f"ğŸ” {main_ticker} ìƒì„¸ ë¶„ì„")

        # --- 1. ê¸°ì´ˆ ë°ì´í„° ë¡œë“œ ---
        with st.spinner(f"'{main_ticker}' ìƒì„¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            profile = get_profile_from_hub(main_ticker)
            quote = get_quote_from_hub(main_ticker)
            news = get_news_from_hub(main_ticker)
            financials_df = get_financials_from_hub(main_ticker)
            peers = get_peers_from_hub(main_ticker)
            earnings_data = get_earnings_from_hub(main_ticker)
            next_earnings_date = get_calendar_from_hub(main_ticker)
            candles_df = get_candles_from_hub(main_ticker)

        # --- 2. íƒ­ UI ìƒì„± ---
        analysis_tab_names = ["ğŸ’ ì¢…í•© ì§„ë‹¨", "ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„", "ğŸ’° í€ë”ë©˜í„¸", "ğŸ“° ë‰´ìŠ¤ ë° ê°œìš”", "ğŸ“œ ê³¼ê±° ë¶„ì„ ê¸°ë¡"]
        diag_tab, tech_tab, fin_tab, news_tab, log_tab = st.tabs(analysis_tab_names)

        # [í•µì‹¬ ìˆ˜ì •] 'ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›' ë¡œì§ ê°•í™”
        # Ticker ë³€ê²½ ì‹œ, ì´ì „ ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
        if 'current_ticker' not in st.session_state or st.session_state.current_ticker != main_ticker:
            st.session_state.current_ticker = main_ticker
            st.session_state.last_analysis_text = None
            st.session_state.structured_reco = {}
            # âœ¨ NEW: Ticker ë³€ê²½ ì‹œ ìµœì‹  ë¡œê·¸ë¥¼ ë¶ˆëŸ¬ì™€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            with st.spinner(f"'{main_ticker}'ì˜ ìµœê·¼ ë¶„ì„ ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                analysis_logs = load_analysis_log(main_ticker)
                if not analysis_logs.empty:
                    latest_log = analysis_logs.iloc[0]
                    st.session_state.last_analysis_text = latest_log.get('ì „ì²´ ë¶„ì„ ë‚´ìš©')
                    st.session_state.last_analysis_ticker = main_ticker
                st.rerun() # ìµœì‹  ë¡œê·¸ë¥¼ ë°˜ì˜í•˜ì—¬ í™”ë©´ì„ ë‹¤ì‹œ ê·¸ë¦½ë‹ˆë‹¤.

                        # --- 3. ê° íƒ­ ë‚´ìš© êµ¬ì„± ---
# --- 3. ê° íƒ­ ë‚´ìš© êµ¬ì„± ---
        with diag_tab:
            st.subheader(f"ğŸ’ {main_ticker} ì¢…í•© ì§„ë‹¨")
            cols = st.columns(4)
            if quote and quote.get('c') != 0:
                cols[0].metric("í˜„ì¬ê°€", f"${quote.get('c', 0):.2f}", f"{quote.get('d', 0):.2f}$ ({quote.get('dp', 0):.2f}%)")
            if not candles_df.empty:
                candles_df_tech_diag = add_technical_indicators(candles_df.copy())
                if 'RSI14' in candles_df_tech_diag.columns and not pd.isna(candles_df_tech_diag['RSI14'].iloc[-1]):
                    cols[1].metric("RSI (14ì¼)", f"{candles_df_tech_diag['RSI14'].iloc[-1]:.2f}")
                high_52w = candles_df['High'].max()
                if high_52w > 0:
                    cols[2].metric("52ì£¼ ê³ ì  ëŒ€ë¹„", f"{((quote.get('c', 0) - high_52w) / high_52w) * 100:.2f}%")
            if profile:
                cols[3].metric("ì‹œê°€ì´ì•¡ (M)", f"${profile.get('marketCapitalization', 0):,.0f}")

            st.divider()
            st.subheader("ğŸ¤– AI ì „ëµ ë¶„ì„")

            # [âœ¨ FINAL] ë‘ ë²„íŠ¼ì„ 'AI ì¢…í•© ë¶„ì„' ë‹¨ì¼ ë²„íŠ¼ìœ¼ë¡œ í†µí•©
            if st.button("ğŸ’¡ AI ì¢…í•© ë¶„ì„", use_container_width=True, type="primary"):
                # ì´ì „ ë¶„ì„ ê²°ê³¼ ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.changelog_for_display = ""
                st.session_state.last_analysis_text = "" 

                analysis_logs = load_analysis_log(main_ticker)

                # --- ë¶„ê¸° ë¡œì§: ê¸°ë¡ ìœ ë¬´ì— ë”°ë¼ ì§€ëŠ¥í˜• ë¶„ì„ ë˜ëŠ” ì „ì²´ ë¶„ì„ ìˆ˜í–‰ ---
                if not analysis_logs.empty:
                    # [CASE 1: ê¸°ë¡ ìˆìŒ -> ì§€ëŠ¥í˜• ë¶„ì„ ìˆ˜í–‰]
                    with st.spinner("1/3) ì¢…í•© íŒ©í„° ì‹œíŠ¸ ìƒì„± ì¤‘..."):
                        latest_log = analysis_logs.iloc[0]
                        previous_analysis_text = latest_log.get('ì „ì²´ ë¶„ì„ ë‚´ìš©', '')
                        candles_with_indicators = add_technical_indicators(candles_df.copy())
                        ratings = get_ratings_from_hub(main_ticker)
                        insider_trans = get_insider_trans_from_hub(main_ticker)
                        factor_sheet = create_factor_sheet(main_ticker, latest_log, candles_with_indicators, news, ratings, insider_trans)
                    
                    with st.spinner("2/3) íŒ©í„° ê¸°ë°˜ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì¤‘..."):
                        evolved_report = "".join(list(stream_evolved_report(previous_analysis_text, factor_sheet, main_ticker)))
                        st.session_state.last_analysis_text = evolved_report
                        st.session_state.last_analysis_ticker = main_ticker

                    with st.spinner("3/3) AIê°€ ë³€ê²½ ë‚´ì—­ ë¸Œë¦¬í•‘ì„ ìƒì„± ì¤‘..."):
                        changelog_header = f"ğŸ’¡ **AI ë³€ê²½ì  ë¸Œë¦¬í•‘ (Changelog)**\n\n**[AIê°€ ì…ë ¥ë°›ì€ ì¢…í•© íŒ©í„° ì‹œíŠ¸]**\n```\n{factor_sheet}\n```\n---"
                        ai_briefing = generate_changelog(previous_analysis_text, evolved_report, factor_sheet)
                        st.session_state.changelog_for_display = changelog_header + "\n\n" + ai_briefing
                
                else:
                    # [CASE 2: ê¸°ë¡ ì—†ìŒ -> ì²« ì „ì²´ ë¶„ì„ ìˆ˜í–‰]
                    st.info("ì²« ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì „ì²´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
                    with st.spinner("AIê°€ ìµœì‹  ì •ë³´ë¡œ ì „ì²´ ë¶„ì„ì„ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                        # 'ì°¸ê³  ìë£Œ'ëŠ” ì œê±°í•˜ê³  'í•µì‹¬ ì§€ì¹¨'ë§Œ ì „ë‹¬
                        core_principle_files = synchronize_knowledge_files()
                        
                        # ì „ì²´ ë¶„ì„ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„° ì¤€ë¹„ (ê¸°ì¡´ 'ì „ì²´ ì¬ë¶„ì„' ë¡œì§ê³¼ ë™ì¼)
                        portfolio_df, _, cash_df = load_data_from_gsheet()
                        holding_context = f"í˜„ì¬ {main_ticker} ì¢…ëª©ì€ ë³´ìœ í•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
                        if not portfolio_df.empty and main_ticker in portfolio_df['ì¢…ëª©ì½”ë“œ'].values:
                            holding_info = portfolio_df[portfolio_df['ì¢…ëª©ì½”ë“œ'] == main_ticker].iloc[0]
                            shares, avg_price_usd = holding_info.get('ìˆ˜ëŸ‰', 0), holding_info.get('í‰ê·  ë‹¨ê°€(USD)', 0)
                            holding_context = f"í˜„ì¬ ë¶„ì„ ëŒ€ìƒì¸ {main_ticker} ì¢…ëª©ì€ {shares}ì£¼ë¥¼ í‰ê·  ë‹¨ê°€ ${avg_price_usd:,.2f}ì— ë³´ìœ  ì¤‘ì…ë‹ˆë‹¤."

                        investable_cash, emergency_cash = 0, 0
                        if not cash_df.empty:
                            investable_mask = cash_df['ì¢…ëª©ëª…'].str.contains('CMA', na=False)
                            investable_cash = cash_df.loc[investable_mask, 'ê¸ˆì•¡(KRW)'].sum()
                            emergency_mask = cash_df['ì¢…ëª©ëª…'].str.contains('ë¹„ìƒê¸ˆ', na=False)
                            emergency_cash = cash_df.loc[emergency_mask, 'ê¸ˆì•¡(KRW)'].sum()

                        cash_context = f"ê·¸ ì™¸ì—, ì¶”ê°€ë¡œ íˆ¬ì ê°€ëŠ¥í•œ í˜„ê¸ˆ(CMA)ì€ ì•½ {investable_cash:,.0f}ì› ë³´ìœ  ì¤‘ì´ë©°, ë¹„ìƒê¸ˆì€ ì•½ {emergency_cash:,.0f}ì›ì…ë‹ˆë‹¤."
                        full_context = f"{holding_context}\n{cash_context}"

                        tech_summary = generate_technical_summary(add_technical_indicators(candles_df.copy()))
                        support_levels = calculate_support_levels(candles_df)
                        dynamic_trends = calculate_dynamic_trends(candles_df.copy(), quote)
                        market_context = get_market_status_data()

                        # AI í˜¸ì¶œ (reference_files ì¸ì ì—†ì´ í˜¸ì¶œ)
                        full_analysis_text = "".join(list(stream_and_capture_analysis(main_ticker, profile, quote, financials_df, tech_summary, news, full_context, support_levels, dynamic_trends, market_context, core_principle_files)))
                        st.session_state.last_analysis_text = full_analysis_text
                        st.session_state.last_analysis_ticker = main_ticker

                st.rerun()

            st.markdown("---")

            # âœ¨ FINAL REVISED: í†µí•©ëœ 'ìµœì¢… ë¶„ì„ ê²°ê³¼' í‘œì‹œ ë¡œì§
            # ì§€ëŠ¥í˜• ì¬ë¶„ì„ ê²°ê³¼ ë¸Œë¦¬í•‘ì„ ë¨¼ì € í‘œì‹œ
            if "changelog_for_display" in st.session_state and st.session_state.changelog_for_display:
                with st.expander("ğŸ’¡ AI ë³€ê²½ì  ë¸Œë¦¬í•‘", expanded=True):
                    st.markdown(st.session_state.changelog_for_display)
            
            # í•­ìƒ 'ê³µì‹ì ì¸ ìµœì¢… ë¶„ì„ ê²°ê³¼'ë¥¼ í‘œì‹œ (ì§€ëŠ¥í˜•/ì „ì²´ ë¶„ì„ ëª¨ë‘ ì—¬ê¸°ì— ë°˜ì˜ë¨)
            if st.session_state.get("last_analysis_text") and st.session_state.get("last_analysis_ticker") == main_ticker:
                st.subheader("ğŸ’¡ AI ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                st.markdown(st.session_state.last_analysis_text)
                
                # ì €ì¥ ë²„íŠ¼ ë¡œì§ì€ ì´ì œ í•­ìƒ ì •í™•í•˜ê²Œ ì‘ë™
                if st.button("ğŸ’¾ í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì €ì¥", key=f"gemini_save_{main_ticker}"):
                    with st.spinner("ë¶„ì„ ê²°ê³¼ë¥¼ Google Sheetsì— ì €ì¥í•˜ëŠ” ì¤‘..."):
                        tech_summary_save = generate_technical_summary(add_technical_indicators(candles_df.copy()))
                        support_levels_save = calculate_support_levels(candles_df)
                        data_snapshot = {
                            "profile": profile, "quote": quote,
                            "news_headlines": [item['headline'] for item in news[:5]] if news else [],
                            "tech_summary": tech_summary_save, "support_levels": support_levels_save
                        }
                        
                        analysis_text_to_save = st.session_state.get("last_analysis_text", "")
                        try:
                            summary_text = analysis_text_to_save.split("#### 4.")[0].strip().replace("*", "").replace("#", "")[-200:] + "..."
                        except Exception:
                            summary_text = analysis_text_to_save.strip().replace("*","").replace("#","")[:200] + "..."
                        
                        log_entry = {
                            "Timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            "ì¢…ëª©ì½”ë“œ": main_ticker,
                            "AI_Model": st.session_state.get("last_model_used", "N/A"),
                            "ë‹¹ì‹œ ì£¼ê°€": quote.get('c', 0) if quote else 0,
                            "ë¶„ì„ ìš”ì•½": summary_text,
                            "ì „ì²´ ë¶„ì„ ë‚´ìš©": analysis_text_to_save,
                            "ì£¼ìš” ë°ì´í„°": json.dumps(data_snapshot, ensure_ascii=False, indent=2)
                        }

                        if save_analysis_to_gsheet(log_entry):
                            st.toast("âœ… ë¶„ì„ ê²°ê³¼ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")
                            st.cache_data.clear() # ìºì‹œ í´ë¦¬ì–´ í›„ ì¬ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë¡œê·¸ ë°˜ì˜
                            st.rerun()
                        else:
                            st.error("ë¶„ì„ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. 'ì¬ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ìƒˆ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ì´í•˜ ë‹¤ë¥¸ íƒ­ë“¤(tech_tab, fin_tab, news_tab, log_tab)ì˜ ë¡œì§ì€ ê¸°ì¡´ ì½”ë“œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        # [ì¤‘ìš”] ë‹¨, ê° íƒ­ì—ì„œ parsed_dataë¥¼ ì°¸ì¡°í•˜ê¸° ì „ì—, st.session_state.last_analysis_textë¥¼ íŒŒì‹±í•˜ëŠ” ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.
        
        # 'ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›' íŒŒì‹± ë¡œì§ (ê° íƒ­ ë Œë”ë§ ì§ì „ì— ìœ„ì¹˜)
        parsed_data = {}
        if st.session_state.get("last_analysis_text"):
            parsed_data = structure_recommendation(st.session_state.last_analysis_text)
       

        with tech_tab:
            st.subheader("ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„")

            if parsed_data and parsed_data.get('technical_briefing'):
                st.info(parsed_data['technical_briefing'])

            if not candles_df.empty and len(candles_df) > 60:
                candles_df_tech = add_technical_indicators(candles_df.copy())
                st.divider()
                st.subheader("AI ì¶”ì²œ ë§¤ë§¤ êµ¬ê°„ ì‹œê°í™”")
                fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05, subplot_titles=('Candlestick & AI Zones', 'MACD', 'RSI'), row_heights=[0.6, 0.2, 0.2])
                fig.add_trace(go.Candlestick(x=candles_df_tech['Date'], open=candles_df_tech['Open'], high=candles_df_tech['High'], low=candles_df_tech['Low'], close=candles_df_tech['Close'], name='Price'), row=1, col=1)

                if parsed_data:
                    buy_zones = parsed_data.get('buy_zones')
                    sell_zones = parsed_data.get('sell_zones')
                    if buy_zones and buy_zones.get('zone1'):
                        fig.add_hrect(y0=buy_zones['zone1'][0], y1=buy_zones['zone1'][1], line_width=0, fillcolor="green", opacity=0.2, annotation_text="1st Buy Zone", annotation_position="bottom right", row=1, col=1)
                    if sell_zones and sell_zones.get('zone1'):
                        fig.add_hrect(y0=sell_zones['zone1'][0], y1=sell_zones['zone1'][1], line_width=0, fillcolor="red", opacity=0.2, annotation_text="1st Sell Zone", annotation_position="bottom right", row=1, col=1)
                
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SMA20'], name='SMA 20', line=dict(color='orange', width=1)), row=1, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SMA60'], name='SMA 60', line=dict(color='purple', width=1)), row=1, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['MACD'], name='MACD', line=dict(color='blue', width=1)), row=2, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SignalLine'], name='Signal Line', line=dict(color='red', width=1)), row=2, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['RSI14'], name='RSI 14', line=dict(color='royalblue', width=1)), row=3, col=1)
                fig.add_hline(y=70, line_dash="dash", line_color="red", row=3, col=1)
                fig.add_hline(y=30, line_dash="dash", line_color="green", row=3, col=1)
                fig.update_layout(height=800, xaxis_rangeslider_visible=False)
                st.plotly_chart(fig, use_container_width=True)
            else: 
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ì°¨íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë§¤ìˆ˜ êµ¬ê°„ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            
        with fin_tab:
            st.subheader("ğŸ’° í€ë”ë©˜í„¸ ë¶„ì„")
            # [ì‹ ê·œ] AI í€ë”ë©˜í„¸ ë¸Œë¦¬í•‘ í‘œì‹œ
            if parsed_data.get('fundamental_briefing'):
                st.info(parsed_data['fundamental_briefing'])

            st.divider()

            st.subheader("í•µì‹¬ ì¬ë¬´ ì§€í‘œ (ì—°ê°„)")
            if not financials_df.empty: st.dataframe(financials_df.style.format("{:,.2f}", na_rep="-"))
            else: st.warning(f"'{main_ticker}'ì— ëŒ€í•œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.subheader("ë¶„ê¸°ë³„ ì‹¤ì  ë°œí‘œ ë‚´ì—­")
            if not earnings_data.empty:
                format_dict = {'ì‹¤ì œ EPS': '{:.2f}', 'ì˜ˆìƒ EPS': '{:.2f}', 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)': '{:.2f}%'}
                st.dataframe(earnings_data.style.format(format_dict, na_rep="-"))
                if 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)' in earnings_data.columns:
                    fig_earn = px.bar(earnings_data, x='ë°œí‘œ ë¶„ê¸°', y='EPS ì„œí”„ë¼ì´ì¦ˆ (%)', color='EPS ê²°ê³¼', color_discrete_map={'Beat': 'green', 'Miss': 'red', 'Meet': 'blue'})
                    st.plotly_chart(fig_earn, use_container_width=True)
            else: st.warning(f"'{main_ticker}'ì— ëŒ€í•œ ì‹¤ì  ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.subheader("ê²½ìŸì‚¬ ë¹„êµ")
            if peers:
                peer_df = get_peer_summary([p for p in peers if p != main_ticker][:5])
                if not peer_df.empty: st.dataframe(peer_df.set_index('Ticker').style.format({"Market Cap (M)": "{:,.0f}", "% Change": "{:.2f}%"}, na_rep="-").background_gradient(cmap='RdYlGn', subset=['% Change']))
                else: st.info("ê²½ìŸì‚¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else: st.info("ê²½ìŸì‚¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        with news_tab:
            st.subheader("ğŸ“° ë‰´ìŠ¤ ë° ê¸°ì—… ê°œìš”")
            # [ì‹ ê·œ] AI ë‰´ìŠ¤ ë¸Œë¦¬í•‘ í‘œì‹œ
            if parsed_data.get('news_briefing'):
                st.info(parsed_data['news_briefing'])

            st.divider()
            if profile:
                st.subheader(f"ê¸°ì—… í”„ë¡œí•„: {profile.get('name', main_ticker)}")
                col1, col2 = st.columns([1, 4]); col1.image(profile.get('logo'), width=100)
                with col2: st.text(f"Industry: {profile.get('finnhubIndustry')}"); st.link_button("Visit Website", profile.get('weburl'))
                if next_earnings_date: st.info(f"**ë‹¤ìŒ ì‹¤ì  ë°œí‘œ ì˜ˆì •ì¼:** {next_earnings_date}")
            else: st.warning("ê¸°ì—… í”„ë¡œí•„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.divider()
            st.subheader("ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤")
            if news:
                for item in news[:10]:
                    news_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d %H:%M')
                    st.markdown(f"**[{item['headline']}]({item['url']})**\n- *Source: {item['source']} | {news_date}*")
            else: st.info("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with log_tab:
            st.subheader("ğŸ“œ ê³¼ê±° ë¶„ì„ ê¸°ë¡ ë³´ê´€ì†Œ")
            analysis_logs = load_analysis_log(main_ticker)
            if not analysis_logs.empty:
                for index, row in analysis_logs.iterrows():
                    log_time = pd.to_datetime(row['Timestamp']).strftime('%Y-%m-%d %H:%M')
                    with st.expander(f"**{log_time}** | ë‹¹ì‹œ ì£¼ê°€: ${float(row.get('ë‹¹ì‹œ ì£¼ê°€', 0)):.2f}"):
                        st.markdown(row.get('ì „ì²´ ë¶„ì„ ë‚´ìš©', 'ì €ì¥ëœ ì „ì²´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'))
            else:
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ê³¼ê±° ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  Tickerë¥¼ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒì„¸ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")


        
with st.sidebar:
    st.header("Controls")
    view_options = ["ğŸ”­ ì‹œì¥ ê±´ê°• ìƒíƒœ", "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤", "ğŸ“¡ ë ˆì´ë”", "ğŸ“¡ íƒìƒ‰", "ğŸ” ìƒì„¸ ë¶„ì„"] #<-- ì´ë ‡ê²Œ ë³€ê²½
    
    # st.radioì˜ í˜„ì¬ ì„ íƒê°’ì„ selected_view ë³€ìˆ˜ì— ì €ì¥
    selected_view = st.radio(
        "Select View", 
        view_options, 
        index=view_options.index(st.session_state.active_view), 
        #horizontal=True,
        key="view_selector"
    )
    
    if selected_view != st.session_state.active_view:
        st.session_state.active_view = selected_view
        st.rerun()

    st.divider()
    
    default_tickers = ""
    if not st.session_state.watchlist_df.empty and 'ì¢…ëª©ì½”ë“œ' in st.session_state.watchlist_df.columns:
        default_tickers = ", ".join(st.session_state.watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist())
    
    tickers_input = st.text_area("Ticker(s) for Analysis", value=default_tickers, help="ë¶„ì„í•  ì¢…ëª©ì˜ Tickerë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”.")
    
    if st.button("ğŸ” ë¶„ì„ ì‹¤í–‰", use_container_width=True, type="primary"):
        # --- âœ¨ NEW: ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘ ì‹œ, ì´ì „ ë¶„ì„ ê¸°ë¡ ì´ˆê¸°í™” ---
        # ì´ì „ì— ë‚¨ì•„ìˆì„ ìˆ˜ ìˆëŠ” ëª¨ë“  ë¶„ì„ ê²°ê³¼ ê´€ë ¨ ì„¸ì…˜ ìƒíƒœë¥¼ ê¹¨ë—í•˜ê²Œ ë¹„ì›ë‹ˆë‹¤.
        keys_to_clear = [
            "last_analysis_text", 
            "last_analysis_ticker", 
            "changelog_for_display",
            "beta_analysis_result", # í˜¹ì‹œ ëª¨ë¥¼ ì´ì „ ë² íƒ€ ê²°ê³¼ë„ í•¨ê»˜ ì œê±°
            "beta_changelog",
            "beta_evolved_report"
        ]
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        # -----------------------------------------------------------

        st.session_state.analysis_tickers = [ticker.strip().upper() for ticker in tickers_input.replace(',', '\n').split('\n') if ticker.strip()]
        st.session_state.active_view = "ğŸ” ìƒì„¸ ë¶„ì„"
        # st.session_state.last_analysis_text = None # ìœ„ì—ì„œ delë¡œ ëŒ€ì²´ë˜ì—ˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì‚­ì œ
        st.session_state.last_saved_ticker = None
        st.rerun()

    st.divider()
    st.info("í¬íŠ¸í´ë¦¬ì˜¤, í˜„ê¸ˆ, ê´€ì‹¬ì¢…ëª©ì€ Google Sheetsì—ì„œ ì§ì ‘ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
    if st.button("ğŸ”„ Reload Data & Clear Cache", use_container_width=True):
        st.session_state.clear()
        st.cache_data.clear()
        st.rerun()

