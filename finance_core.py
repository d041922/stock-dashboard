# dashboard_v34_final.py

import streamlit as st
import finnhub
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import yfinance as yf
import google.generativeai as genai
import gspread
from google.oauth2.service_account import Credentials
import json
import re  # Add this line
from googleapiclient.discovery import build # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
from io import BytesIO
from googleapiclient.http import MediaIoBaseDownload
import tempfile # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
import os       # <-- ì´ ë¼ì¸ì„ ì¶”ê°€
from PyPDF2 import PdfReader
from fredapi import Fred # íŒŒì¼ ìƒë‹¨ import ë¶€ë¶„ì— ì¶”ê°€


# --- 1. ì´ˆê¸° ì„¤ì • ë° ë¡œê·¸ì¸ ---
st.set_page_config(page_title="GEM: Finance Dashboard", page_icon="ğŸ’", layout="wide")

def login():
    if "authenticated" not in st.session_state: st.session_state["authenticated"] = False
    if not st.session_state["authenticated"]:
        st.title("ğŸ’ GEM: Finance Dashboard")
        st.caption("MASTER, please enter the password to access the command center.")
        password = st.text_input("Enter password:", type="password")
        if st.button("Login"):
            if "password" in st.secrets and password == st.secrets["password"]:
                st.session_state["authenticated"] = True
                st.rerun()
            else:
                st.error("Incorrect password or password not set in secrets.toml ğŸš«")
        st.stop()

login()

# --- 2. API í‚¤ ë° ì¸ì¦ ì„¤ì • ---
try:
    FINNHUB_API_KEY = st.secrets["FINNHUB_API_KEY"]
    finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
    gc = gspread.authorize(creds)
    SPREADSHEET_NAME = "GEM_Finance_Portfolio"

    # [ì‹ ê·œ] GEM-Core AI ëª¨ë¸ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
    @st.cache_resource
    def get_gem_core_ai():
        print("Initializing GEM-Core AI Model...") # AIê°€ ì²˜ìŒ ë¡œë“œë  ë•Œë§Œ ì´ ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤.
        model_name = 'gemini-2.5-pro' # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
        return genai.GenerativeModel(model_name)


except Exception as e:
    st.error(f"API í‚¤ ë˜ëŠ” ì¸ì¦ ì •ë³´ë¥¼ secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜: {e}")
    st.stop()

# [ìµœì¢… ë‹¨ìˆœí™” ë²„ì „] run_status_screener í•¨ìˆ˜ë¥¼ ì•„ë˜ ì½”ë“œë¡œ êµì²´
def run_status_screener(ticker_list):
    """
    (ìµœì¢… ë‹¨ìˆœí™” ë²„ì „) ì „ì²´ ì¢…ëª©ì— ëŒ€í•´ 'ë§¤ìˆ˜', 'ì£¼ì˜/ë§¤ë„', 'ì¤‘ë¦½'ì˜ 3ê°€ì§€ ìƒíƒœë¡œë§Œ íŒì •í•©ë‹ˆë‹¤.
    """
    if not ticker_list: return pd.DataFrame()

    data = yf.download(ticker_list, period="1y", progress=False, auto_adjust=True)
    if data.empty: return pd.DataFrame()

    final_results = []
    progress_bar = st.progress(0, text="ì „ì²´ ì¢…ëª© ìƒíƒœ ë¶„ì„ ì‹œì‘...")

    for i, ticker in enumerate(ticker_list):
        progress_bar.progress((i + 1) / len(ticker_list), text=f"ë¶„ì„ ì¤‘... {ticker}")
        try:
            stock_df = data.loc[:, (slice(None), ticker)]
            stock_df.columns = stock_df.columns.droplevel(1)
            
            if stock_df.empty or len(stock_df) < 61: continue

            # ì§€í‘œ ê³„ì‚° (SMA, 52ì£¼ ê³ ì , RSI)
            sma20 = stock_df['Close'].rolling(window=20).mean()
            sma60 = stock_df['Close'].rolling(window=60).mean()
            high_52w = stock_df['High'].rolling(window=252, min_periods=1).max().iloc[-1]
            mdd_percent = (stock_df['Close'].iloc[-1] / high_52w - 1) * 100 if high_52w > 0 else 0
            
            delta = stock_df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).ewm(com=13, adjust=False).mean()
            loss = (-delta.where(delta < 0, 0)).ewm(com=13, adjust=False).mean()
            rsi = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))
            latest_rsi = rsi.iloc[-1]

            # --- âœ¨ ìƒíƒœ íŒì • ë¡œì§ ë‹¨ìˆœí™” ---
            status = "ì¤‘ë¦½/ê´€ë§ âšªï¸"
            # ë§¤ìˆ˜ ì‹ í˜¸
            if (sma20.iloc[-2] < sma60.iloc[-2] and sma20.iloc[-1] > sma60.iloc[-1]) or (latest_rsi <= 30):
                status = "ë§¤ìˆ˜ ì‹ í˜¸ ğŸŸ¢"
            # ì£¼ì˜/ë§¤ë„ ì‹ í˜¸
            elif (sma20.iloc[-2] > sma60.iloc[-2] and sma20.iloc[-1] < sma60.iloc[-1]) or (latest_rsi >= 70):
                status = "ì£¼ì˜/ë§¤ë„ ì‹ í˜¸ ğŸ”´"

            final_results.append({
                "ì¢…ëª©ì½”ë“œ": ticker,
                "ìƒíƒœ": status,
                "í˜„ì¬ê°€": stock_df['Close'].iloc[-1],
                "ë“±ë½ë¥ (%)": (stock_df['Close'].iloc[-1] / stock_df['Close'].iloc[-2] - 1) * 100,
                "ê³ ì ëŒ€ë¹„(%)": mdd_percent,
                "RSI": latest_rsi
            })
        except Exception:
            continue
    
    progress_bar.empty()
    return pd.DataFrame(final_results)



# --- 3. ë°ì´í„° í˜¸ì¶œ ë° ì²˜ë¦¬ í•¨ìˆ˜ ---

def load_data_from_gsheet():
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        portfolio_ws = spreadsheet.worksheet("Portfolio")
        portfolio_data = portfolio_ws.get_all_values()
        portfolio_headers = portfolio_data.pop(0)
        portfolio_df = pd.DataFrame(portfolio_data, columns=portfolio_headers)

        watchlist_ws = spreadsheet.worksheet("Watchlist")
        watchlist_df = pd.DataFrame(watchlist_ws.get_all_records())

        cash_ws = spreadsheet.worksheet("Cash")
        cash_df = pd.DataFrame(cash_ws.get_all_records())

        numeric_cols = ['ìˆ˜ëŸ‰', 'í‰ê·  ë‹¨ê°€(USD)', 'í‰ê·  ë‹¨ê°€(KRW)', 'ìˆ˜ë™ í˜„ì¬ê°€(KRW)']
        for col in numeric_cols:
            if col in portfolio_df.columns:
                portfolio_df[col] = portfolio_df[col].replace('', '0').astype(str).str.replace(',', '')
                portfolio_df[col] = pd.to_numeric(portfolio_df[col], errors='coerce').fillna(0)
        
        if 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)' in portfolio_df.columns:
            portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] = portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'].replace('', '0').astype(str).str.replace('%', '')
            portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] = pd.to_numeric(portfolio_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'], errors='coerce').fillna(0) / 100
        
        if 'ê¸ˆì•¡(KRW)' in cash_df.columns:
            cash_df['ê¸ˆì•¡(KRW)'] = cash_df['ê¸ˆì•¡(KRW)'].replace('', '0').astype(str).str.replace(',', '')
            cash_df['ê¸ˆì•¡(KRW)'] = pd.to_numeric(cash_df['ê¸ˆì•¡(KRW)'], errors='coerce').fillna(0)

        return portfolio_df, watchlist_df, cash_df
    except gspread.exceptions.WorksheetNotFound as e:
        st.error(f"Google Sheetsì—ì„œ '{e.args[0]}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('Portfolio', 'Watchlist', 'Cash', 'Analysis_Log')")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    except Exception as e:
        st.error(f"Google Sheets ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# [ëˆ„ë½ëœ í•¨ìˆ˜ ì¶”ê°€] AI ë¶„ì„ ì „ìš© í˜„ê¸ˆ ë°ì´í„° ë¡œë”
def load_cash_data_only():
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        cash_ws = spreadsheet.worksheet("Cash")
        cash_df = pd.DataFrame(cash_ws.get_all_records())
        if 'ê¸ˆì•¡(KRW)' in cash_df.columns:
            # ê¸ˆì•¡(KRW) ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³ , ë¹ˆ ë¬¸ìì—´ê³¼ ì‰¼í‘œë¥¼ ì²˜ë¦¬
            cash_df['ê¸ˆì•¡(KRW)'] = cash_df['ê¸ˆì•¡(KRW)'].astype(str).str.replace(',', '').replace('', '0')
            # ìˆ«ì í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë³€í™˜
            cash_df['ê¸ˆì•¡(KRW)'] = pd.to_numeric(cash_df['ê¸ˆì•¡(KRW)'], errors='coerce').fillna(0)
        return cash_df
    except Exception as e:
        st.error(f"Cash ì‹œíŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# [ìµœì¢… ë²„ì „] ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•œ ë‹¨ì¼ ë™ê¸°í™” í•¨ìˆ˜
def synchronize_knowledge_files(folder_name="GEM_Finance_Knowledge", core_folder_name="Core_Principles"):
    """Google Drive í´ë”ì™€ ê·¸ í•˜ìœ„ í´ë”ë¥¼ ëª¨ë‘ íƒìƒ‰í•˜ì—¬ Gemini APIì™€ ë™ê¸°í™”í•˜ê³ ,
    'ìµœìƒìœ„ ì§€ì¹¨'ê³¼ 'ì°¸ê³  ìë£Œ' íŒŒì¼ ëª©ë¡ì„ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        drive_service = build('drive', 'v3', credentials=creds)
        
        # 1. ë©”ì¸ í´ë” ID ì°¾ê¸°
        folder_response = drive_service.files().list(q=f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false", fields='files(id)').execute()
        if not folder_response.get('files'):
            st.warning(f"Google Driveì—ì„œ '{folder_name}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return [], []
        folder_id = folder_response.get('files')[0].get('id')
        
        # 2. [í•µì‹¬ ìˆ˜ì •] ë©”ì¸ í´ë” í•˜ìœ„ì˜ ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°
        all_items_response = drive_service.files().list(q=f"'{folder_id}' in parents and trashed=false", fields='files(id, name, mimeType, modifiedTime, parents)').execute()
        all_items = all_items_response.get('files', [])

        # Core_Principles í´ë” ID ì°¾ê¸° ë° í•´ë‹¹ í´ë” ë‚´ë¶€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        core_folder_id = None
        for item in all_items:
            if item.get('mimeType') == 'application/vnd.google-apps.folder' and item.get('name') == core_folder_name:
                core_folder_id = item.get('id')
                core_files_response = drive_service.files().list(q=f"'{core_folder_id}' in parents and trashed=false", fields='files(id, name, mimeType, modifiedTime, parents)').execute()
                all_items.extend(core_files_response.get('files', []))
                break
        
        # íŒŒì¼ë§Œ í•„í„°ë§í•˜ê³ , Core_Principles íŒŒì¼ ì´ë¦„ ëª©ë¡ ìƒì„±
        drive_files = {f['name']: f for f in all_items if f.get('mimeType') != 'application/vnd.google-apps.folder'}
        core_file_names = {f['name'] for f in all_items if f.get('parents') and core_folder_id in f.get('parents')}

        # 3. Gemini APIì™€ ë™ê¸°í™”
        gemini_files_list = genai.list_files()
        gemini_files = {f.display_name: f for f in gemini_files_list}

        # 3. Drive ê¸°ì¤€ìœ¼ë¡œ ë™ê¸°í™”
        with st.spinner("Knowledge Core ë™ê¸°í™” ì¤‘..."):
            # Driveì— ì—†ëŠ” íŒŒì¼ì€ Geminiì—ì„œ ì‚­ì œ
            for name, gemini_file in gemini_files.items():
                if name not in drive_files:
                    st.write(f"   - Driveì—ì„œ ì‚­ì œëœ íŒŒì¼ '{name}'ì„ AIì—ì„œ ì œê±°í•©ë‹ˆë‹¤.")
                    genai.delete_file(gemini_file.name)
            
            # Driveì— ìƒˆë¡œ ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ì€ Geminiì— ì—…ë¡œë“œ
            for name, drive_file in drive_files.items():
                should_upload = False
                if name in gemini_files:
                    gemini_file_metadata = genai.get_file(gemini_files[name].name)
                    drive_mod_time = pd.to_datetime(drive_file['modifiedTime'])
                    gemini_create_time = pd.to_datetime(gemini_file_metadata.create_time)
                    if drive_mod_time > gemini_create_time:
                        st.write(f"   - ìˆ˜ì •ëœ íŒŒì¼ '{name}'ì„ AIì— ë‹¤ì‹œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
                        genai.delete_file(gemini_files[name].name)
                        should_upload = True
                else:
                    should_upload = True

                if should_upload:
                    st.write(f"   - ìƒˆ íŒŒì¼ '{name}'ì„ AIì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
                    request = drive_service.files().get_media(fileId=drive_file.get('id'))
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{name}") as tmp_file:
                        fh = BytesIO()
                        downloader = MediaIoBaseDownload(fh, request)
                        done = False
                        while not done:
                            status, done = downloader.next_chunk()
                        tmp_file.write(fh.getvalue())
                        tmp_file_path = tmp_file.name
                    
                    genai.upload_file(path=tmp_file_path, display_name=name)
                    os.unlink(tmp_file_path)

        st.success("Knowledge Core ë™ê¸°í™” ì™„ë£Œ!")

       # 4. ìµœì¢… íŒŒì¼ ëª©ë¡ì„ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜
        final_gemini_files = genai.list_files()
        core_principle_files = [f for f in final_gemini_files if f.display_name in core_file_names]
        #reference_files = [f for f in final_gemini_files if f.display_name not in core_file_names]
        
        return core_principle_files#, reference_files

    except Exception as e:
        st.error(f"ì§€ì‹ íŒŒì¼ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        return [], []


def save_analysis_to_gsheet(log_data):
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        log_ws = spreadsheet.worksheet("Analysis_Log")
        EXPECTED_HEADERS = ["Timestamp", "ì¢…ëª©ì½”ë“œ", "AI_Model", "ë‹¹ì‹œ ì£¼ê°€", "ë¶„ì„ ìš”ì•½", "ì „ì²´ ë¶„ì„ ë‚´ìš©", "ì£¼ìš” ë°ì´í„°"]
        if not log_ws.get_all_values():
            log_ws.append_row(EXPECTED_HEADERS)
        row_to_append = [log_data.get(h, "") for h in EXPECTED_HEADERS]
        log_ws.append_row(row_to_append)
        return True
    except Exception as e:
        st.error(f"ë¶„ì„ ê¸°ë¡ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

@st.cache_data(ttl=1)
def load_analysis_log(ticker):
    try:
        spreadsheet = gc.open(SPREADSHEET_NAME)
        log_ws = spreadsheet.worksheet("Analysis_Log")
        log_data = log_ws.get_all_records()
        if not log_data:
            return pd.DataFrame()
        log_df = pd.DataFrame(log_data)
        if 'ì¢…ëª©ì½”ë“œ' not in log_df.columns:
            return pd.DataFrame()
        return log_df[log_df['ì¢…ëª©ì½”ë“œ'] == ticker].sort_values(by='Timestamp', ascending=False)
    except Exception as e:
        st.warning(f"ê³¼ê±° ë¶„ì„ ê¸°ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

@st.cache_data
def get_company_profile(ticker): return finnhub_client.company_profile2(symbol=ticker)

@st.cache_data
def get_company_news(ticker):
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    return finnhub_client.company_news(ticker, _from=start_date, to=end_date)

@st.cache_data
def get_quote(ticker): return finnhub_client.quote(ticker)

# [ì‹ ê·œ] ì¤‘ì•™ ë°ì´í„° í—ˆë¸Œë¥¼ ê²½ìœ í•˜ì—¬ ì‹œì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_quote_from_hub(ticker):
    """
    ì¤‘ì•™ ë°ì´í„° í—ˆë¸Œ(st.session_state.data_hub)ë¥¼ í™•ì¸í•˜ê³ ,
    ë°ì´í„°ê°€ ì—†ê±°ë‚˜ 5ë¶„ì´ ì§€ë‚¬ìœ¼ë©´ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê°±ì‹ í•©ë‹ˆë‹¤.
    """
    now = datetime.now()
    hub_key = f"quote_{ticker}"
    
    # í—ˆë¸Œì— ë°ì´í„°ê°€ ìˆê³ , 5ë¶„ ì´ë‚´ì˜ ìµœì‹  ì •ë³´ì¸ì§€ í™•ì¸
    if hub_key in st.session_state.data_hub:
        data, timestamp = st.session_state.data_hub[hub_key]
        if (now - timestamp) < timedelta(minutes=5):
            return data # ìµœì‹  ì •ë³´ê°€ ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜

    # í—ˆë¸Œì— ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ì •ë³´ì´ë©´, ì‹¤ì œ API í˜¸ì¶œ (ê¸°ì¡´ í•¨ìˆ˜ ì¬í™œìš©)
    # st.write(f"CACHE MISS: Calling API for {ticker} quote...") # í…ŒìŠ¤íŠ¸ìš© ë¡œê·¸
    new_data = get_quote(ticker)
    
    # í—ˆë¸Œì— ìµœì‹  ì •ë³´ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
    if new_data:
        st.session_state.data_hub[hub_key] = (new_data, now)
        
    return new_data


@st.cache_data
def get_basic_financials(ticker):
    try:
        financials = finnhub_client.company_basic_financials(ticker, 'all')
        if 'series' in financials and 'annual' in financials['series']:
            records = {}
            for metric, data_points in financials['series']['annual'].items():
                if not data_points: continue
                clean_metric = metric.replace('Value', '').lower()
                for point in data_points:
                    period, value = point.get('period'), point.get('v')
                    if period not in records: records[period] = {}
                    records[period][clean_metric] = value
            if not records: return pd.DataFrame()
            df = pd.DataFrame.from_dict(records, orient='index').sort_index()
            return df
        return pd.DataFrame()
    except Exception: return pd.DataFrame()
@st.cache_data
def get_company_peers(ticker):
    try: return finnhub_client.company_peers(ticker)
    except Exception: return []
@st.cache_data
def get_company_earnings(ticker):
    try:
        earnings = finnhub_client.company_earnings(ticker, limit=5)
        if not earnings: return pd.DataFrame()
        df = pd.DataFrame(earnings)
        if 'surprisePercent' in df.columns:
            df['EPS ê²°ê³¼'] = df['surprisePercent'].apply(lambda x: 'Beat' if pd.notnull(x) and x > 0 else 'Miss' if pd.notnull(x) and x < 0 else 'Meet')
        else: df['surprisePercent'], df['EPS ê²°ê³¼'] = None, 'N/A'
        final_cols = {'period': 'ë°œí‘œ ë¶„ê¸°', 'actual': 'ì‹¤ì œ EPS', 'estimate': 'ì˜ˆìƒ EPS', 'surprisePercent': 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)', 'EPS ê²°ê³¼': 'EPS ê²°ê³¼'}
        return df[[c for c in final_cols if c in df.columns]].rename(columns=final_cols)
    except Exception: return pd.DataFrame()
@st.cache_data
def get_earnings_calendar(ticker):
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        later = (datetime.now() + timedelta(days=365)).strftime('%Y-%m-%d')
        calendar = finnhub_client.earnings_calendar(_from=today, to=later, symbol=ticker)
        if calendar and calendar.get('earningsCalendar'): return calendar['earningsCalendar'][0].get('date')
        return None
    except Exception: return None
@st.cache_data
def get_stock_candles(ticker):
    try:
        df = yf.Ticker(ticker).history(period="1y")
        if df.empty: return pd.DataFrame()
        return df.reset_index()
    except Exception: return pd.DataFrame()

@st.cache_data(ttl=3600) # 1ì‹œê°„ë§ˆë‹¤ Google Sheetsì—ì„œ í‹°ì»¤ ëª©ë¡ ê°±ì‹ 
def get_all_ticker_lists():
    """'Tickers' ì‹œíŠ¸ì—ì„œ ëª¨ë“  ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ì™€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        tickers_ws = gc.open(SPREADSHEET_NAME).worksheet("Tickers")
        all_values = tickers_ws.get_all_values()
        if not all_values:
            return {}
        
        headers = all_values[0]
        ticker_lists = {header: [] for header in headers}
        
        for col_idx, header in enumerate(headers):
            for row_idx in range(1, len(all_values)):
                if col_idx < len(all_values[row_idx]) and all_values[row_idx][col_idx]:
                    ticker_lists[header].append(all_values[row_idx][col_idx])
        return ticker_lists
    except Exception as e:
        st.error(f"Google Sheets 'Tickers' ì‹œíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return {}




def add_technical_indicators(df):
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['SMA60'] = df['Close'].rolling(window=60).mean()
    # [ìˆ˜ì •] ëˆ„ë½ë˜ì—ˆë˜ 120ì¼, 200ì¼ ì´ë™í‰ê· ì„  ê³„ì‚° ì¶”ê°€
    df['SMA120'] = df['Close'].rolling(window=120).mean()
    df['SMA200'] = df['Close'].rolling(window=200).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI14'] = 100 - (100 / (1 + rs))
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['SignalLine'] = df['MACD'].ewm(span=9, adjust=False).mean()
    return df



def generate_technical_summary(df):
    summary = []
    if len(df) < 60: return ["ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    latest = df.iloc[-1]; previous = df.iloc[-2]
    if latest['RSI14'] > 70: summary.append("ğŸ“ˆ **RSI ê³¼ë§¤ìˆ˜:** ë‹¨ê¸° ì¡°ì • ê°€ëŠ¥ì„±.")
    elif latest['RSI14'] < 30: summary.append("ğŸ“‰ **RSI ê³¼ë§¤ë„:** ë‹¨ê¸° ë°˜ë“± ê°€ëŠ¥ì„±.")
    else: summary.append(f"ğŸ“Š **RSI:** {latest['RSI14']:.2f} (ì¤‘ë¦½)")
    if previous['SMA20'] < previous['SMA60'] and latest['SMA20'] > latest['SMA60']: summary.append("ğŸš€ **ê³¨ë“  í¬ë¡œìŠ¤:** ê°•ì„¸ ì‹ í˜¸.")
    elif previous['SMA20'] > previous['SMA60'] and latest['SMA20'] < latest['SMA60']: summary.append("âš ï¸ **ë°ë“œ í¬ë¡œìŠ¤:** ì•½ì„¸ ì‹ í˜¸.")
    if previous['MACD'] < previous['SignalLine'] and latest['MACD'] > latest['SignalLine']: summary.append("ğŸ“ˆ **MACD ìƒí–¥ ëŒíŒŒ:** ë§¤ìˆ˜ ì‹ í˜¸.")
    elif previous['MACD'] > previous['SignalLine'] and latest['MACD'] < latest['SignalLine']: summary.append("ğŸ“‰ **MACD í•˜í–¥ ëŒíŒŒ:** ë§¤ë„ ì‹ í˜¸.")
    if not summary: summary.append("ëšœë ·í•œ ê¸°ìˆ ì  ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return summary

def calculate_support_levels(df):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ AIê°€ ì°¸ê³ í•  ì ì¬ì  ì§€ì§€ì„  ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if df.empty or len(df) < 200:
        return []
    high_1y = df['High'].max()
    low_1y = df['Low'].min()
    
    fibo_382 = high_1y - (high_1y - low_1y) * 0.382
    fibo_500 = high_1y - (high_1y - low_1y) * 0.5
    fibo_618 = high_1y - (high_1y - low_1y) * 0.618
    
    # SMA 120, 200ì¼ì„  ê³„ì‚°ì„ ìœ„í•´ add_technical_indicators í•¨ìˆ˜ ì¬ì‚¬ìš©
    df_with_sma = add_technical_indicators(df.copy())
    sma_120 = df_with_sma['SMA120'].iloc[-1]
    sma_200 = df_with_sma['SMA200'].iloc[-1]

    supports = [fibo_382, fibo_500, fibo_618, sma_120, sma_200]
    return [f"${s:.2f}" for s in supports if pd.notna(s)]

# [ìµœì¢… ìˆ˜ì •] ê³„ì¸µì  ì§€ì‹ ì‹œìŠ¤í…œì„ ëª…ì‹œì  'Tool'ë¡œ êµ¬í˜„í•œ ìµœì¢… AI ë¶„ì„ í•¨ìˆ˜
def stream_and_capture_analysis(ticker, profile, quote, financials_df, tech_summary, news, portfolio_context, support_levels, dynamic_trends, market_context, core_principle_files):
    model = get_gem_core_ai()
    model_name = model.model_name
    
    # [í•µì‹¬ ìˆ˜ì •] ëª¨ë¸ ìƒì„± ì‹œ tools ì„ ì–¸ì„ ì œê±°
    model = genai.GenerativeModel(model_name)

    # ë™ì  íŠ¸ë Œë“œ ì„¤ëª…ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„±
    trends_text = f"""
       - ì‹¤ì‹œê°„: {dynamic_trends.get('realtime_change_percent', 0.0):.2f}%
       - 3ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_3d_percent', 'N/A')}
       - 7ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_7d_percent', 'N/A')}
       - 30ì¼ ìˆ˜ìµë¥ : {dynamic_trends.get('return_30d_percent', 'N/A')}
       - 30ì¼ S&P500 ëŒ€ë¹„: {dynamic_trends.get('vs_spy_30d_percent', 'N/A')}
    """
    
    # [ì¶”ê°€] ê±°ì‹œ ê²½ì œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„±
    market_context_text = f"""
       - VIX (ê³µí¬ì§€ìˆ˜): {market_context.get('VIX', {}).get('price', 'N/A'):.2f} (20 ì´ìƒì¼ ê²½ìš° ë³€ë™ì„± í™•ëŒ€ ì£¼ì˜)
       - ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬: {market_context.get('US 10Y', {}).get('price', 'N/A'):.2f}% (ê¸ˆë¦¬ ìƒìŠ¹ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„±ì¥ì£¼ì— ë¶€ë‹´)
    """
# í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ê° íŒŒì¼ì˜ ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„
    core_files_names = ", ".join([f.display_name for f in core_principle_files]) if core_principle_files else "ì—†ìŒ"
    #ref_files_names = ", ".join([f.display_name for f in reference_files]) if reference_files else "ì—†ìŒ"
    
    master_prompt = f"""
    **SYSTEM ROLE:** ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ìµœê³ ì˜ ê¸ˆìœµ ë¶„ì„ê°€ì´ì, 'MASTER'ë¼ëŠ” íˆ¬ììë¥¼ ë³´ì¢Œí•˜ëŠ” AI ì „ëµ íŒŒíŠ¸ë„ˆ, 'GEM: Finance'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ë¶„ì„ì€ í•­ìƒ MASTERì˜ íˆ¬ì ì² í•™ì´ ë‹´ê¸´ ìµœìƒìœ„ ì§€ì¹¨ì„ ìµœìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤.

    **INPUT DATA:**
    - ë¶„ì„ ëŒ€ìƒ: {ticker}
    - MASTER í¬íŠ¸í´ë¦¬ì˜¤ ìƒí™©: {portfolio_context}
    - ê¸°ì—… ê°œìš”: {profile.get('name', 'N/A')}, ì‚°ì—…: {profile.get('finnhubIndustry', 'N/A')}
    - í˜„ì¬ ì‹œì„¸: ${quote.get('c', 0):.2f}
    - í•µì‹¬ ì¬ë¬´ ìš”ì•½: \n{financials_df.tail(3).to_string() if not financials_df.empty else "N/A"}
    - ê¸°ìˆ ì  ë¶„ì„ ìš”ì•½ (ì‹œìŠ¤í…œ): \n- {"\n- ".join(tech_summary)}
    - ìµœì‹  ë‰´ìŠ¤ ìš”ì•½ (ì‹œìŠ¤í…œ): \n- {"\n- ".join([item['headline'] for item in news[:5]]) if news else "N/A"}
    - ì ì¬ì  ì§€ì§€ì„  (ì‹œìŠ¤í…œ): {support_levels}
    - ìµœê·¼ ì£¼ê°€ ë™í–¥: {trends_text}
    - í˜„ì¬ ê±°ì‹œ ê²½ì œ ìƒí™©: {market_context_text}
    - ì²¨ë¶€ëœ ìµœìƒìœ„ ì§€ì¹¨ íŒŒì¼: {core_files_names}
    

    **MISSION:**
    ëª¨ë“  INPUT DATAì™€ ì²¨ë¶€ëœ ì§€ì¹¨ íŒŒì¼ì„ ì¢…í•©í•˜ì—¬, ì•„ë˜ 4ê°€ì§€ í•µì‹¬ ì§ˆë¬¸ì— ëŒ€í•œ 'ìƒì„¸í•œ ì„œìˆ í˜•' ë‹µë³€ì´ í¬í•¨ëœ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
    ë‹µë³€ì„ ìƒì„±í•  ë•Œ, ê° ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš© ì•ˆì— ì•„ë˜ì— ëª…ì‹œëœ **7ê°œì˜ ë°ì´í„° ë¸”ë¡**ì„ ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    ---
    ### ğŸ’ {ticker} ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
    *Analysis Model: `{model_name}`*

    #### 1. ì¢‹ì€ ì¢…ëª©ì¸ê°€? (í€ë”ë©˜í„¸ ë° ë‰´ìŠ¤ ë¶„ì„)
    *ì´ê³³ì— ììœ ë¡­ê²Œ ì„œìˆ í˜•ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...*
    [FUNDAMENTAL_ANALYSIS_BRIEFING]
    (ì„œìˆ  ë‚´ìš© ìš”ì•½) ì œê³µëœ ì¬ë¬´ì œí‘œì˜ ì„±ì¥ì„±, ìˆ˜ìµì„±, ì•ˆì •ì„± ë™í–¥ì„ ë¶„ì„í•˜ê³ , íˆ¬ììê°€ ìœ ì˜í•´ì•¼ í•  ê¸ì •ì /ë¶€ì •ì  í¬ì¸íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    [/FUNDAMENTAL_ANALYSIS_BRIEFING]
    *ì´ì–´ì„œ ê³„ì† ììœ ë¡­ê²Œ ì„œìˆ í•©ë‹ˆë‹¤...*
    [NEWS_ANALYSIS_BRIEFING]
    (ì„œìˆ  ë‚´ìš© ìš”ì•½) ì œê³µëœ ìµœì‹  ë‰´ìŠ¤ í—¤ë“œë¼ì¸ë“¤ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ê³ , ì „ì²´ì ì¸ ë‰´ìŠ¤ íë¦„ì´ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ì„ ê¸ì •ì , ë¶€ì •ì , ì¤‘ë¦½ì ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    [/NEWS_ANALYSIS_BRIEFING]
    *ê²°ë¡ ì ìœ¼ë¡œ ì´ ì¢…ëª©ì€ í€ë”ë©˜í„¸ê³¼ ë‰´ìŠ¤ ê´€ì ì—ì„œ...*

    #### 2. ì¢‹ì€ ì‹œê¸°ì¸ê°€? (ê¸°ìˆ ì  ë¶„ì„)
    *ì´ê³³ì— ììœ ë¡­ê²Œ ì„œìˆ í˜•ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...*
    [TECHNICAL_ANALYSIS_BRIEFING]
    (ì„œìˆ  ë‚´ìš© ìš”ì•½) í˜„ì¬ ì£¼ê°€ ì°¨íŠ¸ì˜ ì£¼ìš” ì´í‰ì„ (SMA), RSI, MACD ì§€í‘œì™€ ìµœê·¼ ìº”ë“¤ íŒ¨í„´ì„ ì¢…í•©ì ìœ¼ë¡œ í•´ì„í•˜ì—¬, í˜„ì¬ ê¸°ìˆ ì  ìƒíƒœê°€ ê°•ì„¸ì¸ì§€, ì•½ì„¸ì¸ì§€, í˜¹ì€ íš¡ë³´ ìƒíƒœì¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    [/TECHNICAL_ANALYSIS_BRIEFING]
    *ë”°ë¼ì„œ í˜„ì¬ ê¸°ìˆ ì  ê´€ì ì—ì„œëŠ”...*

    #### 3. ì¢‹ì€ ê°€ê²©ì¸ê°€? (ë§¤ìˆ˜ ë° ë§¤ë„ ì „ëµ)
    *ì´ê³³ì— ììœ ë¡­ê²Œ ì„œìˆ í˜•ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...*
    [BUY_ZONES]
    zone1_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone1_end: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_end: [ìˆ«ì ë˜ëŠ” N/A]
    rationale: í•´ë‹¹ ë§¤ìˆ˜ êµ¬ê°„ì„ ì„¤ì •í•œ ê¸°ìˆ ì , í€ë”ë©˜í„¸ì  ê·¼ê±°ë¥¼ ê°„ëµíˆ ì„œìˆ í•©ë‹ˆë‹¤.
    [/BUY_ZONES]
    *ë˜í•œ, ìˆ˜ìµ ì‹¤í˜„ ê´€ì ì—ì„œëŠ”...*
    [SELL_ZONES]
    zone1_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone1_end: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_start: [ìˆ«ì ë˜ëŠ” N/A]
    zone2_end: [ìˆ«ì ë˜ëŠ” N/A]
    rationale: í•´ë‹¹ ë§¤ë„/ìˆ˜ìµì‹¤í˜„ êµ¬ê°„ì„ ì„¤ì •í•œ ê¸°ìˆ ì , í€ë”ë©˜í„¸ì  ê·¼ê±°ë¥¼ ê°„ëµíˆ ì„œìˆ í•©ë‹ˆë‹¤.
    [/SELL_ZONES]

    #### 4. ìµœì¢…ì ìœ¼ë¡œ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ê°€? (ìµœì¢… ê¶Œê³ )
    *MASTERì˜ íˆ¬ì ì² í•™ê³¼ ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í–ˆì„ ë•Œ, ìµœì¢…ì ì¸ í–‰ë™ ê¶Œê³ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...*
    [RECOMMENDATION]
    action: [ë§¤ìˆ˜ ì¶”ì²œ, ì ê·¹ ë§¤ìˆ˜, ê´€ë§, ë¹„ì¤‘ ì¶•ì†Œ, ë§¤ë„ ê³ ë ¤] ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
    rationale: ìœ„ íˆ¬ì í–‰ë™ì„ ê²°ì •í•œ í•µì‹¬ì ì¸ ì´ìœ ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    [/RECOMMENDATION]
    """

    full_response = []
    try:
        # [í•µì‹¬ ìˆ˜ì •] generate_content í˜¸ì¶œ ì‹œ, í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ë‹¬
        all_files = core_principle_files#+ reference_files
        
        response = model.generate_content([master_prompt] + all_files, stream=True)

        for chunk in response:
            full_response.append(chunk.text)
            yield chunk.text

        # [ìˆ˜ì •] ëŒ€í™” ê¸°ë¡ì— í˜„ì¬ ë¬¸ë‹µ ì¶”ê°€
        final_text = "".join(full_response)
        st.session_state.last_analysis_text = final_text
        st.session_state.last_model_used = model_name
        


    except Exception as e:
        error_message = f"Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        st.session_state.last_analysis_text = error_message
        st.session_state.last_model_used = "Error"
        yield error_message

# [âœ¨ NEW] 1. 'ì§„í™”ëœ ë³´ê³ ì„œ' ìƒì„±ì„ ìœ„í•œ AI ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
def stream_evolved_report(previous_analysis_text, change_summary, ticker):
    """
    ê¸°ì¡´ ë¶„ì„ê³¼ ë³€ê²½ì ì„ ë°”íƒ•ìœ¼ë¡œ 'ì§„í™”ëœ ì „ì²´ ë³´ê³ ì„œ'ë¥¼ ìƒì„±í•˜ëŠ” AI í•¨ìˆ˜.
    """
    if "ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in change_summary:
        yield previous_analysis_text # ë³€ê²½ ì—†ìœ¼ë©´ ì´ì „ ë³´ê³ ì„œ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return

    model = get_gem_core_ai()
    
    prompt = f"""
**MISSION:** ì•„ë˜ [ê¸°ì¡´ ë¶„ì„ ë³´ê³ ì„œ]ë¥¼ [ìµœì‹  ë°ì´í„° ë³€ê²½ì  ìš”ì•½]ì„ ë°˜ì˜í•˜ì—¬, ë…¼ë¦¬ì  íë¦„ê³¼ êµ¬ì¡°ë¥¼ ì™„ë²½í•˜ê²Œ ìœ ì§€í•œ 'ì™„ê²°ëœ ìµœì‹  ë²„ì „ì˜ ì „ì²´ ë³´ê³ ì„œ'ë¡œ ì—…ë°ì´íŠ¸ í•˜ì‹­ì‹œì˜¤. ìµœì¢… ê²°ê³¼ë¬¼ì€ ë³´ê³ ì„œ ì „ë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

**[ê¸°ì¡´ ë¶„ì„ ë³´ê³ ì„œ]**
---
{previous_analysis_text}
---

**[ìµœì‹  ë°ì´í„° ë³€ê²½ì  ìš”ì•½]**
---
{change_summary}
---
"""
    response = model.generate_content(prompt, stream=True)
    for chunk in response:
        yield chunk.text

# [âœ¨ NEW] 2. 'ë³€ê²½ ìš”ì•½ ë¸Œë¦¬í•‘(Changelog)' ìƒì„±ì„ ìœ„í•œ AI í•¨ìˆ˜
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
def generate_changelog(previous_analysis_text, new_analysis_text, change_summary):
    """
    ì´ì „/ì‹ ê·œ ë³´ê³ ì„œì™€ ë³€ê²½ì ì„ ë¹„êµí•˜ì—¬ 'AI ë³€ê²½ì  ë¸Œë¦¬í•‘'ì„ ìƒì„±í•˜ëŠ” AI í•¨ìˆ˜.
    """
    if "ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in change_summary:
        return "âœ… ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•„ ê¸°ì¡´ ë¶„ì„ì´ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤."
    
    model = get_gem_core_ai()
    
    prompt = f"""
**MISSION:** ë‹¹ì‹ ì€ ë¶„ì„íŒ€ì¥ì…ë‹ˆë‹¤. ì•„ë˜ ì„¸ ê°€ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì–´ë–¤ 'ë°ì´í„° ë³€ê²½ì ' ë•Œë¬¸ì— ì´ì „ ë³´ê³ ì„œê°€ ìƒˆë¡œìš´ ë³´ê³ ì„œë¡œ ì–´ë–»ê²Œ ë°”ë€Œì—ˆëŠ”ì§€ í•µì‹¬ì ì¸ ì´ìœ ë¥¼ 'ë³€ê²½ ìš”ì•½ ë¸Œë¦¬í•‘' í˜•ì‹ìœ¼ë¡œ ë³´ê³ í•˜ì‹­ì‹œì˜¤.

**[1. ë°ì´í„° ë³€ê²½ì ]**
{change_summary}

**[2. ì´ì „ ë³´ê³ ì„œ]**
{previous_analysis_text}

**[3. ìƒˆë¡œìš´ ë³´ê³ ì„œ]**
{new_analysis_text}

**ë³´ê³  í˜•ì‹:**
ğŸ’¡ **AI ë³€ê²½ì  ë¸Œë¦¬í•‘ (Changelog)**
* **[ì‚¬ìœ ]** (ë°ì´í„° ë³€ê²½ì  ìš”ì•½)
    * **[ê²°ê³¼]** (ë³´ê³ ì„œì˜ ì–´ë–¤ ë¶€ë¶„ì´ ì–´ë–»ê²Œ ìˆ˜ì •ë˜ì—ˆëŠ”ì§€ ì„¤ëª…)
"""
    
    response = model.generate_content(prompt)
    return response.text


def structure_recommendation(full_analysis_text):
    """
    AIê°€ ìƒì„±í•œ 'ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ' í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ë°ì´í„° ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    if not full_analysis_text:
        return {}

    def extract_block(block_name, text):
        """ì§€ì •ëœ ì´ë¦„ì˜ ë°ì´í„° ë¸”ë¡ ë‚´ìš©ì„ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        pattern = re.compile(f'\\[{block_name}\\](.*?)\\[/{block_name}\\]', re.DOTALL)
        match = pattern.search(text)
        if match:
            return match.group(1).strip()
        return None

    def parse_zones(zone_content):
        """BUY_ZONES ë˜ëŠ” SELL_ZONESì˜ ë‚´ìš©ì„ íŒŒì‹±í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        if not zone_content:
            return None

        reco = {}
        for line in zone_content.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                reco[key.strip()] = value.strip()

        def to_float_or_none(val):
            try: return float(val)
            except (ValueError, TypeError): return None

        zone1_start = to_float_or_none(reco.get('zone1_start'))
        zone1_end = to_float_or_none(reco.get('zone1_end'))
        zone2_start = to_float_or_none(reco.get('zone2_start'))
        zone2_end = to_float_or_none(reco.get('zone2_end'))

        return {
            'zone1': (zone1_start, zone1_end) if zone1_start and zone1_end else None,
            'zone2': (zone2_start, zone2_end) if zone2_start and zone2_end else None,
            'rationale': reco.get('rationale', 'N/A')
        }

    def parse_recommendation(reco_content):
        """RECOMMENDATION ë¸”ë¡ì„ íŒŒì‹±í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        if not reco_content:
            return None

        reco = {}
        for line in reco_content.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                reco[key.strip()] = value.strip()
        return {
            'action': reco.get('action', 'N/A'),
            'rationale': reco.get('rationale', 'N/A')
        }

    # ê° ë¸”ë¡ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
    recommendation_content = parse_recommendation(extract_block('RECOMMENDATION', full_analysis_text))
    fundamental_content = extract_block('FUNDAMENTAL_ANALYSIS_BRIEFING', full_analysis_text)
    news_content = extract_block('NEWS_ANALYSIS_BRIEFING', full_analysis_text)
    technical_content = extract_block('TECHNICAL_ANALYSIS_BRIEFING', full_analysis_text)
    buy_zones_content = parse_zones(extract_block('BUY_ZONES', full_analysis_text))
    sell_zones_content = parse_zones(extract_block('SELL_ZONES', full_analysis_text))

    # ìµœì¢… êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ì¢…í•©
    structured_data = {
        'recommendation': recommendation_content,
        'fundamental_briefing': fundamental_content,
        'news_briefing': news_content,
        'technical_briefing': technical_content,
        'buy_zones': buy_zones_content,
        'sell_zones': sell_zones_content
    }

    return structured_data

def calculate_dynamic_trends(df, quote):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ê³¼ ì‹¤ì‹œê°„ ì‹œì„¸ë¥¼ ë°›ì•„ ë™ì  íŠ¸ë Œë“œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    trends = {}
    if df.empty or len(df) < 31:
        return trends

    # ì‹¤ì‹œê°„ ë“±ë½ë¥ 
    trends['realtime_change_percent'] = quote.get('dp', 0.0)

    # ê¸°ê°„ë³„ ìˆ˜ìµë¥  ê³„ì‚°
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.set_index('Date')
    
    latest_price = df['Close'].iloc[-1]
    for days in [3, 7, 30]:
        try:
            past_price = df['Close'].iloc[-days-1]
            trends[f'return_{days}d_percent'] = ((latest_price - past_price) / past_price) * 100
        except IndexError:
            trends[f'return_{days}d_percent'] = 'N/A'

    # S&P500 ëŒ€ë¹„ ì„±ê³¼ (30ì¼ ê¸°ì¤€)
    try:
        spy_df = yf.download('SPY', start=df.index[-31], end=df.index[-1] + pd.Timedelta(days=1), progress=False)
        spy_return = (spy_df['Close'].iloc[-1] - spy_df['Close'].iloc[0]) / spy_df['Close'].iloc[0] * 100
        stock_return_30d = trends.get('return_30d_percent', 0)
        if stock_return_30d != 'N/A':
            trends['vs_spy_30d_percent'] = stock_return_30d - spy_return
    except Exception:
        trends['vs_spy_30d_percent'] = 'N/A'
        
    return trends


# backup (lines 260-281)
@st.cache_data(ttl=300)
def get_current_prices_and_rate(tickers):
    try: usd_krw_rate = yf.Ticker("USDKRW=X").history(period='1d')['Close'].iloc[-1]
    except: usd_krw_rate = 1350.0
    try:
        data = yf.download(tickers, period='1d', progress=False)
        if data.empty: return {}, usd_krw_rate
        prices = data['Close'].iloc[-1].to_dict() if isinstance(data.columns, pd.MultiIndex) else {tickers[0]: data['Close'].iloc[-1]}
        return prices, usd_krw_rate
    except: return {}, usd_krw_rate
def create_portfolio_dashboard(df, prices, usd_krw_rate):
    dashboard_df = df.copy()
    dashboard_df['API í˜„ì¬ê°€'] = dashboard_df['ì¢…ëª©ì½”ë“œ'].map(prices)
    if 'ìˆ˜ë™ í˜„ì¬ê°€(KRW)' in dashboard_df.columns:
        dashboard_df['í˜„ì¬ê°€'] = dashboard_df['ìˆ˜ë™ í˜„ì¬ê°€(KRW)'].where(dashboard_df['ìˆ˜ë™ í˜„ì¬ê°€(KRW)'] > 0, dashboard_df['API í˜„ì¬ê°€'])
    else: dashboard_df['í˜„ì¬ê°€'] = dashboard_df['API í˜„ì¬ê°€']
    dashboard_df['í†µí™”'] = 'USD'
    dashboard_df.loc[dashboard_df['ì¢…ëª©ì½”ë“œ'].str.contains('.KS|.KQ', na=False), 'í†µí™”'] = 'KRW'
    dashboard_df['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] = dashboard_df.apply(lambda r: r['í‰ê·  ë‹¨ê°€(KRW)'] if r['í†µí™”'] == 'KRW' else r['í‰ê·  ë‹¨ê°€(USD)'], axis=1)
    dashboard_df['í˜„ì¬ê°€ (ê³ ìœ )'] = dashboard_df['í˜„ì¬ê°€']
    dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'] = dashboard_df.apply(lambda r: (r['ìˆ˜ëŸ‰'] * r['í‰ê·  ë‹¨ê°€ (ê³ ìœ )']) if r['í†µí™”'] == 'KRW' else (r['ìˆ˜ëŸ‰'] * r['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] * usd_krw_rate), axis=1)
    dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = pd.NA
    if 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)' in dashboard_df.columns:
        mask = dashboard_df['ìˆ˜ë™ ìˆ˜ìµë¥ (%)'] != 0
        dashboard_df.loc[mask, 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = dashboard_df.loc[mask, 'ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'] * (1 + dashboard_df.loc[mask, 'ìˆ˜ë™ ìˆ˜ìµë¥ (%)'])
    auto_calc_mask = dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].isna()
    dashboard_df.loc[auto_calc_mask, 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] = dashboard_df.loc[auto_calc_mask].apply(lambda r: (r['ìˆ˜ëŸ‰'] * r['í˜„ì¬ê°€']) if r['í†µí™”'] == 'KRW' else (r['ìˆ˜ëŸ‰'] * r['í˜„ì¬ê°€'] * usd_krw_rate), axis=1)
    dashboard_df['ì†ìµ (KRW)'] = (dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'] - dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)']).fillna(0)
    dashboard_df['ì†ìµ (ê³ ìœ )'] = dashboard_df.apply(lambda r: r['ì†ìµ (KRW)'] if r['í†µí™”'] == 'KRW' else r['ì†ìµ (KRW)'] / usd_krw_rate, axis=1)
    dashboard_df['ìˆ˜ìµë¥  (%)'] = (dashboard_df['ì†ìµ (KRW)'] / dashboard_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].replace(0, pd.NA)) * 100
    return dashboard_df

@st.cache_data
def get_peer_summary(ticker_list):
    summary_data = []
    for ticker in ticker_list:
        try:
            # [ìˆ˜ì •] get_quoteë¥¼ get_quote_from_hubë¡œ ë³€ê²½
            profile, quote = get_profile_from_hub(ticker), get_quote_from_hub(ticker) # <-- ì—¬ê¸°ë¥¼ ìˆ˜ì •
            summary_data.append({"Ticker": ticker, "Name": profile.get('name', ticker), "Market Cap (M)": profile.get('marketCapitalization', 0), "% Change": quote.get('dp', 0)})
        except: continue
    return pd.DataFrame(summary_data)


# --- [MOD v39.1 Start] ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ ì•ˆì •ì„± ë³µì› ë° ê°œì„  (ìµœì¢…) ---
@st.cache_data(ttl=300)
def get_market_status_data():
    """[ìµœì¢… ì•ˆì •í™” ë²„ì „] ê° ì§€í‘œì˜ 'ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ'ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤."""
    data = {}
    tickers = {
        "S&P 500": "^GSPC", "Nasdaq": "^IXIC", "KOSPI": "^KS11", "VIX": "^VIX", 
        "US 10Y": "^TNX", "Dollar": "DX-Y.NYB", "Crude Oil": "CL=F", 
        "Gold": "GC=F", "USD/KRW": "USDKRW=X"
    }
    
    hist_data = pd.DataFrame() 
    try:
        # 1. ëª¨ë“  í‹°ì»¤ ë°ì´í„°ë¥¼ í•œ ë²ˆì— íš¨ìœ¨ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
        hist_data = yf.download(list(tickers.values()), period="6d", progress=False)
        
        if not hist_data.empty:
            for name, ticker_symbol in tickers.items():
                try:
                    # 2. ê° í‹°ì»¤ë³„ë¡œ ë°ì´í„° ì‹œë¦¬ì¦ˆë¥¼ ì¶”ì¶œí•˜ê³ , ë¹„ì–´ìˆëŠ” ê°’(NaN) ì œê±°
                    ticker_series = hist_data['Close'][ticker_symbol].dropna()
                    
                    if ticker_series.empty:
                        data[name] = {"price": "N/A", "change": "N/A", "change_percent": "N/A", "last_update": "N/A"}
                        continue

                    # 3. ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œë¥¼ 'last_update'ë¡œ ì¶”ì¶œ
                    last_update_date = ticker_series.index[-1].strftime('%Y-%m-%d')
                    
                    # 4. ë“±ë½ë¥  ê³„ì‚°
                    if len(ticker_series) >= 2:
                        price = ticker_series.iloc[-1]
                        change = price - ticker_series.iloc[-2]
                        change_percent = (change / ticker_series.iloc[-2]) * 100 if ticker_series.iloc[-2] != 0 else 0
                        data[name] = {"price": price, "change": change, "change_percent": change_percent, "last_update": last_update_date}
                    elif len(ticker_series) == 1:
                        data[name] = {"price": ticker_series.iloc[-1], "change": "N/A", "change_percent": "N/A", "last_update": last_update_date}
                except (KeyError, IndexError):
                    data[name] = {"price": "N/A", "change": "N/A", "change_percent": "N/A", "last_update": "N/A"}
    except Exception:
        for name in tickers.keys():
            data[name] = {"price": "N/A", "change": "N/A", "change_percent": "N/A", "last_update": "N/A"}

    try:
        data['news'] = finnhub_client.general_news('general', min_id=0)[:5]
    except Exception:
        data['news'] = []
        
    return data, hist_data
# --- [MOD v39.1 End] ---


# --- [MOD v38 Start] í…Œë§ˆ ETFì— 'ì¶”ì„¸ ë¶„ì„' ê¸°ëŠ¥ ì¶”ê°€ ---
@st.cache_data(ttl=300)
def get_theme_etf_performance():
    """ì„ ì •ëœ 12ê°œ ETFì˜ 'ë‹¹ì¼ ì„±ê³¼'ì™€ '5ì¼ ì¶”ì„¸'ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤."""
    etf_tickers = {
        "S&P 500": "SPY", "ê°€ì¹˜ì£¼": "VTV", "ì„±ì¥ì£¼": "VUG", "ë°˜ë„ì²´": "SOXX", 
        "AI": "AIQ", "ë¡œë³´í‹±ìŠ¤": "BOTZ", "ë°”ì´ì˜¤í…Œí¬": "IBB", "ì°¨ì„¸ëŒ€ ì „ë ¥": "GRID",
        "ê³ ë°°ë‹¹": "SCHD", "ì¥ê¸°ì±„": "TLT", "í˜ì‹ ê¸°ìˆ ": "ARKK", "ë¹„íŠ¸ì½”ì¸": "IBIT"
    }
    try:
        # 5ì¼ ì¶”ì„¸ ê³„ì‚°ì„ ìœ„í•´ 6ì¼ì¹˜ ë°ì´í„° ìš”ì²­
        data = yf.download(list(etf_tickers.values()), period="6d", progress=False)
        if data.empty: return {}
        
        performance = {}
        for theme, ticker in etf_tickers.items():
            series = data['Close'][ticker].dropna()
            if len(series) >= 2:
                # ë‹¹ì¼ ë“±ë½ë¥ 
                change_percent = (series.iloc[-1] / series.iloc[-2] - 1) * 100
                
                # 5ì¼ ì¶”ì„¸
                trend = "íš¡ë³´"
                if len(series) >= 6: # 5ì¼ ì¶”ì„¸ë¥¼ ë³´ë ¤ë©´ ìµœì†Œ 6ì¼ ë°ì´í„° í•„ìš”
                    if series.iloc[-1] > series.iloc[-2] * 1.01: trend = "ìƒìŠ¹"
                    elif series.iloc[-1] < series.iloc[-2] * 0.99: trend = "í•˜ë½"

                performance[theme] = {'change_percent': change_percent, 'trend': trend}
        return performance
    except Exception:
        return {}
# --- [MOD v38 End] ---


# --- [MOD v41 Start] ì´ë²¤íŠ¸ ìº˜ë¦°ë” ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ---
@st.cache_data(ttl=3600) # 1ì‹œê°„ë§ˆë‹¤ ê°±ì‹ 
def get_economic_calendar():
    """Finnhub APIë¥¼ ì‚¬ìš©í•˜ì—¬ í–¥í›„ 2ì£¼ê°„ì˜ ì£¼ìš” ê±°ì‹œ ê²½ì œ ì´ë²¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        two_weeks_later = (datetime.now() + timedelta(days=14)).strftime('%Y-%m-%d')
        calendar = finnhub_client.economic_calendar(_from=today, to=two_weeks_later)
        if calendar and calendar.get('economicCalendar'):
            us_events = [
                event for event in calendar['economicCalendar'] 
                if event.get('country') == 'US' and event.get('impact') in ['high', 'medium']
            ]
            return sorted(us_events, key=lambda x: x['time'])
    except Exception:
        return []
    return []

@st.cache_data(ttl=3600) # 1ì‹œê°„ë§ˆë‹¤ ê°±ì‹ 
def get_portfolio_earnings_calendar(tickers):
    """ì…ë ¥ëœ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ í–¥í›„ 2ì£¼ê°„ì˜ ì‹¤ì  ë°œí‘œì¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    all_earnings = []
    today = datetime.now().strftime('%Y-%m-%d')
    two_weeks_later = (datetime.now() + timedelta(days=14)).strftime('%Y-%m-%d')
    try:
        # Finnhub APIëŠ” í•œ ë²ˆì— ì—¬ëŸ¬ í‹°ì»¤ ì¡°íšŒë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê°œë³„ í˜¸ì¶œ
        for ticker in tickers:
            calendar = finnhub_client.earnings_calendar(
                _from=today, to=two_weeks_later, symbol=ticker
            )
            if calendar and calendar.get('earningsCalendar'):
                for earning in calendar['earningsCalendar']:
                    earning['ticker'] = ticker # ê²°ê³¼ì— í‹°ì»¤ ì •ë³´ ì¶”ê°€
                    all_earnings.append(earning)
        return sorted(all_earnings, key=lambda x: x['date'])
    except Exception:
        return []
# --- [MOD v41 End] ---



# --- [MOD v38.1 Start] AI í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì°¸ì¡° ì˜¤ë¥˜ ìˆ˜ì • ë° êµ¬ì¡° ê°œì„  (ìµœì¢…) ---
def generate_market_health_briefing(market_data, full_hist_data, sector_perf_df, theme_perf, combined_events, eco_indicators): # buffett_data ì¸ìˆ˜ ì œê±°


    """
    [ìµœì¢… ìˆ˜ì •ë³¸] ëª¨ë“  ë°ì´í„°ë¥¼ AI í”„ë¡¬í”„íŠ¸ì— 'ì§ì ‘' ì£¼ì…í•˜ê³ ,
    'ì ˆëŒ€ ê·œì¹™'ì„ ë¶€ì—¬í•˜ì—¬ ë°ì´í„° ê¸°ë°˜ì˜ 'JSON' ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    model = get_gem_core_ai()
    generation_config = genai.types.GenerationConfig(response_mime_type="application/json")

    # --- ë°ì´í„° ìš”ì•½ ë¶€ë¶„ (ì´ì „ê³¼ ë™ì¼) ---
    tickers = {
        "S&P 500": "^GSPC", "Nasdaq": "^IXIC", "KOSPI": "^KS11", "VIX": "^VIX", 
        "US 10Y": "^TNX", "Dollar": "DX-Y.NYB", "Crude Oil": "CL=F", 
        "Gold": "GC=F", "USD/KRW": "USDKRW=X"
    }
    data_summary_items, news_summary_items, sector_summary_items, theme_summary_items = [], [], [], []
    
    for name, values in market_data.items():
        if name == 'news': continue
        price, change_percent = values.get('price', 'N/A'), values.get('change_percent', 'N/A')
        trend = "íš¡ë³´"
        try:
            ticker_symbol = tickers.get(name)
            if ticker_symbol and not full_hist_data.empty:
                series = full_hist_data['Close'][ticker_symbol].dropna()
                if len(series) >= 5:
                    if series.iloc[-1] > series.iloc[0] * 1.01: trend = "ìƒìŠ¹ ì¶”ì„¸"
                    elif series.iloc[-1] < series.iloc[0] * 0.99: trend = "í•˜ë½ ì¶”ì„¸"
        except (KeyError, IndexError, TypeError): trend = "íŒë‹¨ ë¶ˆê°€"
        last_update = values.get('last_update', 'N/A')
        if isinstance(price, (int, float)) and isinstance(change_percent, (int, float)):
            data_summary_items.append(f"- {name}: {price:.2f} ({change_percent:+.2f}%) | 5ì¼ ì¶”ì„¸: {trend} | ìµœì¢… ì—…ë°ì´íŠ¸: {last_update}")
    
    news_summary_items = [f"- {news['headline']}" for news in market_data.get('news', [])]
    sector_summary_items = [f"- {row['Sector']}: {row['Performance_5D']:.2f}%" for index, row in sector_perf_df.iterrows()]
    
    for theme, perf_data in theme_perf.items():
        change = perf_data.get('change_percent', 0)
        trend = perf_data.get('trend', 'N/A')
        theme_summary_items.append(f"- {theme}: {change:+.2f}% | 5ì¼ ì¶”ì„¸: {trend}")

    data_summary_text = "\n".join(data_summary_items) if data_summary_items else "ë°ì´í„° ì—†ìŒ"
    news_summary_text = "\n".join(news_summary_items) if news_summary_items else "ìµœì‹  ì£¼ìš” ë‰´ìŠ¤ ì—†ìŒ"
    sector_summary_text = "\n".join(sector_summary_items) if sector_summary_items else "ì„¹í„° ë°ì´í„° ì—†ìŒ"
    theme_summary_text = "\n".join(theme_summary_items) if theme_summary_items else "í…Œë§ˆ ETF ë°ì´í„° ì—†ìŒ"

    # [ì¶”ê°€] ì´ë²¤íŠ¸ ë°ì´í„° ìš”ì•½
    event_summary_items = []
    for event in combined_events[:5]: # ìƒìœ„ 5ê°œ ì´ë²¤íŠ¸ë§Œ ìš”ì•½
        event_date = datetime.strptime(event['date'], '%Y-%m-%d').strftime('%m/%d')
        if event['type'] == 'eco':
            event_summary_items.append(f"- {event_date}: {event['data']['event']}")
        elif event['type'] == 'earn':
            event_summary_items.append(f"- {event_date}: ${event['data']['ticker']} ì‹¤ì ë°œí‘œ")
    event_summary_text = "\n".join(event_summary_items) if event_summary_items else "í–¥í›„ 2ì£¼ ë‚´ ì£¼ìš” ì´ë²¤íŠ¸ ì—†ìŒ"


    # [ê³ ë„í™”] ê²½ì œ ì§€í‘œ ìš”ì•½ ì‹œ, ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
    eco_summary_items = []
    if eco_indicators:
        for name, data in eco_indicators.items():
            # AIì—ê²Œ 12ê°œì›” ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ëª…í™•í•˜ê²Œ ì „ë‹¬
            timeseries_str = ", ".join(map(str, data.get('timeseries', [])))
            eco_summary_items.append(f"- {name} ({data['type']}): {data['value']:.2f} | ìƒíƒœ: {data['status']} | 12ê°œì›” ì¶”ì´: [{timeseries_str}]")
    eco_summary_text = "\n".join(eco_summary_items) if eco_summary_items else "ë°ì´í„° ì—†ìŒ"
    
    # --- ë°ì´í„° ìš”ì•½ ë ---
    
    # âœ¨ --- [í•µì‹¬ ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ ë‚´ë¶€ì˜ ì˜ˆì‹œ ë¬¸êµ¬ ë° êµ¬ì¡° ê°œì„  --- âœ¨
    prompt = f"""
    **SYSTEM ROLE:** ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ìˆ˜ì„ ì‹œì¥ ì „ëµê°€ 'GEM: Finance'ë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì ì¸ ì§„ì‹¤ë§Œì„ ë³´ê³ í•˜ëŠ” ê²ƒì´ë‹¤.

    ---
    **## âœ¨ ì ˆëŒ€ ê·œì¹™ (Absolute Rules) ##**
    1.  **ë°ì´í„° ì ˆëŒ€ì£¼ì˜:** ë„ˆì˜ ëª¨ë“  ë¶„ì„ì€ **ì˜¤ì§ 'INPUT DATA'ì— ì œì‹œëœ ìˆ«ìì™€ ì‚¬ì‹¤ì—ë§Œ ê¸°ë°˜**í•´ì•¼ í•œë‹¤.
    2.  **ìˆ˜ì¹˜ ì¸ìš© ì˜ë¬´:** ì£¼ì¥ì„ ì¦ëª…í•˜ê¸° ìœ„í•´ **ë°˜ë“œì‹œ í•´ë‹¹ ìˆ˜ì¹˜ë¥¼ ê´„í˜¸ ì•ˆì— í•¨ê»˜ ì œì‹œ**í•´ì•¼ í•œë‹¤. (ì˜ˆ: 'ì„±ì¥ì£¼({theme_perf.get('ì„±ì¥ì£¼', {}).get('change_percent', 0):.2f}%)ëŠ” ê°€ì¹˜ì£¼({theme_perf.get('ê°€ì¹˜ì£¼', {}).get('change_percent', 0):.2f}%) ëŒ€ë¹„ ë¶€ì§„í–ˆìŠµë‹ˆë‹¤.')
    3.  **ì°½ì‘ ê¸ˆì§€:** **ì‚¬ì‹¤ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼.** ë°ì´í„°ê°€ íŠ¹ì • ë‚´ëŸ¬í‹°ë¸Œì™€ ë‹¤ë¥´ë‹¤ë©´, ê·¸ 'ë‹¤ë¦„' ìì²´ë¥¼ ë¶„ì„í•˜ë¼.
    4.  **ì‹œì  ë¶„ì„ (Timing Analysis):** ê° ì§€í‘œì˜ **'ìµœì¢… ì—…ë°ì´íŠ¸'** ë‚ ì§œë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ë¼. ë§Œì•½ íŠ¹ì • ì§€í‘œì˜ ë‚ ì§œê°€ ë‹¤ë¥¸ ì§€í‘œë“¤ë³´ë‹¤ ê³¼ê±°ì— ë©ˆì¶°ìˆë‹¤ë©´(ì˜ˆ: íœ´ì¥ì¼), ì´ë¥¼ 'ë…ìì  ê°•ì„¸/ì•½ì„¸'ë¡œ ì„±ê¸‰í•˜ê²Œ í•´ì„í•´ì„œëŠ” ì•ˆ ëœë‹¤. ëŒ€ì‹ , **'ì‹œì  ë¶ˆì¼ì¹˜'**ê°€ ë°œìƒí–ˆìŒì„ ëª…í™•íˆ ì§€ì í•˜ê³ , ê·¸ë¡œ ì¸í•´ ë¶„ì„ì— ì–´ë–¤ í•œê³„ê°€ ìˆëŠ”ì§€ ì„¤ëª…í•˜ë¼.
    5. **ì‹œê³„ì—´ ë¶„ì„ ì˜ë¬´:** **'í•µì‹¬ ê²½ì œ ì§€í‘œ' ë¶„ì„ ì‹œ, ë°˜ë“œì‹œ '12ê°œì›” ì¶”ì´' ìˆ«ì ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì„¸(ìƒìŠ¹/í•˜ë½/íš¡ë³´)ë¥¼ ì‹¬ì¸µ ë¶„ì„**í•˜ê³ , ê·¸ ì¶”ì„¸ê°€ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í•´ì„í•´ì•¼ í•œë‹¤. (ì˜ˆ: 'ì‹¤ì—…ë¥ (4.30) ìì²´ëŠ” ë‚®ì§€ë§Œ, 12ê°œì›” ì¶”ì´ê°€ [3.8, ..., 4.3]ìœ¼ë¡œ ê¾¸ì¤€íˆ ìƒìŠ¹í•˜ê³  ìˆì–´ ê³ ìš© ì‹œì¥ì˜ ì ì§„ì ì¸ ë‘”í™”ë¥¼ ì‹œì‚¬í•œë‹¤.'
    ---

    **INPUT DATA:**
    1. ìµœì‹  ì‹œì¥ ì§€í‘œ ë° 5ì¼ ì¶”ì„¸:
    {data_summary_text}
    2. ìµœì‹  ê²½ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸:
    {news_summary_text}
    3. ìµœê·¼ 5ì¼ê°„ ì„¹í„°ë³„ ìê¸ˆ íë¦„(ìˆ˜ìµë¥ ):
    {sector_summary_text}
    4. ì‹¤ì‹œê°„ í…Œë§ˆ & ìì‚°êµ°ë³„ ì„±ê³¼ ë° '5ì¼ ì¶”ì„¸':
    {theme_summary_text}
    5. í–¥í›„ 2ì£¼ ë‚´ ì£¼ìš” ì´ë²¤íŠ¸:
    {event_summary_text}
    6. í•µì‹¬ ê²½ì œ ì§€í‘œ (ìˆ˜ì¹˜ | ìƒíƒœ | 12ê°œì›” ì¶”ì´):
    {eco_summary_text}

    

    **MISSION:**
    ìœ„ 'ì ˆëŒ€ ê·œì¹™'ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ëª¨ë“  ì…ë ¥ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ê³  ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶° 'ìš”ì•½'ê³¼ 'ìƒì„¸ ë¦¬í¬íŠ¸'ë¥¼ ìƒì„±í•˜ë¼. 'report' í•„ë“œì˜ ë‚´ìš©ì€ ë§ˆí¬ë‹¤ìš´(Markdown) í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•œë‹¤.
    ** 7ê°€ì§€ ëª¨ë“  ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ë¼. **íŠ¹íˆ, 6ë²ˆ 'í•µì‹¬ ê²½ì œ ì§€í‘œ'ì˜ '12ê°œì›” ì¶”ì´'ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ í˜„ì¬ ê²½ì œê°€ í™•ì¥ êµ­ë©´ì¸ì§€, ë‘”í™” êµ­ë©´ì¸ì§€, í˜¹ì€ ë³€ê³¡ì ì— ìˆëŠ”ì§€ ì§„ë‹¨í•˜ë¼.** ì‹œì¥ì˜ ì¢…í•©ì ì¸ ê±´ê°• ìƒíƒœë¥¼ í‰ê°€í•˜ë¼.
    ë¶„ì„ ì‹œì—ëŠ” ê° í…Œë§ˆì˜ 'ë‹¹ì¼ ì„±ê³¼'ì™€ '5ì¼ ì¶”ì„¸'ë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ì‹œì¥ì˜ ì„±ê²©ì„ ì‹¬ì¸µ ë¶„ì„í•˜ë¼. (ì˜ˆ: 'ë°˜ë„ì²´(-1.5%)ëŠ” ì˜¤ëŠ˜ í•˜ë½í–ˆì§€ë§Œ 5ì¼ ì¶”ì„¸ëŠ” ìƒìŠ¹ì„¸ì´ë¯€ë¡œ, ê±´ê°•í•œ ì¡°ì •ì¼ ìˆ˜ ìˆë‹¤.')
    ** í˜„ì¬ ì‹œì¥ì˜ ì›€ì§ì„ì´ 5ë²ˆ 'ì£¼ìš” ì´ë²¤íŠ¸'ë¥¼ ì•ë‘” ê¸°ëŒ€ê° ë˜ëŠ” ê²½ê³„ê°ì„ ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í•´ì„í•˜ë¼.
    ëª¨ë“  ì…ë ¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ê³¼ì •ì—ì„œ, ì˜¤ëŠ˜ ì‹œì¥ì— ì˜ë¯¸ ìˆëŠ” ì˜í–¥ì„ ì¤€ ëª¨ë“  'í•µì‹¬ ë™ì¸(Key Drivers)'ë“¤ì„ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì°¾ì•„ë‚´ì–´ ë¶„ì„í•˜ë¼. 'í•µì‹¬ ë™ì¸'ì´ë€, íŠ¹ì • ì„¹í„°/í…Œë§ˆ/ìì‚°êµ°ì˜ ì´ë¡€ì ì¸ ì›€ì§ì„ì„ ìœ ë°œí•œ ê°€ì¥ ìœ ë ¥í•œ ë‰´ìŠ¤ë‚˜ ì´ë²¤íŠ¸ë¥¼ ì˜ë¯¸í•œë‹¤.


    **OUTPUT JSON FORMAT:**
    {{
      "summary": "ëª¨ë“  ë¶„ì„ì„ ì••ì¶•í•œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ê²°ë¡  í•œ ë¬¸ì¥",
      "report": "ğŸ’¡ **AI ì‹œì¥ ì¢…í•© ì§„ë‹¨**\\n\\n* **ì‹œì¥ í˜„ìƒ (What):** ...\\n* **ë‚´ë¶€ ë™ë ¥ (Why):** ...\\n* **í•µì‹¬ ì¸ì‚¬ì´íŠ¸:** ...\\n* **ì¢…í•© ì½”ë©˜íŠ¸:** ..."
    }}
    """

    try:
        response = model.generate_content(prompt, generation_config=generation_config)
        result_json = json.loads(response.text)
        return result_json
    except Exception as e:
        return {"summary": "AI ë¸Œë¦¬í•‘ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "report": f"**ì˜¤ë¥˜ ë°œìƒ:**\n\n```\n{str(e)}\n```"}
# --- [MOD v38.1 End] ---


# --- [MOD v35.6 Start] ì„¹í„° ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ---
@st.cache_data(ttl=1800) # 30ë¶„ë§ˆë‹¤ ë°ì´í„° ê°±ì‹ 
def get_sector_performance():
    """11ê°œ ì£¼ìš” ì„¹í„° ETFì˜ ìµœê·¼ 5ì¼ê°„ì˜ ì„±ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    sector_tickers = {
        'Technology': 'XLK', 'Health Care': 'XLV', 'Financials': 'XLF',
        'Consumer Discretionary': 'XLY', 'Communication Services': 'XLC', 'Industrials': 'XLI',
        'Consumer Staples': 'XLP', 'Energy': 'XLE', 'Utilities': 'XLU',
        'Real Estate': 'XLRE', 'Materials': 'XLB'
    }
    try:
        data = yf.download(list(sector_tickers.values()), period="5d", progress=False)
        if data.empty:
            return pd.DataFrame()
        
        performance = {}
        for sector, ticker in sector_tickers.items():
            series = data['Close'][ticker].dropna()
            if len(series) >= 2:
                # 5ì¼ê°„ì˜ ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
                perf = (series.iloc[-1] / series.iloc[0] - 1) * 100
                performance[sector] = perf
        
        if not performance:
            return pd.DataFrame()

        perf_df = pd.DataFrame(list(performance.items()), columns=['Sector', 'Performance_5D'])
        return perf_df

    except Exception:
        return pd.DataFrame()
# --- [MOD v35.6 End] ---


# finance_core.py íŒŒì¼ì˜ get_economic_indicators í•¨ìˆ˜ë¥¼ ì•„ë˜ ì½”ë“œë¡œ ì „ì²´ êµì²´

@st.cache_data(ttl=43200) # 12ì‹œê°„ë§ˆë‹¤ ê°±ì‹ 
def get_economic_indicators():
    """[ìµœì¢… ê³ ë„í™”] ë°ì´í„° ê¸¸ì´ì— ë”°ë¼ 'ì¥ê¸°/ë‹¨ê¸° ì¶”ì„¸'ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    indicator_definitions = {
        "ë¯¸êµ­ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨": {"code": "T10Y2Y", "type": "ì„ í–‰"},
        "ê°œì¸ì†Œë¹„ì§€ì¶œ(PCE)": {"code": "PCE", "type": "ë™í–‰"},
        "ì‹¤ì—…ë¥ ": {"code": "UNRATE", "type": "í›„í–‰"},
        "ê·¼ì› CPI (YoY)": {"code": "CORESTICKM159SFRBATL", "type": "í›„í–‰"},
    }
    try:
        fred_api_key = st.secrets["FRED_API_KEY"]
        fred = Fred(api_key=fred_api_key)
        results = {}
        start_date = (datetime.now() - timedelta(days=400)).strftime('%Y-%m-%d')

        for name, info in indicator_definitions.items():
            series = fred.get_series(info['code'], observation_start=start_date)
            if not series.empty:
                series_monthly = series.resample('M').last().dropna()
                
                # [í•µì‹¬] ë°ì´í„° ê¸¸ì´ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì¶”ì„¸ ë¶„ì„
                if len(series_monthly) >= 6:
                    # Case 1: ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ì¥ê¸° ì¶”ì„¸ ë¶„ì„
                    avg_recent_3m = series_monthly.iloc[-3:].mean()
                    avg_prev_3m = series_monthly.iloc[-6:-3].mean()
                    trend_change = avg_recent_3m - avg_prev_3m
                    trend_label = "(3mo avg)"
                elif len(series_monthly) >= 2:
                    # Case 2: ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ë‹¨ê¸° ì¶”ì„¸(MoM) ë¶„ì„
                    latest_value_trend = series_monthly.iloc[-1]
                    prev_value_trend = series_monthly.iloc[-2]
                    trend_change = latest_value_trend - prev_value_trend
                    trend_label = "(MoM)"
                else:
                    # ì¶”ì„¸ ë¶„ì„ ë¶ˆê°€
                    trend_change = 0
                    trend_label = ""

                latest_value = series_monthly.iloc[-1]
                
                if trend_change > 0.05: trend_icon = "ğŸ”¼"
                elif trend_change < -0.05: trend_icon = "ğŸ”½"
                else: trend_icon = "âºï¸"
                trend_text = f"{trend_icon} {trend_label}"

                # (ì´í•˜ ìƒíƒœ í‰ê°€ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
                status_text = "ì¤‘ë¦½ì  âšªï¸"
                if name == "ë¯¸êµ­ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨":
                    if latest_value > 0.25: status_text = "ê¸ì •ì  ğŸŸ¢"
                    elif latest_value < 0: status_text = "ë¶€ì •ì  ğŸ”´"
                # ... (ë‹¤ë¥¸ ì§€í‘œë“¤ì˜ ìƒíƒœ í‰ê°€ ë¡œì§)
                
                results[name] = {
                    "value": latest_value, "type": info['type'],
                    "trend": trend_text, "status": status_text,
                    "timeseries": series_monthly.tail(12).round(2).tolist()
                }
        return results
    except Exception as e:
        st.warning(f"FRED ê²½ì œ ì§€í‘œ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return {}

# [ì‹ ê·œ ê¸°ëŠ¥] AI í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ ë¸Œë¦¬í•‘ ìƒì„± í•¨ìˆ˜
def generate_portfolio_briefing(summary_df, detail_df):
    """
    ëª©í‘œ ëŒ€ë¹„ ë°°ë¶„ í˜„í™©ê³¼ ê°œë³„ ì¢…ëª© ìƒì„¸ í˜„í™©ì„ ë°”íƒ•ìœ¼ë¡œ
    AIê°€ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì¢…í•© ì§„ë‹¨ ë° ì „ëµ ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    model = get_gem_core_ai()

    # AIì—ê²Œ ì „ë‹¬í•  ë°ì´í„° ìš”ì•½
    summary_text = summary_df.to_string(index=False)
    
    # ê±´ê°•ê²€ì§„ ë°ì´í„° ì¤‘ ìœ ì˜ë¯¸í•œ ì •ë³´ë§Œ í•„í„°ë§ (ì˜ˆ: RSI > 70 ë˜ëŠ” ê³ ì ëŒ€ë¹„ < -30%)
    critical_stocks = detail_df[
        (detail_df['RSI'] > 70) | (detail_df['ê³ ì ëŒ€ë¹„(%)'] < -30)
    ][['ì¢…ëª©ëª…', 'ìì‚°í‹°ì–´', 'RSI', 'ê³ ì ëŒ€ë¹„(%)']].copy()
    critical_text = "í˜„ì¬ íŠ¹ë³„í•œ ìœ„í—˜/ê¸°íšŒ ì‹ í˜¸ë¥¼ ë³´ì´ëŠ” ê°œë³„ ì¢…ëª©ì€ ì—†ìŠµë‹ˆë‹¤."
    if not critical_stocks.empty:
        critical_text = "ì•„ë˜ëŠ” í˜„ì¬ ìœ ì˜ë¯¸í•œ ì‹ í˜¸ë¥¼ ë³´ì´ëŠ” ê°œë³„ ì¢…ëª© í˜„í™©ì…ë‹ˆë‹¤:\n" + critical_stocks.to_string(index=False)

    prompt = f"""
    **SYSTEM ROLE:** ë‹¹ì‹ ì€ íˆ¬ì ì „ëµê°€ 'GEM: Finance'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” MASTERì˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, í˜„ì¬ ìƒíƒœë¥¼ ëª…í™•íˆ ì§„ë‹¨í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ì œì•ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. MASTERì˜ íˆ¬ì ì² í•™ì€ 'í˜„ëª…í•œ ê³µê²©'ì´ë©°, ë¹„ì¤‘ì´ ë¶€ì¡±í•œ ìì‚°ì„ ì €ë ´í•˜ê²Œ ë§¤ìˆ˜í•˜ê³ , ê³¼ì—´ëœ ìì‚°ì€ ì¼ë¶€ ì´ìµ ì‹¤í˜„í•˜ì—¬ ë¦¬ë°¸ëŸ°ì‹±í•˜ëŠ” ê²ƒì„ ì„ í˜¸í•©ë‹ˆë‹¤.

    **INPUT DATA:**
    1. ëª©í‘œ ëŒ€ë¹„ ìì‚° ë°°ë¶„ í˜„í™©:
    {summary_text}

    2. ì£¼ì˜ê°€ í•„ìš”í•œ ê°œë³„ ì¢…ëª© í˜„í™© (RSI ê³¼ì—´ ë˜ëŠ” ê³¼ë„í•œ í•˜ë½):
    {critical_text}

    **MISSION:**
    ìœ„ ë‘ ê°€ì§€ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬, ì•„ë˜ í˜•ì‹ì— ë§ì¶° 'AI í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ ë¸Œë¦¬í•‘'ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤. ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    ---
    ### ğŸ’¡ AI í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ ë¸Œë¦¬í•‘

    * **ì¢…í•© ì§„ë‹¨:** (ìì‚° ë°°ë¶„ í˜„í™©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ê°œë³„ ì¢…ëª©ì˜ ìœ„í—˜/ê¸°íšŒ ìš”ì†Œë¥¼ ì–¸ê¸‰í•˜ë©° í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤. ì˜ˆ: 'í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ì½”ì–´ ë¹„ì¤‘ì´ ë¶€ì¡±í•œ ìƒíƒœì´ë©°, ë™ì‹œì— í•µì‹¬ ìœ„ì„± ìì‚°ì¸ SMCIê°€ ë‹¨ê¸° ê³¼ì—´ ì‹ í˜¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.')

    * **ì „ëµ ì œì•ˆ:** (ìœ„ ì§„ë‹¨ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ë¦¬ë°¸ëŸ°ì‹± í–‰ë™ ê³„íšì„ ì œì•ˆí•©ë‹ˆë‹¤. ì–´ë–¤ ìì‚°ì„ íŒ”ê³ , ì–´ë–¤ ìì‚°ì„ ì‚¬ì•¼ í•˜ëŠ”ì§€ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì‹­ì‹œì˜¤. ì˜ˆ: 'ë”°ë¼ì„œ, ë‹¨ê¸° ê³¼ì—´ ìƒíƒœì¸ SMCIì˜ ì¼ë¶€ë¥¼ ì´ìµ ì‹¤í˜„í•˜ê³ , í™•ë³´ëœ í˜„ê¸ˆìœ¼ë¡œ ë¹„ì¤‘ì´ ë¶€ì¡±í•œ ì½”ì–´ ìì‚°ì„ ì¶”ê°€ ë§¤ìˆ˜í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë¦¬ë°¸ëŸ°ì‹±ì„ ê³ ë ¤í•  ìµœì ì˜ ì‹œì ì…ë‹ˆë‹¤.')
    ---
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"**AI ë¸Œë¦¬í•‘ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:**\n\n{e}"




# [ì‹ ê·œ] ë‹¤ë¥¸ ëª¨ë“  ë°ì´í„° í•¨ìˆ˜ì— ëŒ€í•œ í—ˆë¸Œ ê²½ìœ  í•¨ìˆ˜ë“¤

def create_hub_function(original_function, key_prefix, minutes_to_live=60):
    """
    ë°˜ë³µì ì¸ í—ˆë¸Œ í•¨ìˆ˜ ìƒì„±ì„ ìœ„í•œ íŒ©í† ë¦¬ í•¨ìˆ˜.
    """
    def hub_function(ticker):
        now = datetime.now()
        hub_key = f"{key_prefix}_{ticker}"
        
        if hub_key in st.session_state.data_hub:
            data, timestamp = st.session_state.data_hub[hub_key]
            if (now - timestamp) < timedelta(minutes=minutes_to_live):
                return data

        new_data = original_function(ticker)
        
        if new_data is not None: # ë°ì´í„°ê°€ Noneì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ì €ì¥
            st.session_state.data_hub[hub_key] = (new_data, now)
            
        return new_data
    return hub_function

# ê° ì›ë³¸ í•¨ìˆ˜ì— ëŒ€í•´ í—ˆë¸Œ ê²½ìœ  í•¨ìˆ˜ ìƒì„±
get_profile_from_hub = create_hub_function(get_company_profile, "profile")
get_news_from_hub = create_hub_function(get_company_news, "news")
get_financials_from_hub = create_hub_function(get_basic_financials, "financials")
get_peers_from_hub = create_hub_function(get_company_peers, "peers")
get_earnings_from_hub = create_hub_function(get_company_earnings, "earnings")
get_calendar_from_hub = create_hub_function(get_earnings_calendar, "calendar")
get_candles_from_hub = create_hub_function(get_stock_candles, "candles")


@st.cache_data
def get_analyst_ratings(ticker):
    """Finnhub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì• ë„ë¦¬ìŠ¤íŠ¸ í‰ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        ratings = finnhub_client.recommendation_trends(ticker)
        if ratings:
            # ê°€ì¥ ìµœì‹  ì›”ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©
            latest_rating = ratings[0]
            return {
                "period": latest_rating['period'],
                "strongBuy": latest_rating['strongBuy'],
                "buy": latest_rating['buy'],
                "hold": latest_rating['hold'],
                "sell": latest_rating['sell'],
                "strongSell": latest_rating['strongSell']
            }
    except Exception:
        return None
    return None

@st.cache_data
def get_insider_transactions(ticker):
    """Finnhub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ 90ì¼ê°„ì˜ ë‚´ë¶€ì ê±°ë˜ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        transactions = finnhub_client.stock_insider_transactions(ticker, _from=start_date.strftime('%Y-%m-%d'), to=end_date.strftime('%Y-%m-%d'))
        
        if transactions and 'data' in transactions and transactions['data']:
            df = pd.DataFrame(transactions['data'])
            # 'mspr'ëŠ” ì´ ê±°ë˜ ê¸ˆì•¡ì„ ì˜ë¯¸
            total_buy_value = df[df['change'] > 0]['mspr'].sum()
            total_sell_value = abs(df[df['change'] < 0]['mspr'].sum())
            net_value = total_buy_value - total_sell_value
            return {
                "totalBuyValue": total_buy_value,
                "totalSellValue": total_sell_value,
                "netValue": net_value
            }
    except Exception:
        return None
    return None

# ìƒˆë¡œìš´ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ì„ ì¤‘ì•™ í—ˆë¸Œì— ë“±ë¡
get_ratings_from_hub = create_hub_function(get_analyst_ratings, "ratings", minutes_to_live=1440) # í•˜ë£¨ì— í•œë²ˆ ê°±ì‹ 
get_insider_trans_from_hub = create_hub_function(get_insider_transactions, "insider", minutes_to_live=1440) # í•˜ë£¨ì— í•œë²ˆ ê°±ì‹ 


# [ì‹ ê·œ] 'ì¼ìƒ ê±´ê°•ê²€ì§„'ì„ ìˆ˜í–‰í•˜ëŠ” í†µí•© ë°ì´í„° ì²˜ë¦¬ê¸°
def get_health_check_data(ticker_list):
    """
    ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ 'ì¼ìƒ ê±´ê°•ê²€ì§„'ì„ ìˆ˜í–‰í•˜ê³ ,
    ê²°ê³¼ë¥¼ ë°ì´í„° í—ˆë¸Œì— ìºì‹œí•œ ë’¤ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    summary_list = []
    
    # yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì¢…ëª©ì˜ 1ë…„ì¹˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜´
    try:
        hist_data = yf.download(ticker_list, period="1y", progress=False)
        if hist_data.empty:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ì£¼ê°€ ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

    for ticker in ticker_list:
        hub_key = f"health_check_{ticker}"
        
        # 1. ìºì‹œ í™•ì¸ (1ì‹œê°„ì§œë¦¬ ìºì‹œ)
        now = datetime.now()
        if hub_key in st.session_state.data_hub:
            data, timestamp = st.session_state.data_hub[hub_key]
            if (now - timestamp) < timedelta(hours=1):
                summary_list.append(data)
                continue # ìºì‹œëœ ë°ì´í„° ì‚¬ìš©

        # 2. ë°ì´í„° ê³„ì‚° (ìºì‹œê°€ ì—†ì„ ê²½ìš°)
        try:
            # MultiIndexì—ì„œ ë‹¨ì¼ ì¢…ëª© ë°ì´í„° ì¶”ì¶œ
            if len(ticker_list) > 1:
                hist = hist_data.loc[:, (slice(None), ticker)]
                hist.columns = hist.columns.droplevel(1)
            else:
                hist = hist_data
            
            if hist.empty or len(hist) < 20: continue

            # í•µì‹¬ ì§€í‘œ ê³„ì‚°
            current_price = hist['Close'].iloc[-1]
            prev_price = hist['Close'].iloc[-2]
            change_percent = ((current_price - prev_price) / prev_price) * 100 if prev_price != 0 else 0
            high_52w = hist['High'].max()
            mdd_percent = ((current_price - high_52w) / high_52w) * 100 if high_52w != 0 else 0
            
            delta = hist['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs.iloc[-1]))
            
            volume_avg_20d = hist['Volume'].rolling(window=20).mean().iloc[-1]
            volume_change = (hist['Volume'].iloc[-1] / volume_avg_20d) * 100 if volume_avg_20d != 0 else 0

            ticker_summary = {
                "ì¢…ëª©ì½”ë“œ": ticker, "í˜„ì¬ê°€": current_price, "ë“±ë½ë¥ (%)": change_percent,
                "ê³ ì ëŒ€ë¹„(%)": mdd_percent, "RSI": rsi, "ê±°ë˜ëŸ‰(%)": volume_change
            }

            # 3. ê³„ì‚° ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            st.session_state.data_hub[hub_key] = (ticker_summary, now)
            summary_list.append(ticker_summary)

        except Exception:
            continue
            
    if not summary_list:
        return pd.DataFrame()
    
    df = pd.DataFrame(summary_list)
    # ë°ì´í„° íƒ€ì…ì„ ìˆ«ìë¡œ ëª…ì‹œì  ë³€í™˜
    numeric_cols = ["í˜„ì¬ê°€", "ë“±ë½ë¥ (%)", "ê³ ì ëŒ€ë¹„(%)", "RSI", "ê±°ë˜ëŸ‰(%)"]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        
    return df

# [âœ¨ NEW & REVISED] 'ì¢…í•© íŒ©í„° ì‹œíŠ¸'ë¥¼ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ í•µì‹¬ í•¨ìˆ˜
def create_factor_sheet(ticker, latest_log, candles_df, news, ratings, insider_trans):
    """
    ëª¨ë“  ë³€ê²½ì  íŒ©í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  AIì—ê²Œ ì „ë‹¬í•  'ì¢…í•© íŒ©í„° ì‹œíŠ¸' í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if latest_log is None:
        return "ê³¼ê±° ë¶„ì„ ê¸°ë¡ì´ ì—†ì–´ ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."

    sheet = [f"**[ì¢…í•© íŒ©í„° ì‹œíŠ¸: {ticker}]**"]
    
    # 1. ê³¼ê±° ë°ì´í„° ë¡œë“œ
    try:
        past_data = json.loads(latest_log.get('ì£¼ìš” ë°ì´í„°', '{}'))
        past_quote = past_data.get('quote', {})
        past_price = past_quote.get('c', 0)
    except Exception:
        past_price = 0

    # 2. ì‹œì¥ ë°ì´í„° íŒ©í„°
    if not candles_df.empty:
        current_price = candles_df['Close'].iloc[-1]
        market_factors = []
        if past_price > 0:
            price_change_cum = ((current_price - past_price) / past_price) * 100
            market_factors.append(f"- ëˆ„ì  ë³€ë™ë¥ : {price_change_cum:+.2f}% (vs. ë§ˆì§€ë§‰ ë¶„ì„)")
        
        price_change_recent = ((current_price - candles_df['Close'].iloc[-2]) / candles_df['Close'].iloc[-2]) * 100
        market_factors.append(f"- ìµœê·¼ ë³€ë™ë¥ : {price_change_recent:+.2f}% (vs. ì „ì¼)")

        if len(candles_df) > 20:
            avg_volume_20d = candles_df['Volume'].rolling(window=20).mean().iloc[-2] # ì „ì¼ê¹Œì§€ì˜ í‰ê· 
            current_volume = candles_df['Volume'].iloc[-1]
            if avg_volume_20d > 0:
                volume_change_percent = (current_volume / avg_volume_20d) * 100
                market_factors.append(f"- ê±°ë˜ëŸ‰: 20ì¼ í‰ê·  ëŒ€ë¹„ {volume_change_percent:.0f}% ìˆ˜ì¤€")
        
        if market_factors:
            sheet.append("\n**I. ì‹œì¥ ë°ì´í„°**\n" + "\n".join(market_factors))

    # 3. ê¸°ìˆ ì  ìƒíƒœ íŒ©í„° (candles_dfëŠ” ì´ë¯¸ ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ ìƒíƒœë¡œ ì „ë‹¬ë°›ì•„ì•¼ í•¨)
    if not candles_df.empty and 'SMA20' in candles_df.columns:
        tech_factors = []
        latest = candles_df.iloc[-1]
        previous = candles_df.iloc[-2]
        # RSI ìƒíƒœ ë³€í™”
        if previous['RSI14'] < 70 and latest['RSI14'] >= 70: tech_factors.append("- RSI ê³¼ë§¤ìˆ˜ êµ¬ê°„(70) ì§„ì…")
        elif previous['RSI14'] > 30 and latest['RSI14'] <= 30: tech_factors.append("- RSI ê³¼ë§¤ë„ êµ¬ê°„(30) ì§„ì…")
        # MACD ì‹ í˜¸
        if previous['MACD'] < previous['SignalLine'] and latest['MACD'] > latest['SignalLine']: tech_factors.append("- MACD ê³¨ë“  í¬ë¡œìŠ¤ ë°œìƒ")
        elif previous['MACD'] > previous['SignalLine'] and latest['MACD'] < latest['SignalLine']: tech_factors.append("- MACD ë°ë“œ í¬ë¡œìŠ¤ ë°œìƒ")
        
        if tech_factors:
            sheet.append("\n**II. ê¸°ìˆ ì  ìƒíƒœ**\n" + "\n".join(tech_factors))

    # 4. ê¸°ì—… ë° ì™¸ë¶€ í™˜ê²½ íŒ©í„°
    env_factors = []
    if news:
        past_news_headlines = past_data.get('news_headlines', [])
        current_news_headlines = [item['headline'] for item in news[:5]]
        new_headlines = [h for h in current_news_headlines if h not in past_news_headlines]
        if new_headlines:
            env_factors.append(f"- {len(new_headlines)}ê°œì˜ ì‹ ê·œ ì£¼ìš” ë‰´ìŠ¤ ë°œìƒ")

    if ratings:
        buy_ratings = ratings.get('strongBuy', 0) + ratings.get('buy', 0)
        total_ratings = buy_ratings + ratings.get('hold', 0) + ratings.get('sell', 0) + ratings.get('strongSell', 0)
        if total_ratings > 0:
            buy_ratio = (buy_ratings / total_ratings) * 100
            env_factors.append(f"- ìµœì‹  ì• ë„ë¦¬ìŠ¤íŠ¸ 'ë§¤ìˆ˜' ì˜ê²¬: {buy_ratio:.0f}% ({total_ratings}ëª… ì°¸ì—¬)")

    if insider_trans and insider_trans.get('netValue') != 0:
        if insider_trans['netValue'] > 0:
            env_factors.append(f"- ìµœê·¼ 90ì¼ê°„ ë‚´ë¶€ì ìˆœë§¤ìˆ˜: ì•½ ${insider_trans['netValue']:,.0f}")
        else:
            env_factors.append(f"- ìµœê·¼ 90ì¼ê°„ ë‚´ë¶€ì ìˆœë§¤ë„: ì•½ ${abs(insider_trans['netValue']):,.0f}")

    if env_factors:
        sheet.append("\n**III. ê¸°ì—… ë° ì™¸ë¶€ í™˜ê²½**\n" + "\n".join(env_factors))

    if len(sheet) == 1: # ì•„ë¬´ íŒ©í„°ë„ ì¶”ê°€ë˜ì§€ ì•Šì•˜ë‹¤ë©´
        return "ë§ˆì§€ë§‰ ë¶„ì„ ì´í›„ ìœ ì˜ë¯¸í•œ ë°ì´í„° ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
    return "\n".join(sheet)


# --- 4. ë©”ì¸ UI ë° ë¡œì§ ---
st.title("ğŸ’ GEM: Finance Dashboard")
st.caption("v34.0 - Final Strategy Implemented")

# [ìˆ˜ì •] ëª¨ë“  ì„¸ì…˜ ìƒíƒœë¥¼ ì—¬ê¸°ì„œ í•œ ë²ˆì— ì´ˆê¸°í™”
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.active_view = "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤"
    st.session_state.data_hub = {}
    # ... ê¸°íƒ€ ì´ˆê¸°í™” í•„ìš”í•œ session_state ...

if not st.session_state.data_loaded:
    with st.spinner("Initializing System... Loading data from Google Sheets..."):
        st.session_state.portfolio_df, st.session_state.watchlist_df, st.session_state.cash_df = load_data_from_gsheet()
    st.session_state.data_loaded = True
    st.rerun() # ë°ì´í„°ë¥¼ ë¡œë“œí•œ í›„, ê¸°ë³¸ ë·°ë¥¼ ì œëŒ€ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´ í•œ ë²ˆ ë” ì¬ì‹¤í–‰

# --- í¬íŠ¸í´ë¦¬ì˜¤ ë·° ---
# --- í¬íŠ¸í´ë¦¬ì˜¤ ë·° ---
elif st.session_state.active_view == "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤":
    st.header("ğŸ’¼ Portfolio Command Center")
    
    portfolio_df = st.session_state.portfolio_df
    cash_df = st.session_state.cash_df

    if not cash_df.empty:
        cash_df = cash_df[~cash_df['ì¢…ëª©ëª…'].str.contains('ë¹„ìƒê¸ˆ', na=False)]

    if not portfolio_df.empty or not cash_df.empty:
        # --- 1. ëª¨ë“  ë°ì´í„° ì¤€ë¹„ ë° ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìƒì„± ---
        all_tickers_for_price = portfolio_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        if all_tickers_for_price:
            current_prices, usd_krw_rate = get_current_prices_and_rate(all_tickers_for_price)
            st.sidebar.metric("USD/KRW í™˜ìœ¨", f"â‚©{usd_krw_rate:,.2f}")
            invest_dashboard_df = create_portfolio_dashboard(portfolio_df, current_prices, usd_krw_rate)
        else:
            invest_dashboard_df = pd.DataFrame()

        health_check_df = pd.DataFrame()
        if not invest_dashboard_df.empty:
            all_investment_tickers = invest_dashboard_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
            if all_investment_tickers:
                with st.spinner("ê°œë³„ ìì‚° ê±´ê°•ê²€ì§„ ìˆ˜í–‰ ì¤‘..."):
                    health_check_df = get_health_check_data(all_investment_tickers)
            if not health_check_df.empty:
                invest_dashboard_df = pd.merge(invest_dashboard_df, health_check_df, on='ì¢…ëª©ì½”ë“œ', how='left')

        cash_dashboard_df = pd.DataFrame()
        if not cash_df.empty:
            cash_dashboard_df = cash_df.rename(columns={'ê¸ˆì•¡(KRW)': 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'})
            cash_dashboard_df['ìˆ˜ìµë¥  (%)'] = 0; cash_dashboard_df['ì†ìµ (ê³ ìœ )'] = 0; cash_dashboard_df['ìˆ˜ëŸ‰'] = '-';
            cash_dashboard_df['í‰ê·  ë‹¨ê°€ (ê³ ìœ )'] = '-'; cash_dashboard_df['í˜„ì¬ê°€ (ê³ ìœ )'] = '-';

        final_dashboard_df = pd.concat([invest_dashboard_df, cash_dashboard_df], ignore_index=True)
        
        final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'] = (
            final_dashboard_df['ê³„ì¢Œêµ¬ë¶„']
            .astype(str).str.strip()
            .replace({'nan': 'í˜„ê¸ˆ', 'None': 'í˜„ê¸ˆ', '': 'í˜„ê¸ˆ'}).str.lower()
        )
        final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'] = final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'].replace({
            'irp': 'IRP', 'íšŒì‚¬í‡´ì§dc': 'íšŒì‚¬í‡´ì§DC', 'isa': 'ISA',
            'í•´ì™¸ ì§íˆ¬': 'í•´ì™¸ ì§íˆ¬', 'ì—°ê¸ˆì €ì¶•': 'ì—°ê¸ˆì €ì¶•', 'í˜„ê¸ˆ': 'í˜„ê¸ˆ'
        })

        # --- 2. AI ë¸Œë¦¬í•‘ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ ---
        direct_investment_df = final_dashboard_df[final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'] == 'í•´ì™¸ ì§íˆ¬'].copy()
        total_direct_investment_value = direct_investment_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
        targets = {"ì½”ì–´ (Tier 1+1.5)": 60.0, "í•µì‹¬ ìœ„ì„± (Tier 2)": 30.0, "í…Œë§ˆí˜• ìœ„ì„± (Tier 3)": 10.0}
        summary_df_for_ai = pd.DataFrame()

        if total_direct_investment_value > 0 and 'ìì‚°í‹°ì–´' in direct_investment_df.columns:
            core_value = direct_investment_df[direct_investment_df['ìì‚°í‹°ì–´'].isin(['Tier 1', 'Tier 1.5'])]['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
            tier2_value = direct_investment_df[direct_investment_df['ìì‚°í‹°ì–´'] == 'Tier 2']['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
            tier3_value = direct_investment_df[direct_investment_df['ìì‚°í‹°ì–´'] == 'Tier 3']['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
            current_alloc = {
                "ì½”ì–´ (Tier 1+1.5)": (core_value / total_direct_investment_value) * 100,
                "í•µì‹¬ ìœ„ì„± (Tier 2)": (tier2_value / total_direct_investment_value) * 100,
                "í…Œë§ˆí˜• ìœ„ì„± (Tier 3)": (tier3_value / total_direct_investment_value) * 100,
            }
            summary_data_for_ai = []
            for group, target_pct in targets.items():
                current_pct = current_alloc.get(group, 0)
                diff = current_pct - target_pct
                status = "ì •ìƒ"
                if diff < -5: status = "ë¶€ì¡±"
                elif diff > 5: status = "ê³¼ë‹¤"
                summary_data_for_ai.append({
                    "ìì‚° ê·¸ë£¹": group, "í˜„ì¬ ë¹„ì¤‘(%)": current_pct, "ëª©í‘œ ë¹„ì¤‘(%)": target_pct,
                    "ì°¨ì´(%)": diff, "ìƒíƒœ í‰ê°€": status
                })
            summary_df_for_ai = pd.DataFrame(summary_data_for_ai)
        
        # --- 3. [ì‹ ê·œ] AI í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ ë¸Œë¦¬í•‘ í‘œì‹œ ---
        if not summary_df_for_ai.empty:
            with st.spinner("AIê°€ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ê³  ì „ëµì„ ì œì•ˆí•˜ëŠ” ì¤‘..."):
                briefing = generate_portfolio_briefing(summary_df_for_ai, final_dashboard_df)
                st.markdown(briefing)

        # --- 2. ê³„ì¢Œë³„ ì„±ê³¼ ìš”ì•½ ---
        st.subheader("ğŸ“Š ì„±ê³¼ ìš”ì•½")

        total_value = final_dashboard_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
        total_invest_df = final_dashboard_df[final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'] != 'í˜„ê¸ˆ']
        total_cost = total_invest_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].sum() if not total_invest_df.empty else 0
        total_pl = total_invest_df['ì†ìµ (KRW)'].sum() if not total_invest_df.empty else 0
        total_pl_percent = (total_pl / total_cost) * 100 if total_cost > 0 else 0
        
        with st.container(border=True):
            st.markdown("##### ì´ ìì‚° (ì „ì²´ ê³„ì¢Œ, ë¹„ìƒê¸ˆ ì œì™¸)")
            cols = st.columns(3)
            cols[0].metric("ì´ í‰ê°€ ìì‚°", f"â‚©{total_value:,.0f}")
            cols[1].metric("ì´ ì†ìµ (íˆ¬ì)", f"â‚©{total_pl:,.0f}", f"{total_pl_percent:.2f}%")
            cols[2].metric("ì´ íˆ¬ì ì›ê¸ˆ", f"â‚©{total_cost:,.0f}")

        with st.expander("ê³„ì¢Œë³„ ìƒì„¸ ì„±ê³¼ ë³´ê¸°", expanded=True):
            # (ì´í•˜ ë¡œì§ì€ ë³€ê²½ ì—†ìŒ, ì´ì œ ì •ìƒì ìœ¼ë¡œ ì‘ë™)
            account_summary_data = []
            accounts = final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'].unique()
            for account in accounts:
                account_df = final_dashboard_df[final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'] == account]
                account_invest_df = account_df[account_df['ê³„ì¢Œêµ¬ë¶„'] != 'í˜„ê¸ˆ']
                acc_total_value = account_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
                acc_total_cost = account_invest_df['ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)'].sum() if not account_invest_df.empty else 0
                acc_total_pl = account_invest_df['ì†ìµ (KRW)'].sum() if not account_invest_df.empty else 0
                acc_total_pl_percent = (acc_total_pl / acc_total_cost) * 100 if acc_total_cost > 0 else 0
                
                account_summary_data.append({
                    "ê³„ì¢Œ êµ¬ë¶„": account, "í‰ê°€ ìì‚°": acc_total_value,
                    "ì†ìµ": acc_total_pl, "ìˆ˜ìµë¥ (%)": acc_total_pl_percent,
                    "íˆ¬ì ì›ê¸ˆ": acc_total_cost
                })
            
            if account_summary_data:
                account_summary_df = pd.DataFrame(account_summary_data)
                account_order = ['í•´ì™¸ ì§íˆ¬', 'ISA', 'ì—°ê¸ˆì €ì¶•', 'IRP', 'íšŒì‚¬í‡´ì§DC', 'í˜„ê¸ˆ']
                ordered_categories = [acc for acc in account_order if acc in account_summary_df['ê³„ì¢Œ êµ¬ë¶„'].values]
                account_summary_df['ê³„ì¢Œ êµ¬ë¶„'] = pd.Categorical(account_summary_df['ê³„ì¢Œ êµ¬ë¶„'], categories=ordered_categories, ordered=True)
                account_summary_df = account_summary_df.sort_values('ê³„ì¢Œ êµ¬ë¶„').reset_index(drop=True)

                def color_return(val):
                    color = '#4CAF50' if val > 0 else '#F44336' if val < 0 else '#333333'
                    return f'color: {color}'
                
                st.dataframe(account_summary_df.style.format({
                                 "í‰ê°€ ìì‚°": "â‚©{:,.0f}", "ì†ìµ": "â‚©{:,.0f}",
                                 "ìˆ˜ìµë¥ (%)": "{:,.2f}%", "íˆ¬ì ì›ê¸ˆ": "â‚©{:,.0f}"
                             }).applymap(color_return, subset=['ìˆ˜ìµë¥ (%)']), 
                             use_container_width=True)
        st.divider()

        # --- 3. ëª©í‘œ ëŒ€ë¹„ ìì‚° ë°°ë¶„ í˜„í™© (í•´ì™¸ ì§íˆ¬) ---
        st.subheader("ğŸ¯ ëª©í‘œ ëŒ€ë¹„ ìì‚° ë°°ë¶„ í˜„í™© (í•´ì™¸ ì§íˆ¬)")
        direct_investment_df = final_dashboard_df[final_dashboard_df['ê³„ì¢Œêµ¬ë¶„'] == 'í•´ì™¸ ì§íˆ¬'].copy()
        total_direct_investment_value = direct_investment_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
        targets = {"ì½”ì–´ (Tier 1+1.5)": 60.0, "í•µì‹¬ ìœ„ì„± (Tier 2)": 30.0, "í…Œë§ˆí˜• ìœ„ì„± (Tier 3)": 10.0}

        if total_direct_investment_value > 0 and 'ìì‚°í‹°ì–´' in direct_investment_df.columns:
            core_value = direct_investment_df[direct_investment_df['ìì‚°í‹°ì–´'].isin(['Tier 1', 'Tier 1.5'])]['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
            tier2_value = direct_investment_df[direct_investment_df['ìì‚°í‹°ì–´'] == 'Tier 2']['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
            tier3_value = direct_investment_df[direct_investment_df['ìì‚°í‹°ì–´'] == 'Tier 3']['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
            current_alloc = {
                "ì½”ì–´ (Tier 1+1.5)": (core_value / total_direct_investment_value) * 100,
                "í•µì‹¬ ìœ„ì„± (Tier 2)": (tier2_value / total_direct_investment_value) * 100,
                "í…Œë§ˆí˜• ìœ„ì„± (Tier 3)": (tier3_value / total_direct_investment_value) * 100,
            }
            summary_data = []
            for group, target_pct in targets.items():
                current_pct = current_alloc.get(group, 0)
                diff = current_pct - target_pct
                status = "ğŸŸ¢ ì •ìƒ"
                if diff < -5: status = "ğŸ”´ ë¶€ì¡±"
                elif diff > 5: status = "ğŸŸ¡ ê³¼ë‹¤"
                summary_data.append({
                    "ìì‚° ê·¸ë£¹": group, "í˜„ì¬ ë¹„ì¤‘(%)": current_pct, "ëª©í‘œ ë¹„ì¤‘(%)": target_pct,
                    "ì°¨ì´(%)": diff, "ìƒíƒœ í‰ê°€": status
                })
            summary_df = pd.DataFrame(summary_data)
            def color_status(val):
                color = 'red' if 'ë¶€ì¡±' in val else 'orange' if 'ê³¼ë‹¤' in val else 'green'
                return f'color: {color}'
            st.dataframe(summary_df.style
                         .format({"í˜„ì¬ ë¹„ì¤‘(%)": "{:.1f}%", "ëª©í‘œ ë¹„ì¤‘(%)": "{:.1f}%", "ì°¨ì´(%)": "{:+.1f}%"})
                         .applymap(color_status, subset=['ìƒíƒœ í‰ê°€'])
                         .bar(subset=["í˜„ì¬ ë¹„ì¤‘(%)"], color='lightblue', vmin=0, vmax=100),
                         use_container_width=True)
        else:
            st.warning("'í•´ì™¸ ì§íˆ¬' ê³„ì¢Œì— ìì‚°ì´ ì—†ê±°ë‚˜ 'ìì‚°í‹°ì–´'ê°€ ì§€ì •ë˜ì§€ ì•Šì•„ ëª©í‘œ ëŒ€ë¹„ í˜„í™©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.divider()
        
         # --- 4. ë³´ìœ  ìì‚° ìƒì„¸ ë° ìì‚° ë°°ë¶„ ì°¨íŠ¸ ---
        col1, col2 = st.columns([0.7, 0.3])
        with col1:
            st.subheader("ë³´ìœ  ìì‚° ìƒì„¸ (ì „ì²´)")
            display_cols = ['ê³„ì¢Œêµ¬ë¶„', 'ì¢…ëª©ëª…', 'ìì‚°í‹°ì–´', 'ìˆ˜ëŸ‰', 'í‰ê·  ë‹¨ê°€ (ê³ ìœ )', 'í˜„ì¬ê°€ (ê³ ìœ )',  
                            'ì†ìµ (ê³ ìœ )', 'ìˆ˜ìµë¥  (%)', 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)', 
                            'ê³ ì ëŒ€ë¹„(%)', 'RSI', 'ê±°ë˜ëŸ‰(%)']
            
            formatter = {'ì†ìµ (ê³ ìœ )': '{:,.2f}', 'ìˆ˜ìµë¥  (%)': '{:.2f}%', 'í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)': 'â‚©{:,.0f}', 
                         "ê³ ì ëŒ€ë¹„(%)": "{:,.2f}%", "RSI": "{:.1f}", "ê±°ë˜ëŸ‰(%)": "{:,.0f}%"}
            
            # âœ¨ [í•µì‹¬ ìˆ˜ì •] ë¶ˆí•„ìš”í•œ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ ì‚­ì œ, ìµœì¢… ë°ì´í„°í”„ë ˆì„ì„ ë°”ë¡œ ì‚¬ìš©
            st.dataframe(final_dashboard_df.style
                         .format(formatter, na_rep="-")
                         .background_gradient(cmap='RdYlGn', subset=['ìˆ˜ìµë¥  (%)'])
                         .bar(subset=['ê³ ì ëŒ€ë¹„(%)'], color='#FFA07A', vmin=-100, vmax=0)
                         .bar(subset=['RSI'], align='mid', color=['#d65f5f', '#5fba7d'], vmin=0, vmax=100)
                         .bar(subset=['ê±°ë˜ëŸ‰(%)'], color='lightblue'), 
                         use_container_width=True,
                         column_order=display_cols # ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
            )
        
        with col2:
            st.subheader("ìì‚° ë°°ë¶„ (ì „ì²´)")
            chart_group_by = st.radio("ì°¨íŠ¸ ê¸°ì¤€", ['ìì‚°í‹°ì–´', 'ê³„ì¢Œêµ¬ë¶„'], horizontal=True, key='chart_group')
            filter_cols = st.columns(2)
            exclude_base = filter_cols[0].checkbox("'ê¸°ë°˜' í‹°ì–´ ì œì™¸", value=True)
            exclude_cash = filter_cols[1].checkbox("'í˜„ê¸ˆ' ìì‚° ì œì™¸", value=True)
            
            chart_df = final_dashboard_df.copy()
            
            if exclude_base and 'ìì‚°í‹°ì–´' in chart_df.columns:
                chart_df = chart_df[~chart_df['ìì‚°í‹°ì–´'].str.contains('ê¸°ë°˜', na=False)]
            if exclude_cash and 'ìì‚°í‹°ì–´' in chart_df.columns:
                chart_df = chart_df[~chart_df['ìì‚°í‹°ì–´'].str.contains('í˜„ê¸ˆ', na=False)]
            
            if not chart_df.empty and chart_df['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum() > 0:
                allocation = chart_df.groupby(chart_group_by)['í˜„ì¬ í‰ê°€ ê¸ˆì•¡ (KRW)'].sum()
                fig_tier = px.pie(values=allocation.values, names=allocation.index, title=f"{chart_group_by}ë³„ ë¹„ì¤‘", hole=.3)
                st.plotly_chart(fig_tier, use_container_width=True)
            else:
                st.warning("ì°¨íŠ¸ì— í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("Google Sheetsì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ë˜ëŠ” í˜„ê¸ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# --- [ì¶”ê°€] ë ˆì´ë” ë·° ---
elif st.session_state.active_view == "ğŸ“¡ ë ˆì´ë”":
    st.header("ğŸ“¡ Stock Radar")

    watchlist_df = st.session_state.watchlist_df

    if watchlist_df.empty or 'ì¢…ëª©ì½”ë“œ' not in watchlist_df.columns:
        st.info("ê´€ì‹¬ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. Google Sheetsì˜ 'Watchlist'ì— ì¢…ëª©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else:
        tickers = watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()

        # [ìˆ˜ì •] ìŠ¤í”¼ë„ˆ ë©”ì‹œì§€ë¥¼ í˜„ì¬ ì‘ì—…ì— ë§ê²Œ ë³€ê²½
        with st.spinner("ë ˆì´ë” ë°ì´í„°ë¥¼ ìŠ¤ìº”í•˜ëŠ” ì¤‘... (ì¼ìƒ ê±´ê°•ê²€ì§„ ìˆ˜í–‰)"):
            # [ìˆ˜ì •] ìƒˆë¡œìš´ 'í†µí•© ê±´ê°•ê²€ì§„ ëª¨ë“ˆ'ì„ í˜¸ì¶œí•˜ë„ë¡ ë³€ê²½
            radar_df = get_health_check_data(tickers)

        if not radar_df.empty:
            # [ë³€ê²½ ì—†ìŒ] ì´í•˜ ë°ì´í„°í”„ë ˆì„ ìŠ¤íƒ€ì¼ë§ ë° í‘œì‹œ ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•©ë‹ˆë‹¤.
            formatter = {
                "ë“±ë½ë¥ (%)": "{:,.2f}%",
                "ê³ ì ëŒ€ë¹„(%)": "{:,.2f}%",
                "RSI": "{:.1f}",
                "ê±°ë˜ëŸ‰(%)": "{:,.0f}%",
                "í˜„ì¬ê°€": lambda x: f"${x:,.2f}" # ê°„ë‹¨í•˜ê²Œ ë‹¬ëŸ¬ë¡œ í†µì¼ (ì¶”í›„ ê³ ë„í™” ê°€ëŠ¥)
            }

            st.dataframe(radar_df.style
                .format(formatter)
                .background_gradient(cmap='RdYlGn', subset=['ë“±ë½ë¥ (%)'])
                .bar(subset=['ê³ ì ëŒ€ë¹„(%)'], color='#FFA07A')
                .bar(subset=['RSI'], align='mid', color=['#d65f5f', '#5fba7d'])
                .bar(subset=['ê±°ë˜ëŸ‰(%)'], color='lightblue'),
                use_container_width=True
            )
        else:
            st.error("ë ˆì´ë” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

elif st.session_state.active_view == "ğŸ”­ ì‹œì¥ ê±´ê°• ìƒíƒœ":
    st.header("ğŸ”­ Market Health Dashboard")

    # --- 1. ëª¨ë“  ë°ì´í„° ì¤€ë¹„ ---
    with st.spinner("ì‹œì¥ ë°ì´í„° ë° ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘..."):
        market_data, hist_data = get_market_status_data()
        sector_perf_df = get_sector_performance()
        theme_perf = get_theme_etf_performance()

        # --- ì‹ ê·œ ë°ì´í„° ë¡œë“œ ---
        eco_indicators = get_economic_indicators()
        
        # ì´ë²¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        eco_events = get_economic_calendar()
        portfolio_tickers = st.session_state.portfolio_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        watchlist_tickers = st.session_state.watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        all_my_tickers = list(set(portfolio_tickers + watchlist_tickers))
        earnings_events = get_portfolio_earnings_calendar(all_my_tickers)

        combined_events = []
        for event in eco_events:
            combined_events.append({'date': event['time'].split(' ')[0], 'type': 'eco', 'data': event})
        for event in earnings_events:
            combined_events.append({'date': event['date'], 'type': 'earn', 'data': event})
        sorted_events = sorted(combined_events, key=lambda x: x['date'])

    # --- 2. AI ì¢…í•© ë¶„ì„ (ëª¨ë“  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ í›„ ì‹¤í–‰) ---
    with st.spinner("AIê°€ ì‹œì¥ ê±´ê°• ìƒíƒœ ë° ë¯¸ë˜ ì´ë²¤íŠ¸ë¥¼ ì¢…í•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        hub_key = "market_briefing_v4"
        now = datetime.now()
        if hub_key in st.session_state.data_hub and (now - st.session_state.data_hub[hub_key][1]) < timedelta(minutes=5):
            briefing_result = st.session_state.data_hub[hub_key][0]
        else:
            briefing_result = generate_market_health_briefing(market_data, hist_data, sector_perf_df, theme_perf, sorted_events, eco_indicators)
            st.session_state.data_hub[hub_key] = (briefing_result, now)

    # --- 3. UI í‘œì‹œ ---
    # AI ë¸Œë¦¬í•‘ í‘œì‹œ
    summary = briefing_result.get("summary", "AIê°€ ìš”ì•½ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    full_report = briefing_result.get("report", "ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.subheader("ğŸ’¡ AI ì¢…í•© ì§„ë‹¨ ìš”ì•½")
    st.info(summary)
    with st.expander("ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ë³´ê¸°"):
        st.markdown(full_report)
    # --- [MOD v36.6 End] ---

    if market_data:
        st.divider()

         # --- [MOD v46 Start] ê±°ì‹œ ì§€í‘œ ì„¹ì…˜ UI ì¬êµ¬ì„± ---
        st.subheader("ğŸ”­ ì‹œì¥ ì¢…í•© ê³„ê¸°íŒ")

        # 2. í•µì‹¬ ê²½ì œ ì§€í‘œ (ì„ í–‰/ë™í–‰/í›„í–‰)
        st.markdown("##### ğŸ”‘ í•µì‹¬ ê²½ì œ ì§€í‘œ")

        eco_indicators = get_economic_indicators()
        if eco_indicators:
            cols = st.columns(len(eco_indicators))
            for i, (name, data) in enumerate(eco_indicators.items()):
                
                # [ê³ ë„í™”] ìƒíƒœ(status)ì— ë”°ë¼ ë¸íƒ€ ìƒ‰ìƒ ê²°ì •
                delta_color = "off"
                if "ê¸ì •ì " in data['status']: delta_color = "normal"
                elif "ë¶€ì •ì " in data['status']: delta_color = "inverse"
                    
                cols[i].metric(
                    label=f"{name} ({data['type']})",
                    value=f"{data['value']:,.2f}",
                    delta=f"{data['status']} {data['trend']}", # ìƒíƒœì™€ ì¶”ì„¸ë¥¼ í•¨ê»˜ í‘œì‹œ
                    delta_color=delta_color
                )
        else:
            st.warning("í•µì‹¬ ê²½ì œ ì§€í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        
        st.divider()
        
        # 1. ê±°ì‹œ ê²½ì œ ì§€í‘œ ì„¹ì…˜ (ê¸°ì¡´ê³¼ ë™ì¼)
        st.subheader("ğŸŒ ê±°ì‹œ ê²½ì œ ì§€í‘œ")
        # ... (ê±°ì‹œ ì§€í‘œ í‘œì‹œí•˜ëŠ” cols, indices, for ë£¨í”„ ë“±ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€) ...
        cols = st.columns(5)
        indices = ["S&P 500", "Nasdaq", "VIX", "US 10Y", "USD/KRW"]
        for i, name in enumerate(indices):
            if name in market_data and market_data[name]["price"] != "N/A":
                d = market_data[name]
                cols[i].metric(label=name, value=f"{d['price']:,.2f}", delta=f"{d['change']:,.2f} ({d['change_percent']:.2f}%)" if name not in ['VIX', 'US 10Y'] else f"{d['change']:.2f}")
        cols = st.columns(4)
        indices = ["Dollar", "Crude Oil", "Gold", "KOSPI"]
        for i, name in enumerate(indices):
             if name in market_data and market_data[name]["price"] != "N/A":
                d = market_data[name]
                cols[i].metric(label=name, value=f"{d['price']:,.2f}", delta=f"{d['change']:.2f} ({d['change_percent']:.2f}%)" if name not in ['Dollar'] else f"{d['change']:.2f}")

        st.divider()

        # 2. ìê¸ˆ íë¦„ ë¶„ì„ ì„¹ì…˜ (íƒ­ìœ¼ë¡œ ë¶„ë¦¬)
        st.subheader("ğŸ“Š ìê¸ˆ íë¦„ ë¶„ì„")
        tab1, tab2 = st.tabs(["ì „ì²´ ì„¹í„° íë¦„ (11 Sectors)", "í•µì‹¬ í…Œë§ˆ & ìì‚°êµ°"])

        with tab1:
            # âœ¨ [ë³µì›] 11ê°œ ì„¹í„° íˆíŠ¸ë§µ
            st.markdown("###### 5ì¼ ëˆ„ì  ìˆ˜ìµë¥  ê¸°ì¤€")
            sector_perf_df = get_sector_performance()
            if not sector_perf_df.empty:
                fig = px.treemap(sector_perf_df, 
                                 path=[px.Constant("S&P 500 Sectors"), 'Sector'], 
                                 values=sector_perf_df['Performance_5D'].abs(),
                                 color='Performance_5D',
                                 color_continuous_scale=['#d65f5f', 'lightgray', '#5fba7d'],
                                 color_continuous_midpoint=0,
                                 custom_data=['Performance_5D'])
                fig.update_traces(texttemplate='%{label}<br>%{customdata[0]:.2f}%')
                fig.update_layout(margin=dict(t=0, l=0, r=0, b=0))
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("ì„¹í„° ì„±ê³¼ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        with tab2:
            # âœ¨ [ì¬êµ¬ì„±] í…Œë§ˆ & ìì‚°êµ° ëŒ€ì‹œë³´ë“œ
            st.markdown("###### ë‹¹ì¼ ë“±ë½ë¥  ê¸°ì¤€ (vs S&P 500)")
            theme_perf = get_theme_etf_performance()
            if theme_perf:
                # ... (ì´í•˜ í…Œë§ˆ ETFë¥¼ í‘œì‹œí•˜ëŠ” display_etf_metric í•¨ìˆ˜ ë° UI ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼) ...
                spy_perf_change = theme_perf.get("S&P 500", {}).get('change_percent', 0)
                def display_etf_metric(col, theme_name):
                    perf_data = theme_perf.get(theme_name, {})
                    perf_change = perf_data.get('change_percent', 0)
                    trend = perf_data.get('trend', 'íš¡ë³´')
                    trend_icon = "ğŸ”¼" if trend == "ìƒìŠ¹" else "ğŸ”½" if trend == "í•˜ë½" else "âºï¸"
                    delta_vs_spy = perf_change - spy_perf_change
                    col.metric(
                        label=f"{trend_icon} {theme_name}",
                        value=f"{perf_change:.2f}%",
                        delta=f"{delta_vs_spy:.2f}% vs SPY",
                        delta_color="off" if abs(delta_vs_spy) < 0.01 else ("normal")
                    )
                st.markdown("<h6>1. ì‹œì¥ ì„±ê²© (Style)</h6>", unsafe_allow_html=True)
                cols = st.columns(2); display_etf_metric(cols[0], "ê°€ì¹˜ì£¼"); display_etf_metric(cols[1], "ì„±ì¥ì£¼")
                st.markdown("<h6>2. í•µì‹¬ ê¸°ìˆ  (Core Tech)</h6>", unsafe_allow_html=True)
                cols = st.columns(2); display_etf_metric(cols[0], "ë°˜ë„ì²´"); display_etf_metric(cols[1], "AI")
                st.markdown("<h6>3. ë¯¸ë˜ í…Œë§ˆ (Future Forward)</h6>", unsafe_allow_html=True)
                cols = st.columns(3); display_etf_metric(cols[0], "ë¡œë³´í‹±ìŠ¤"); display_etf_metric(cols[1], "ë°”ì´ì˜¤í…Œí¬"); display_etf_metric(cols[2], "ì°¨ì„¸ëŒ€ ì „ë ¥")
                st.markdown("<h6>4. ë°©ì–´ & ì¸ì»´ (Defense & Income)</h6>", unsafe_allow_html=True)
                cols = st.columns(2); display_etf_metric(cols[0], "ê³ ë°°ë‹¹"); display_etf_metric(cols[1], "ì¥ê¸°ì±„")
                st.markdown("<h6>5. ì‹œì¥ ì‹¬ë¦¬ (Sentiment)</h6>", unsafe_allow_html=True)
                cols = st.columns(2); display_etf_metric(cols[0], "í˜ì‹ ê¸°ìˆ "); display_etf_metric(cols[1], "ë¹„íŠ¸ì½”ì¸")
            else:
                st.warning("í…Œë§ˆ/ìì‚°êµ° ETF ì„±ê³¼ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        # --- [MOD v40 End] ---
        
        st.divider()
        st.subheader("ğŸ—“ï¸ í–¥í›„ 2ì£¼ ì£¼ìš” ì´ë²¤íŠ¸")

        # ë°ì´í„° ë¡œë“œ
        eco_events = get_economic_calendar()
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë° ê´€ì‹¬ì¢…ëª© í‹°ì»¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        portfolio_tickers = st.session_state.portfolio_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        watchlist_tickers = st.session_state.watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist()
        all_my_tickers = list(set(portfolio_tickers + watchlist_tickers))
        
        earnings_events = get_portfolio_earnings_calendar(all_my_tickers)

        # ë‘ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ í†µí•©í•˜ê³  ì •ë ¬
        combined_events = []
        for event in eco_events:
            combined_events.append({'date': event['time'].split(' ')[0], 'type': 'eco', 'data': event})
        for event in earnings_events:
            combined_events.append({'date': event['date'], 'type': 'earn', 'data': event})
            
        sorted_events = sorted(combined_events, key=lambda x: x['date'])

        if sorted_events:
            cols = st.columns(2)
            col_idx = 0
            
            for event in sorted_events:
                event_date = datetime.strptime(event['date'], '%Y-%m-%d').strftime('%m/%d (%a)')
                
                # ì¢Œìš° ì»¬ëŸ¼ì— ë²ˆê°ˆì•„ ê°€ë©° ì´ë²¤íŠ¸ í‘œì‹œ
                with cols[col_idx % 2]:
                    if event['type'] == 'eco':
                        impact = event['data']['impact']
                        impact_icon = "ğŸ”´" if impact == 'high' else "ğŸŸ " if impact == 'medium' else ""
                        st.markdown(f"**{event_date}**: {impact_icon} {event['data']['event']}")
                    elif event['type'] == 'earn':
                        st.markdown(f"**{event_date}**: ğŸ“¢ Earnings - **${event['data']['ticker']}**")
                col_idx += 1
        else:
            st.info("í–¥í›„ 2ì£¼ ë‚´ì— ì˜ˆì •ëœ ì£¼ìš” ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        # --- [MOD v41 End] ---
        st.subheader("ì£¼ìš” ê²½ì œ ë‰´ìŠ¤")
        if market_data.get('news'):
            for item in market_data['news']:
                news_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d')
                st.markdown(f"**[{item['headline']}]({item['url']})** - *{news_date}, {item['source']}*")
        else:
            st.warning("ì£¼ìš” ê²½ì œ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("ì‹œì¥ í˜„í™© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


elif st.session_state.active_view == "ğŸ“¡ íƒìƒ‰":
    st.header("ğŸ“¡ Discovery Engine: Status Tracker")
    st.info("ì„ íƒí•œ ì‹œì¥ì˜ ì „ì²´ ì¢…ëª©ì— ëŒ€í•œ ê¸°ìˆ ì  ìƒíƒœë¥¼ ë¶„ì„í•˜ê³ , í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìƒíƒœ íƒœê·¸ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.")

    # --- ìƒíƒœ(Status) íŒì • ê¸°ì¤€ ì„¤ëª… ---
    with st.expander("â„¹ï¸ ìƒíƒœ(Status) íŒì • ê¸°ì¤€"):
        st.markdown("""
        - **ë§¤ìˆ˜ ì‹ í˜¸ ğŸŸ¢**: ê³¨ë“ í¬ë¡œìŠ¤ê°€ ë°œìƒí–ˆê±°ë‚˜, RSIê°€ 30 ì´í•˜ ê³¼ë§¤ë„ êµ¬ê°„ì— ì§„ì…í•œ ì¢…ëª©.
        - **ì£¼ì˜/ë§¤ë„ ì‹ í˜¸ ğŸ”´**: ë°ë“œí¬ë¡œìŠ¤ê°€ ë°œìƒí–ˆê±°ë‚˜, RSIê°€ 70 ì´ìƒ ê³¼ë§¤ìˆ˜ êµ¬ê°„ì— ì§„ì…í•œ ì¢…ëª©.
        - **ì¤‘ë¦½/ê´€ë§ âšªï¸**: ìœ„ ì‹ í˜¸ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ë‚˜ë¨¸ì§€ ëª¨ë“  ì¢…ëª©.
        """)

    ticker_lists = get_all_ticker_lists()
    
    if not ticker_lists:
        st.warning("'Tickers' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. Google Sheetsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        selected_list_name = st.selectbox("íƒìƒ‰ ëŒ€ìƒ ì‹œì¥ ì„ íƒ:", list(ticker_lists.keys()))
        
        if st.button(f"ğŸš€ {selected_list_name} ì „ì²´ ì¢…ëª© ìƒíƒœ ë¶„ì„", use_container_width=True, type="primary"):
            tickers_to_scan = ticker_lists.get(selected_list_name, [])
            st.session_state.screener_results = run_status_screener(tickers_to_scan)
            st.rerun()

    if "screener_results" in st.session_state:
        st.divider()
        results_df = st.session_state.screener_results
        
        st.subheader(f"ğŸ“Š ìƒíƒœ ë¶„ì„ ê²°ê³¼: {len(results_df)}ê°œ ì¢…ëª©")

        if not results_df.empty:
            # ë“±ë½ë¥ (%) ê°’ì— ë”°ë¼ í°íŠ¸ ìƒ‰ìƒì„ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
            def style_change_percent(val):
                color = 'red' if val < 0 else 'green' if val > 0 else '#525252' # íšŒìƒ‰
                return f'color: {color}'

            st.dataframe(
                results_df.style
                    .applymap(style_change_percent, subset=['ë“±ë½ë¥ (%)'])
                    .format({
                        "í˜„ì¬ê°€": "${:,.2f}",
                        "ë“±ë½ë¥ (%)": "{:+.2f}%",
                        "ê³ ì ëŒ€ë¹„(%)": "{:.2f}%",
                        "RSI": "{:.1f}",
                    }),
                hide_index=True,
                use_container_width=True,
                height=800
            )
        else:
            st.error("ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‹°ì»¤ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")



# --- ìƒì„¸ ë¶„ì„ ë·° ---
elif st.session_state.active_view == "ğŸ” ìƒì„¸ ë¶„ì„":
    if 'analysis_tickers' in st.session_state and st.session_state.analysis_tickers:
        main_ticker = st.session_state.analysis_tickers[0]
        st.header(f"ğŸ” {main_ticker} ìƒì„¸ ë¶„ì„")

        # --- 1. ê¸°ì´ˆ ë°ì´í„° ë¡œë“œ ---
        with st.spinner(f"'{main_ticker}' ìƒì„¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            profile = get_profile_from_hub(main_ticker)
            quote = get_quote_from_hub(main_ticker)
            news = get_news_from_hub(main_ticker)
            financials_df = get_financials_from_hub(main_ticker)
            peers = get_peers_from_hub(main_ticker)
            earnings_data = get_earnings_from_hub(main_ticker)
            next_earnings_date = get_calendar_from_hub(main_ticker)
            candles_df = get_candles_from_hub(main_ticker)

        # --- 2. íƒ­ UI ìƒì„± ---
        analysis_tab_names = ["ğŸ’ ì¢…í•© ì§„ë‹¨", "ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„", "ğŸ’° í€ë”ë©˜í„¸", "ğŸ“° ë‰´ìŠ¤ ë° ê°œìš”", "ğŸ“œ ê³¼ê±° ë¶„ì„ ê¸°ë¡"]
        diag_tab, tech_tab, fin_tab, news_tab, log_tab = st.tabs(analysis_tab_names)

        # [í•µì‹¬ ìˆ˜ì •] 'ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›' ë¡œì§ ê°•í™”
        # Ticker ë³€ê²½ ì‹œ, ì´ì „ ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
        if 'current_ticker' not in st.session_state or st.session_state.current_ticker != main_ticker:
            st.session_state.current_ticker = main_ticker
            st.session_state.last_analysis_text = None
            st.session_state.structured_reco = {}
            # âœ¨ NEW: Ticker ë³€ê²½ ì‹œ ìµœì‹  ë¡œê·¸ë¥¼ ë¶ˆëŸ¬ì™€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            with st.spinner(f"'{main_ticker}'ì˜ ìµœê·¼ ë¶„ì„ ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                analysis_logs = load_analysis_log(main_ticker)
                if not analysis_logs.empty:
                    latest_log = analysis_logs.iloc[0]
                    st.session_state.last_analysis_text = latest_log.get('ì „ì²´ ë¶„ì„ ë‚´ìš©')
                    st.session_state.last_analysis_ticker = main_ticker
                st.rerun() # ìµœì‹  ë¡œê·¸ë¥¼ ë°˜ì˜í•˜ì—¬ í™”ë©´ì„ ë‹¤ì‹œ ê·¸ë¦½ë‹ˆë‹¤.

                        # --- 3. ê° íƒ­ ë‚´ìš© êµ¬ì„± ---
# --- 3. ê° íƒ­ ë‚´ìš© êµ¬ì„± ---
        with diag_tab:
            st.subheader(f"ğŸ’ {main_ticker} ì¢…í•© ì§„ë‹¨")
            cols = st.columns(4)
            if quote and quote.get('c') != 0:
                cols[0].metric("í˜„ì¬ê°€", f"${quote.get('c', 0):.2f}", f"{quote.get('d', 0):.2f}$ ({quote.get('dp', 0):.2f}%)")
            if not candles_df.empty:
                candles_df_tech_diag = add_technical_indicators(candles_df.copy())
                if 'RSI14' in candles_df_tech_diag.columns and not pd.isna(candles_df_tech_diag['RSI14'].iloc[-1]):
                    cols[1].metric("RSI (14ì¼)", f"{candles_df_tech_diag['RSI14'].iloc[-1]:.2f}")
                high_52w = candles_df['High'].max()
                if high_52w > 0:
                    cols[2].metric("52ì£¼ ê³ ì  ëŒ€ë¹„", f"{((quote.get('c', 0) - high_52w) / high_52w) * 100:.2f}%")
            if profile:
                cols[3].metric("ì‹œê°€ì´ì•¡ (M)", f"${profile.get('marketCapitalization', 0):,.0f}")

            st.divider()
            st.subheader("ğŸ¤– AI ì „ëµ ë¶„ì„")

            # [âœ¨ FINAL] ë‘ ë²„íŠ¼ì„ 'AI ì¢…í•© ë¶„ì„' ë‹¨ì¼ ë²„íŠ¼ìœ¼ë¡œ í†µí•©
            if st.button("ğŸ’¡ AI ì¢…í•© ë¶„ì„", use_container_width=True, type="primary"):
                # ì´ì „ ë¶„ì„ ê²°ê³¼ ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.changelog_for_display = ""
                st.session_state.last_analysis_text = "" 

                analysis_logs = load_analysis_log(main_ticker)

                # --- ë¶„ê¸° ë¡œì§: ê¸°ë¡ ìœ ë¬´ì— ë”°ë¼ ì§€ëŠ¥í˜• ë¶„ì„ ë˜ëŠ” ì „ì²´ ë¶„ì„ ìˆ˜í–‰ ---
                if not analysis_logs.empty:
                    # [CASE 1: ê¸°ë¡ ìˆìŒ -> ì§€ëŠ¥í˜• ë¶„ì„ ìˆ˜í–‰]
                    with st.spinner("1/3) ì¢…í•© íŒ©í„° ì‹œíŠ¸ ìƒì„± ì¤‘..."):
                        latest_log = analysis_logs.iloc[0]
                        previous_analysis_text = latest_log.get('ì „ì²´ ë¶„ì„ ë‚´ìš©', '')
                        candles_with_indicators = add_technical_indicators(candles_df.copy())
                        ratings = get_ratings_from_hub(main_ticker)
                        insider_trans = get_insider_trans_from_hub(main_ticker)
                        factor_sheet = create_factor_sheet(main_ticker, latest_log, candles_with_indicators, news, ratings, insider_trans)
                    
                    with st.spinner("2/3) íŒ©í„° ê¸°ë°˜ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸ ì¤‘..."):
                        evolved_report = "".join(list(stream_evolved_report(previous_analysis_text, factor_sheet, main_ticker)))
                        st.session_state.last_analysis_text = evolved_report
                        st.session_state.last_analysis_ticker = main_ticker

                    with st.spinner("3/3) AIê°€ ë³€ê²½ ë‚´ì—­ ë¸Œë¦¬í•‘ì„ ìƒì„± ì¤‘..."):
                        changelog_header = f"ğŸ’¡ **AI ë³€ê²½ì  ë¸Œë¦¬í•‘ (Changelog)**\n\n**[AIê°€ ì…ë ¥ë°›ì€ ì¢…í•© íŒ©í„° ì‹œíŠ¸]**\n```\n{factor_sheet}\n```\n---"
                        ai_briefing = generate_changelog(previous_analysis_text, evolved_report, factor_sheet)
                        st.session_state.changelog_for_display = changelog_header + "\n\n" + ai_briefing
                
                else:
                    # [CASE 2: ê¸°ë¡ ì—†ìŒ -> ì²« ì „ì²´ ë¶„ì„ ìˆ˜í–‰]
                    st.info("ì²« ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì „ì²´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
                    with st.spinner("AIê°€ ìµœì‹  ì •ë³´ë¡œ ì „ì²´ ë¶„ì„ì„ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                        # 'ì°¸ê³  ìë£Œ'ëŠ” ì œê±°í•˜ê³  'í•µì‹¬ ì§€ì¹¨'ë§Œ ì „ë‹¬
                        core_principle_files = synchronize_knowledge_files()
                        
                        # ì „ì²´ ë¶„ì„ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„° ì¤€ë¹„ (ê¸°ì¡´ 'ì „ì²´ ì¬ë¶„ì„' ë¡œì§ê³¼ ë™ì¼)
                        portfolio_df, _, cash_df = load_data_from_gsheet()
                        holding_context = f"í˜„ì¬ {main_ticker} ì¢…ëª©ì€ ë³´ìœ í•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
                        if not portfolio_df.empty and main_ticker in portfolio_df['ì¢…ëª©ì½”ë“œ'].values:
                            holding_info = portfolio_df[portfolio_df['ì¢…ëª©ì½”ë“œ'] == main_ticker].iloc[0]
                            shares, avg_price_usd = holding_info.get('ìˆ˜ëŸ‰', 0), holding_info.get('í‰ê·  ë‹¨ê°€(USD)', 0)
                            holding_context = f"í˜„ì¬ ë¶„ì„ ëŒ€ìƒì¸ {main_ticker} ì¢…ëª©ì€ {shares}ì£¼ë¥¼ í‰ê·  ë‹¨ê°€ ${avg_price_usd:,.2f}ì— ë³´ìœ  ì¤‘ì…ë‹ˆë‹¤."

                        investable_cash, emergency_cash = 0, 0
                        if not cash_df.empty:
                            investable_mask = cash_df['ì¢…ëª©ëª…'].str.contains('CMA', na=False)
                            investable_cash = cash_df.loc[investable_mask, 'ê¸ˆì•¡(KRW)'].sum()
                            emergency_mask = cash_df['ì¢…ëª©ëª…'].str.contains('ë¹„ìƒê¸ˆ', na=False)
                            emergency_cash = cash_df.loc[emergency_mask, 'ê¸ˆì•¡(KRW)'].sum()

                        cash_context = f"ê·¸ ì™¸ì—, ì¶”ê°€ë¡œ íˆ¬ì ê°€ëŠ¥í•œ í˜„ê¸ˆ(CMA)ì€ ì•½ {investable_cash:,.0f}ì› ë³´ìœ  ì¤‘ì´ë©°, ë¹„ìƒê¸ˆì€ ì•½ {emergency_cash:,.0f}ì›ì…ë‹ˆë‹¤."
                        full_context = f"{holding_context}\n{cash_context}"

                        tech_summary = generate_technical_summary(add_technical_indicators(candles_df.copy()))
                        support_levels = calculate_support_levels(candles_df)
                        dynamic_trends = calculate_dynamic_trends(candles_df.copy(), quote)
                        market_context = get_market_status_data()

                        # AI í˜¸ì¶œ (reference_files ì¸ì ì—†ì´ í˜¸ì¶œ)
                        full_analysis_text = "".join(list(stream_and_capture_analysis(main_ticker, profile, quote, financials_df, tech_summary, news, full_context, support_levels, dynamic_trends, market_context, core_principle_files)))
                        st.session_state.last_analysis_text = full_analysis_text
                        st.session_state.last_analysis_ticker = main_ticker

                st.rerun()

            st.markdown("---")

            # âœ¨ FINAL REVISED: í†µí•©ëœ 'ìµœì¢… ë¶„ì„ ê²°ê³¼' í‘œì‹œ ë¡œì§
            # ì§€ëŠ¥í˜• ì¬ë¶„ì„ ê²°ê³¼ ë¸Œë¦¬í•‘ì„ ë¨¼ì € í‘œì‹œ
            if "changelog_for_display" in st.session_state and st.session_state.changelog_for_display:
                with st.expander("ğŸ’¡ AI ë³€ê²½ì  ë¸Œë¦¬í•‘", expanded=True):
                    st.markdown(st.session_state.changelog_for_display)
            
            # í•­ìƒ 'ê³µì‹ì ì¸ ìµœì¢… ë¶„ì„ ê²°ê³¼'ë¥¼ í‘œì‹œ (ì§€ëŠ¥í˜•/ì „ì²´ ë¶„ì„ ëª¨ë‘ ì—¬ê¸°ì— ë°˜ì˜ë¨)
            if st.session_state.get("last_analysis_text") and st.session_state.get("last_analysis_ticker") == main_ticker:
                st.subheader("ğŸ’¡ AI ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                st.markdown(st.session_state.last_analysis_text)
                
                # ì €ì¥ ë²„íŠ¼ ë¡œì§ì€ ì´ì œ í•­ìƒ ì •í™•í•˜ê²Œ ì‘ë™
                if st.button("ğŸ’¾ í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì €ì¥", key=f"gemini_save_{main_ticker}"):
                    with st.spinner("ë¶„ì„ ê²°ê³¼ë¥¼ Google Sheetsì— ì €ì¥í•˜ëŠ” ì¤‘..."):
                        tech_summary_save = generate_technical_summary(add_technical_indicators(candles_df.copy()))
                        support_levels_save = calculate_support_levels(candles_df)
                        data_snapshot = {
                            "profile": profile, "quote": quote,
                            "news_headlines": [item['headline'] for item in news[:5]] if news else [],
                            "tech_summary": tech_summary_save, "support_levels": support_levels_save
                        }
                        
                        analysis_text_to_save = st.session_state.get("last_analysis_text", "")
                        try:
                            summary_text = analysis_text_to_save.split("#### 4.")[0].strip().replace("*", "").replace("#", "")[-200:] + "..."
                        except Exception:
                            summary_text = analysis_text_to_save.strip().replace("*","").replace("#","")[:200] + "..."
                        
                        log_entry = {
                            "Timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            "ì¢…ëª©ì½”ë“œ": main_ticker,
                            "AI_Model": st.session_state.get("last_model_used", "N/A"),
                            "ë‹¹ì‹œ ì£¼ê°€": quote.get('c', 0) if quote else 0,
                            "ë¶„ì„ ìš”ì•½": summary_text,
                            "ì „ì²´ ë¶„ì„ ë‚´ìš©": analysis_text_to_save,
                            "ì£¼ìš” ë°ì´í„°": json.dumps(data_snapshot, ensure_ascii=False, indent=2)
                        }

                        if save_analysis_to_gsheet(log_entry):
                            st.toast("âœ… ë¶„ì„ ê²°ê³¼ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")
                            st.cache_data.clear() # ìºì‹œ í´ë¦¬ì–´ í›„ ì¬ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë¡œê·¸ ë°˜ì˜
                            st.rerun()
                        else:
                            st.error("ë¶„ì„ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. 'ì¬ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ìƒˆ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ì´í•˜ ë‹¤ë¥¸ íƒ­ë“¤(tech_tab, fin_tab, news_tab, log_tab)ì˜ ë¡œì§ì€ ê¸°ì¡´ ì½”ë“œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        # [ì¤‘ìš”] ë‹¨, ê° íƒ­ì—ì„œ parsed_dataë¥¼ ì°¸ì¡°í•˜ê¸° ì „ì—, st.session_state.last_analysis_textë¥¼ íŒŒì‹±í•˜ëŠ” ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.
        
        # 'ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›' íŒŒì‹± ë¡œì§ (ê° íƒ­ ë Œë”ë§ ì§ì „ì— ìœ„ì¹˜)
        parsed_data = {}
        if st.session_state.get("last_analysis_text"):
            parsed_data = structure_recommendation(st.session_state.last_analysis_text)
       

        with tech_tab:
            st.subheader("ğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„")

            if parsed_data and parsed_data.get('technical_briefing'):
                st.info(parsed_data['technical_briefing'])

            if not candles_df.empty and len(candles_df) > 60:
                candles_df_tech = add_technical_indicators(candles_df.copy())
                st.divider()
                st.subheader("AI ì¶”ì²œ ë§¤ë§¤ êµ¬ê°„ ì‹œê°í™”")
                fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05, subplot_titles=('Candlestick & AI Zones', 'MACD', 'RSI'), row_heights=[0.6, 0.2, 0.2])
                fig.add_trace(go.Candlestick(x=candles_df_tech['Date'], open=candles_df_tech['Open'], high=candles_df_tech['High'], low=candles_df_tech['Low'], close=candles_df_tech['Close'], name='Price'), row=1, col=1)

                if parsed_data:
                    buy_zones = parsed_data.get('buy_zones')
                    sell_zones = parsed_data.get('sell_zones')
                    if buy_zones and buy_zones.get('zone1'):
                        fig.add_hrect(y0=buy_zones['zone1'][0], y1=buy_zones['zone1'][1], line_width=0, fillcolor="green", opacity=0.2, annotation_text="1st Buy Zone", annotation_position="bottom right", row=1, col=1)
                    if sell_zones and sell_zones.get('zone1'):
                        fig.add_hrect(y0=sell_zones['zone1'][0], y1=sell_zones['zone1'][1], line_width=0, fillcolor="red", opacity=0.2, annotation_text="1st Sell Zone", annotation_position="bottom right", row=1, col=1)
                
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SMA20'], name='SMA 20', line=dict(color='orange', width=1)), row=1, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SMA60'], name='SMA 60', line=dict(color='purple', width=1)), row=1, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['MACD'], name='MACD', line=dict(color='blue', width=1)), row=2, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['SignalLine'], name='Signal Line', line=dict(color='red', width=1)), row=2, col=1)
                fig.add_trace(go.Scatter(x=candles_df_tech['Date'], y=candles_df_tech['RSI14'], name='RSI 14', line=dict(color='royalblue', width=1)), row=3, col=1)
                fig.add_hline(y=70, line_dash="dash", line_color="red", row=3, col=1)
                fig.add_hline(y=30, line_dash="dash", line_color="green", row=3, col=1)
                fig.update_layout(height=800, xaxis_rangeslider_visible=False)
                st.plotly_chart(fig, use_container_width=True)
            else: 
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ì°¨íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë§¤ìˆ˜ êµ¬ê°„ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            
        with fin_tab:
            st.subheader("ğŸ’° í€ë”ë©˜í„¸ ë¶„ì„")
            # [ì‹ ê·œ] AI í€ë”ë©˜í„¸ ë¸Œë¦¬í•‘ í‘œì‹œ
            if parsed_data.get('fundamental_briefing'):
                st.info(parsed_data['fundamental_briefing'])

            st.divider()

            st.subheader("í•µì‹¬ ì¬ë¬´ ì§€í‘œ (ì—°ê°„)")
            if not financials_df.empty: st.dataframe(financials_df.style.format("{:,.2f}", na_rep="-"))
            else: st.warning(f"'{main_ticker}'ì— ëŒ€í•œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.subheader("ë¶„ê¸°ë³„ ì‹¤ì  ë°œí‘œ ë‚´ì—­")
            if not earnings_data.empty:
                format_dict = {'ì‹¤ì œ EPS': '{:.2f}', 'ì˜ˆìƒ EPS': '{:.2f}', 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)': '{:.2f}%'}
                st.dataframe(earnings_data.style.format(format_dict, na_rep="-"))
                if 'EPS ì„œí”„ë¼ì´ì¦ˆ (%)' in earnings_data.columns:
                    fig_earn = px.bar(earnings_data, x='ë°œí‘œ ë¶„ê¸°', y='EPS ì„œí”„ë¼ì´ì¦ˆ (%)', color='EPS ê²°ê³¼', color_discrete_map={'Beat': 'green', 'Miss': 'red', 'Meet': 'blue'})
                    st.plotly_chart(fig_earn, use_container_width=True)
            else: st.warning(f"'{main_ticker}'ì— ëŒ€í•œ ì‹¤ì  ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.subheader("ê²½ìŸì‚¬ ë¹„êµ")
            if peers:
                peer_df = get_peer_summary([p for p in peers if p != main_ticker][:5])
                if not peer_df.empty: st.dataframe(peer_df.set_index('Ticker').style.format({"Market Cap (M)": "{:,.0f}", "% Change": "{:.2f}%"}, na_rep="-").background_gradient(cmap='RdYlGn', subset=['% Change']))
                else: st.info("ê²½ìŸì‚¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else: st.info("ê²½ìŸì‚¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        with news_tab:
            st.subheader("ğŸ“° ë‰´ìŠ¤ ë° ê¸°ì—… ê°œìš”")
            # [ì‹ ê·œ] AI ë‰´ìŠ¤ ë¸Œë¦¬í•‘ í‘œì‹œ
            if parsed_data.get('news_briefing'):
                st.info(parsed_data['news_briefing'])

            st.divider()
            if profile:
                st.subheader(f"ê¸°ì—… í”„ë¡œí•„: {profile.get('name', main_ticker)}")
                col1, col2 = st.columns([1, 4]); col1.image(profile.get('logo'), width=100)
                with col2: st.text(f"Industry: {profile.get('finnhubIndustry')}"); st.link_button("Visit Website", profile.get('weburl'))
                if next_earnings_date: st.info(f"**ë‹¤ìŒ ì‹¤ì  ë°œí‘œ ì˜ˆì •ì¼:** {next_earnings_date}")
            else: st.warning("ê¸°ì—… í”„ë¡œí•„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.divider()
            st.subheader("ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤")
            if news:
                for item in news[:10]:
                    news_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d %H:%M')
                    st.markdown(f"**[{item['headline']}]({item['url']})**\n- *Source: {item['source']} | {news_date}*")
            else: st.info("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with log_tab:
            st.subheader("ğŸ“œ ê³¼ê±° ë¶„ì„ ê¸°ë¡ ë³´ê´€ì†Œ")
            analysis_logs = load_analysis_log(main_ticker)
            if not analysis_logs.empty:
                for index, row in analysis_logs.iterrows():
                    log_time = pd.to_datetime(row['Timestamp']).strftime('%Y-%m-%d %H:%M')
                    with st.expander(f"**{log_time}** | ë‹¹ì‹œ ì£¼ê°€: ${float(row.get('ë‹¹ì‹œ ì£¼ê°€', 0)):.2f}"):
                        st.markdown(row.get('ì „ì²´ ë¶„ì„ ë‚´ìš©', 'ì €ì¥ëœ ì „ì²´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'))
            else:
                st.info(f"'{main_ticker}'ì— ëŒ€í•œ ê³¼ê±° ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  Tickerë¥¼ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒì„¸ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")


        
with st.sidebar:
    st.header("Controls")
    view_options = ["ğŸ”­ ì‹œì¥ ê±´ê°• ìƒíƒœ", "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤", "ğŸ“¡ ë ˆì´ë”", "ğŸ“¡ íƒìƒ‰", "ğŸ” ìƒì„¸ ë¶„ì„"] #<-- ì´ë ‡ê²Œ ë³€ê²½
    
    # st.radioì˜ í˜„ì¬ ì„ íƒê°’ì„ selected_view ë³€ìˆ˜ì— ì €ì¥
    selected_view = st.radio(
        "Select View", 
        view_options, 
        index=view_options.index(st.session_state.active_view), 
        #horizontal=True,
        key="view_selector"
    )
    
    if selected_view != st.session_state.active_view:
        st.session_state.active_view = selected_view
        st.rerun()

    st.divider()
    
    default_tickers = ""
    if not st.session_state.watchlist_df.empty and 'ì¢…ëª©ì½”ë“œ' in st.session_state.watchlist_df.columns:
        default_tickers = ", ".join(st.session_state.watchlist_df['ì¢…ëª©ì½”ë“œ'].dropna().unique().tolist())
    
    tickers_input = st.text_area("Ticker(s) for Analysis", value=default_tickers, help="ë¶„ì„í•  ì¢…ëª©ì˜ Tickerë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”.")
    
    if st.button("ğŸ” ë¶„ì„ ì‹¤í–‰", use_container_width=True, type="primary"):
        # --- âœ¨ NEW: ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘ ì‹œ, ì´ì „ ë¶„ì„ ê¸°ë¡ ì´ˆê¸°í™” ---
        # ì´ì „ì— ë‚¨ì•„ìˆì„ ìˆ˜ ìˆëŠ” ëª¨ë“  ë¶„ì„ ê²°ê³¼ ê´€ë ¨ ì„¸ì…˜ ìƒíƒœë¥¼ ê¹¨ë—í•˜ê²Œ ë¹„ì›ë‹ˆë‹¤.
        keys_to_clear = [
            "last_analysis_text", 
            "last_analysis_ticker", 
            "changelog_for_display",
            "beta_analysis_result", # í˜¹ì‹œ ëª¨ë¥¼ ì´ì „ ë² íƒ€ ê²°ê³¼ë„ í•¨ê»˜ ì œê±°
            "beta_changelog",
            "beta_evolved_report"
        ]
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        # -----------------------------------------------------------

        st.session_state.analysis_tickers = [ticker.strip().upper() for ticker in tickers_input.replace(',', '\n').split('\n') if ticker.strip()]
        st.session_state.active_view = "ğŸ” ìƒì„¸ ë¶„ì„"
        # st.session_state.last_analysis_text = None # ìœ„ì—ì„œ delë¡œ ëŒ€ì²´ë˜ì—ˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì‚­ì œ
        st.session_state.last_saved_ticker = None
        st.rerun()

    st.divider()
    st.info("í¬íŠ¸í´ë¦¬ì˜¤, í˜„ê¸ˆ, ê´€ì‹¬ì¢…ëª©ì€ Google Sheetsì—ì„œ ì§ì ‘ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
    if st.button("ğŸ”„ Reload Data & Clear Cache", use_container_width=True):
        st.session_state.clear()
        st.cache_data.clear()
        st.rerun()

